---
title: "Score_Qualtrics"
author: "Kate, Cameron, & Nandi"
date: "15 July 2017"
output: html_document
---

```{r}

```

Set working directory
```{r Set Directory, message=FALSE, warning=FALSE, include=FALSE}
getwd()
#You should set this to the behavioral directory on the TAG file server 
workdir='I:/dsnlab/TAG/behavior/' 
```

Load required packages
```{r Load packages, message=FALSE, warning=FALSE, include=FALSE}
## Load required packages ##
packages <- c("lme4", "nlme", "ggplot2", "dplyr", "tidyr", "knitr",
              "parallel", "data.table", "lubridate","xml2","devtools")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))  
}
lapply(packages, library, character.only = TRUE)
install_github('jflournoy/qualtrics')
library(scorequaltrics)
rm(packages)
```

Extract qualtrics data from website
```{r Extract Qualtrics, message=FALSE, warning=FALSE, include=FALSE}
credsFile<-file.path(workdir,"Questionnaires/RDOC/Confidential/credentials.yaml.DEFAULT", fsep="")
creds<-creds_from_file(credsFile)

exclude_survey=c("NV","GUT","TEST","Appointment","Newsletter","SOS","Sharing Task")
survey_info<-scorequaltrics::get_surveys(creds) %>% 
  filter(!grepl(paste0(exclude_survey,collapse="|"),SurveyName)) %>% 
  #filter(!SurveyName %in% paste0(exclude_survey)) %>%
  dplyr::select(SurveyID, SurveyName)

get_survey_data<-function(surveysDF,pid_col){
  #Takes the data.frame that is returned by `get_surveys`
  #Returns a long format data.frame of survey data with names
  # "SID variable name"         "item"        "value"       "survey_name"
  survey_data<-surveysDF %>% 
    group_by(SurveyID) %>%
    do(
      survey_name=.$SurveyName[[1]],
      survey_data=scorequaltrics::get_survey_responses(
        creds,
        surveyid=.$SurveyID[[1]])
    )
  long_survey_data<-survey_data %>% 
    filter(dim(survey_data)[1]>0) %>%
    do({
      colNames <- names(.$survey_data)
      gather_cols_list <- lapply(pid_col, function(x) colNames[!grepl(x, colNames)])
      gather_cols<-Reduce(intersect, gather_cols_list)
      aDF<-gather_(.$survey_data,
                   'item',
                   'value',
                   gather_cols)
      aDF$survey_name<-.$survey_name
      aDF
    })
  long_survey_data
}

raw_survey_data <- get_survey_data(survey_info,pid_col=c("SID", "SID_embed"))

long_survey_data<- raw_survey_data %>% mutate(value = ifelse(value == -99, NA, value)) %>% 
  mutate(SID = ifelse(!is.na(SID_embed), SID_embed, 
                      ifelse(SID=="", SID_embed, SID))) %>%
  select(-SID_embed)

embedded_qs<-survey_info %>% 
  filter(SurveyName %in% c("TAG - Home Qs - V3 - with SID embedded", 
                           "TAG - W1 Home Qs - Current V4")) 
sortbyqid_data <- get_survey_data(embedded_qs,pid_col="qid") %>% mutate(value = ifelse(value == -99, NA, value))

rm(creds,credsFile,get_survey_data)
```

Clean qualtrics (from scratch)
```{r Clean qualtrics, message=FALSE, warning=FALSE, include=FALSE}
#This is too slow. See data table implementation below.
# system.time({
# cleaned_survey_data<- long_survey_data %>% 
#   mutate(tagid=ifelse(nchar(SID)==3, sprintf("TAG%03s",SID), SID)) %>%
#   select(tagid, item, value, survey_name) %>%
#   filter(!tagid=="TAG000",
#          !tagid=="TAG999") %>%
#   mutate(tagid=ifelse(tagid=="013 ", "TAG013", tagid))
# })
#   user  system elapsed 
# 45.024   2.324  46.810 

library(data.table)
cleaned_survey_data <- as.data.table(long_survey_data)
cleaned_survey_data[, tagid := ifelse(nchar(SID)==3, sprintf("TAG%03s",SID), SID)]
cleaned_survey_data[, SID := NULL]
cleaned_survey_data <- cleaned_survey_data[!(tagid %in% c('TAG000', 'TAG999'))]
cleaned_survey_data[tagid == '013 ', tagid := 'TAG013']
cleaned_survey_data[tagid == '70', tagid := 'TAG070']
cleaned_survey_data[tagid == 'TAG255', tagid := 'TAG225'] #SJC updated
cleaned_survey_data[tagid == 'home', tagid := "TAG244"] #NV updated
cleaned_survey_data[tagid == '541695411', tagid := "TAG040"] #NV updated
cleaned_survey_data[tagid == "TAGHVU", tagid := "TAG070"] #NV updated
cleaned_survey_data <- as.data.frame(cleaned_survey_data)
#The above is much much quicker.
#  user  system elapsed 
# 0.228   0.012   0.241 

IDs<-unique(cleaned_survey_data$tagid)

# Need to fix the IDs of participants
# who showed an error with their qualtrics
# home questionnaires
misIDkey<-read.csv(paste0(workdir,"Questionnaires/RDOC/Confidential/qidkey.csv"))
TAGHomeQ<-sortbyqid_data
for (i in 1:length(misIDkey$qid)){
  TAGHomeQ <- TAGHomeQ %>%
    mutate(value=ifelse(qid==as.character(misIDkey$qid[i]) && item=="SID",
                        as.character(misIDkey$SID[i]),value))
}
gather_cols<-unique(TAGHomeQ$item)
TAGEmbeddedHomeQ_Gathered <- TAGHomeQ %>% 
  spread(item,value) %>%
  mutate(tagid=ifelse(nchar(SID)==3, sprintf("TAG%03s",SID), SID))
test1 <- select(TAGEmbeddedHomeQ_Gathered, tagid, survey_name, qid, everything())
test2 <- gather(test1,"item","value",3:dim(test1)[2]) %>%
  filter(!tagid=='')

cleaned_survey_data2 <- bind_rows(cleaned_survey_data, test2)
cleaned_survey_data3<-cleaned_survey_data2 %>% distinct(tagid,item,value,survey_name,.keep_all = TRUE)

#Remove missing data and the duplicated data from the embedded ID home questionnaires
cleaned_survey_data<-cleaned_survey_data3 %>% 
  filter(!tagid=="") %>% 
  filter(!tagid=="SV_eqvWqPtsOO4uqPP") %>% 
  filter(grepl('TAG', tagid))

# Change the one participant with a ghost SID
cleaned_survey_data <- cleaned_survey_data %>%
  mutate(tagid=ifelse(tagid=="078\177","TAG078",tagid)) 

#Check odd IDs:
#cleaned_survey_data %>% filter(item == 'qid') %>% distinct(tagid, survey_name, value) %>% filter(!grepl('TAG', tagid)) %>% write.csv('~/weirdIDs.csv')

rm(cleaned_survey_data2,cleaned_survey_data3,embedded_qs,misIDkey,missingID,sortbyqid_data,TAGEmbeddedHomeQ_Gathered,TAGHomeQ,test1,test2,i,gather_cols,IDs)
rm(long_survey_data)

surveyed<-unique(cleaned_survey_data$tagid)
surveyed

print(paste0("A total of ",length(surveyed)," participants have completed surveys!"))
print(paste0("A total of ",length(unique((cleaned_survey_data %>% filter(grepl("Home",survey_name)))$tagid))," participants have completed home surveys!"))
print(paste0("A total of ",length(unique((cleaned_survey_data %>% filter(grepl("Sess 1",survey_name) | grepl("W1S1",survey_name)))$tagid))," participants have completed Wave 1 Session 1 surveys!"))
print(paste0("A total of ",length(unique((cleaned_survey_data %>% filter(grepl("Sess 2",survey_name) | grepl("W1S2",survey_name)))$tagid))," participants have completed Wave 1 Session 2 surveys!"))
print(paste0("A total of ",length(unique((cleaned_survey_data %>% filter(grepl("W2S1",survey_name)))$tagid))," participants have completed Wave 2 Session 1 surveys!"))
print(paste0("A total of ",length(unique((cleaned_survey_data %>% filter(grepl("W2S2",survey_name)))$tagid))," participants have completed Wave 2 Session 2 surveys!"))
print(paste0("A total of ",length(unique((cleaned_survey_data %>% filter(grepl("W3S1",survey_name)))$tagid))," participants have completed Wave 3 Session 1 surveys!"))
print(paste0("A total of ",length(unique((cleaned_survey_data %>% filter(grepl("W3S2",survey_name)))$tagid))," participants have completed Wave 3 Session 2 surveys!"))

#rm(surveyed)
```

Load and clean redcap info
```{r Load&Clean Redcap, message=FALSE, warning=FALSE, include=FALSE}
redcapData <- read.csv(paste0(workdir,"Questionnaires/RDOC/Confidential/redcap_dates_20190110.csv"), header = TRUE, stringsAsFactors = FALSE)# %>%
  # filter(!grepl("wave_2",redcap_event_name))
redcapData_dob<-redcapData %>%
  select(dob,subject_spit_id) %>%
  filter(!dob=="")
redcapData_sessiondates<-redcapData %>%
  select(sa_date,sb_date,redcap_event_name,subject_spit_id) %>%
  filter(!sa_date=="") %>%
  extract(redcap_event_name, c('wave'), 'wave_([\\d]).*')
redcap_cleaned<-merge(redcapData_sessiondates,redcapData_dob) %>%
  mutate(tagid=substring(subject_spit_id,first=4,last=length(subject_spit_id)))%>%
  filter(!subject_spit_id=="TAG_001P") %>%
  mutate(tagid=ifelse(nchar(tagid)==4,substring(subject_spit_id,first=5,last=length(subject_spit_id)),tagid)) %>%
  mutate(tagid=sprintf("TAG%03d",as.integer(tagid))) %>%
  select(-subject_spit_id)
redcap_cleaned$sa_date <- as.Date(redcap_cleaned$sa_date, format = "%m/%d/%Y")
redcap_cleaned$sb_date <- as.Date(redcap_cleaned$sb_date, format = "%m/%d/%Y")
redcap_cleaned$dob <- as.Date(redcap_cleaned$dob, format = "%m/%d/%Y")
rm(redcapData_dob,redcapData,redcapData_sessiondates)
```

Configure anthro information
```{r Load&Clean Redcap, message=FALSE, warning=FALSE, include=FALSE}
redcap_anthro <- read.csv(paste0(workdir,"Questionnaires/RDOC/Confidential/redcap_anthro.csv"), header = TRUE, stringsAsFactors = FALSE) %>%
  filter(!anthro_doc=="") %>%
  extract(redcap_event_name, c('wave'), 'wave_([\\d]).*') %>%
  mutate(tagid=substring(subject_spit_id,first=4,last=length(subject_spit_id)))%>%
  filter(!subject_spit_id=="TAG_001P") %>%
  mutate(tagid=ifelse(nchar(tagid)==4,substring(subject_spit_id,first=5,last=length(subject_spit_id)),tagid)) %>%
  mutate(tagid=sprintf("TAG%03d",as.integer(tagid))) %>%
  select(-subject_spit_id)
anthro<-left_join(redcap_anthro,redcap_cleaned,by=c("tagid", "wave")) %>%
  mutate_at(vars(matches('(height|weight|waist).*')), funs(as.numeric)) %>%
  mutate(height_1=ifelse(height_system==3,(height_1*2.54),height_1),
         height_2=ifelse(height_system==3,(height_2*2.54),height_2),
         height_3=ifelse(height_system==3,(height_3*2.54),height_3),
         waist_1=ifelse(waist_system==3,(waist_1*2.54),waist_1),
         waist_2=ifelse(waist_system==3,(waist_2*2.54),waist_2),
         waist_3=ifelse(waist_system==3,(waist_3*2.54),waist_3),
         weight_1=ifelse(weight_system==2,(weight_1*0.453592),weight_1),
         weight_2=ifelse(weight_system==2,(weight_2*0.453592),weight_2),
         weight_3=ifelse(weight_system==2,(weight_3*0.453592),weight_3))
anthro<- left_join(anthro, 
                   anthro %>%
                     group_by(tagid, wave) %>%
                     summarise(height=ifelse(!is.na(height_1 & height_2 & height_3),
                                             median(c(height_1,height_2,height_3)),
                                             ifelse(!is.na(height_1 & height_2) & is.na(height_3),
                                                    mean(c(height_1,height_2)),
                                                    ifelse(!is.na(height_1) & is.na(height_2 & height_3), height_1,
                                                           height_1)))))
anthro<- left_join(anthro, anthro %>%
                     group_by(tagid, wave) %>%
                     summarise(weight=round(ifelse(!is.na(weight_1 & weight_2 & weight_3), median(c(weight_1, weight_2, weight_3)),
                                                   ifelse(!is.na(weight_1 & weight_2) & is.na(weight_3), mean(c(weight_1, weight_2)),
                                                          ifelse(!is.na(weight_1) & is.na(weight_2 & weight_3), weight_1, weight_1))),3)))
anthro<- left_join(anthro, anthro %>%
                     group_by(tagid, wave) %>%
                     summarise(waist=ifelse(!is.na(waist_1 & waist_2 & waist_3), median(c(waist_1, waist_2, waist_3)),
                                            ifelse(!is.na(waist_1 & waist_2) & is.na(waist_3), mean(c(waist_1, waist_2)),
                                                   ifelse(!is.na(waist_1) & is.na(waist_2 & waist_3), waist_1, waist_1)))))
anthro$anthro_doc <- as.Date(anthro$anthro_doc, format = "%m/%d/%Y")
anthro<-anthro %>% 
  filter(!is.na(anthro_doc)) %>%
  mutate(age=round((interval(start = dob, end = anthro_doc) / duration(num = 1, units = "years")),2)) %>%
  select(-sa_date,-sb_date,-contains("waist_"),-contains("height_"),-contains("weight_"),-dob)

heights_graph<-ggplot(anthro, aes(x=height)) +
  geom_histogram(alpha=.3)+
  ggtitle(paste0("Height (cm) for ",length(anthro$height[!is.na(anthro$height)])," participants"))+
  facet_grid(~wave)

weights_graph<-ggplot(anthro, aes(x=weight)) +
  geom_histogram(alpha=.3)+
  ggtitle(paste0("Weight (lb) for ",length(anthro$weight[!is.na(anthro$weight)])," participants"))+
  facet_grid(~wave)

waist_graph<-ggplot(anthro, aes(x=waist)) +
  geom_histogram(alpha=.3)+
  ggtitle(paste0("Waist measurement (cm) for ",length(anthro$waist[!is.na(anthro$waist)])," participants"))+
  facet_grid(~wave)

anthro_change_graph <- anthro %>%
  select(tagid, height, weight, waist, age) %>%
  gather(key='key', value='value', -tagid, -age) %>%
  ggplot(aes(x=age, y=value, group=tagid)) +
  geom_point(alpha=.15) +
  geom_line(alpha=.5) +
  geom_line(aes(group=NULL), stat = 'smooth', method = 'loess', span=1, color = 'blue') +
  facet_wrap(~key, scales='free') +
  theme_bw()

rm(waist_graph,heights_graph,weights_graph,redcap_anthro,anthro_change_graph)
```

ONLY RUN IF Prepping for NDA Submission: Prepare GUIDs
```{r, eval=FALSE, include=FALSE}
redcap_NDA_info <- read.csv(paste0(workdir,"RDoCdb/Confidential/redcap_nda_consent_20190111.csv"),
                            header = TRUE,
                            stringsAsFactors = FALSE)

redcapNDA_sessiondates<-redcap_NDA_info %>%
  select(sa_date,sb_date,subject_spit_id) %>%
  filter(!sa_date=="" & !sb_date=="") %>%
  distinct()

redcap_NDA_info$nda_form_date <- as.Date(redcap_NDA_info$nda_form_date, format = "%m/%d/%Y")
redcap_NDA_info$dob <- as.Date(redcap_NDA_info$dob, format = "%m/%d/%Y")
redcap_NDA_info$sa_date <- as.Date(redcap_NDA_info$sa_date, format = "%m/%d/%Y")
redcap_NDA_info$sb_date <- as.Date(redcap_NDA_info$sb_date, format = "%m/%d/%Y")

redcapNDA_data<-redcap_NDA_info %>%
  select(-sa_date,-sb_date) %>%
  filter(!participant_first_name=="") %>%
  distinct()

redcapNDA_sessiondates$sa_date <- as.Date(redcapNDA_sessiondates$sa_date, format = "%m/%d/%Y")
redcapNDA_sessiondates$sb_date <- as.Date(redcapNDA_sessiondates$sb_date, format = "%m/%d/%Y")

redcap_NDA_info<-merge(redcapNDA_sessiondates,redcapNDA_data) %>%
  mutate(tagid=substring(subject_spit_id,first=4,last=length(subject_spit_id)))%>%
  filter(!subject_spit_id=="TAG_001P") %>%
  mutate(tagid=ifelse(nchar(tagid)==4,substring(subject_spit_id,first=5,last=length(subject_spit_id)),tagid),
         dob=as.Date(dob),
         sa_date=as.Date(sa_date),
         sb_date=as.Date(sb_date))

rm(redcapNDA_data,redcapNDA_sessiondates)

guid_colnames<-colnames(read.csv(paste0(workdir,"RDoCdb/templates/guid_sample_template.csv"),
                                 header = TRUE,
                                 stringsAsFactors = FALSE,
                                 nrow=1))

consentedlist<-unique(redcap_NDA_info %>%
                  filter(nda_consent___1==1 & nda_consent___2==1) %>%
                  select(tagid))[[1]]

prepareGUIDs=function(subID){
  sub_NDA_info<-redcap_NDA_info %>% filter(tagid==subID)
  assign(guid_colnames[2], sub_NDA_info$participant_first_name)
  assign(guid_colnames[3], ifelse(sub_NDA_info$participant_middle_name=="No Middle Name",
                                  "",
                                  sub_NDA_info$participant_middle_name))
  assign(guid_colnames[4], sub_NDA_info$participant_last_name)
  assign(guid_colnames[5], month(parse_date_time(sub_NDA_info$dob[1], order=c('ymd'))))
  assign(guid_colnames[6], day(parse_date_time(sub_NDA_info$dob[1], order=c('ymd'))))
  assign(guid_colnames[7], year(parse_date_time(sub_NDA_info$dob[1], order=c('ymd'))))
  assign(guid_colnames[8], sub_NDA_info$participant_city_of_birth)
  assign(guid_colnames[9],"F")
  assign(guid_colnames[10],ifelse(sub_NDA_info$participant_middle_name=="No Middle Name","NO","YES"))
  assign(guid_colnames[11],"YES")
  cbind(subID,get(guid_colnames[2]),get(guid_colnames[3]),get(guid_colnames[4]),get(guid_colnames[5]),get(guid_colnames[6]),
        get(guid_colnames[7]),get(guid_colnames[8]),get(guid_colnames[9]),get(guid_colnames[10]),get(guid_colnames[11]))
}

guid_batch<-lapply(consentedlist,prepareGUIDs)
guid_batch.df<-as.data.frame(do.call(rbind,guid_batch)) %>% distinct()
guid_batch_ids<-guid_batch.df %>%
  select(subID) %>%
  mutate(ID=row.names(guid_batch.df),
         tagid=sprintf("TAG%03s",subID)) %>%
  select(-subID)
guid_batch.df<- guid_batch.df %>% select(-subID)
guid_batch.df<-cbind(guid_colnames[1],guid_batch.df)
colnames(guid_batch.df) <- guid_colnames
guid_batch.df$ID <-row.names(guid_batch.df)
print(paste0("GUID batch created for ",nrow(guid_batch.df)," participants!"))
rm(guid_batch,guid_colnames,consentedlist,redcap_NDA_info)
write.csv(guid_batch.df,file=paste0(workdir,"RDoCdb/Confidential/GUID_batch_",Sys.Date(),".csv"),row.names = FALSE)
write.csv(guid_batch_ids,file=paste0(workdir,"RDoCdb/Confidential/GUID_batch_subIDkey_",Sys.Date(),".csv"),row.names = FALSE)
```

Get Survey Date info
```{r}
survey_startdate<-filter(cleaned_survey_data, grepl("StartDate",item)) %>%
  filter(!survey_name=="Sharing Task Experience Survey") %>%
  mutate(startdate=as.Date(value),
         survey_type=ifelse(grepl("(Sess 1|W[123]S1)",survey_name),"Sess 1",
                            ifelse(grepl("(Sess 2|W[123]S2)",survey_name),"Sess 2",
                                   ifelse(grepl("Parent",survey_name),"Parent",
                                          ifelse(grepl("Home",survey_name),"Home",
                                                 NA)))))  %>%
  select(-value,-item) %>%
  # filter(!survey_type=="Parent") %>%
  dplyr::arrange(startdate)

survey_originaldate<-filter(cleaned_survey_data, grepl("original.date.timestamp",item)) %>%
  filter(!survey_name=="Sharing Task Experience Survey") %>%
  filter(!value=="") %>%
  mutate(originaldate=as.Date(value),
         survey_type=ifelse(grepl("Sess 1|W[123]S1",survey_name),"Sess 1",
                            ifelse(grepl("Sess 2|W[123]S2",survey_name),"Sess 2",
                                   ifelse(grepl("Parent",survey_name),"Parent",
                                          ifelse(grepl("Home",survey_name),"Home",
                                                 NA))))) %>%
  select(-value,-item) %>%
  # filter(!survey_type=="Parent") %>%
  dplyr::arrange(originaldate)

survey_date<-left_join(survey_startdate,survey_originaldate) %>%
  mutate(value=as.Date(ifelse(is.na(originaldate),startdate,originaldate),origin="1970-01-01 UTC")) %>%
  select(-originaldate,-startdate)

survey_date_sorted <- survey_date %>%
  mutate(tagid_sorted = factor(tagid, levels = unique(tagid[order(value)])))

graph_dates<-ggplot(survey_date_sorted, aes(x=value, y=tagid_sorted, group=tagid)) +
  geom_line(colour="black", alpha=.5) +
  geom_point(aes(colour = survey_type)) +
  scale_x_date(date_breaks = "1 month", date_labels =  "%b %Y") +
  theme_minimal() + 
  theme(axis.text.y=element_blank(),
        axis.text.x = element_text(hjust = 0, angle = 360-45))
graph_dates

timebetween=function(subid){
  tag_id <- as.character(subid)
  start <- strptime((survey_date %>%
                       filter(tagid==tag_id) %>%
                       filter(survey_type=="Sess 1") %>%
                       select(value) %>%
                       arrange(value))[[1]][[1]], format="%Y - %m - %d") 
  if (nrow(survey_date %>%
           filter(tagid==tag_id) %>%
           filter(survey_type=="Sess 2"))>0) {
    end <- strptime((survey_date %>%
                       filter(tagid==tag_id) %>%
                       filter(survey_type=="Sess 2") %>%
                       select(value) %>%
                       arrange(desc(value)))[[1]][[1]], format="%Y - %m - %d")
    totaldays<-(end-start)
  } else {
    end <- "NA"
    totaldays<-"NA"
  }
  as.data.frame(cbind(tag_id, totaldays))
}
output.df<-lapply(as.list(unique(survey_date$tagid)),timebetween) ##NV: NOT WORKING, BUT SEEMINGLY ONLY RELEVANT FOR PLOTTING TIME DIFFERENCE
output.df<-as.data.frame(do.call(rbind,output.df)) %>% 
  mutate(totaldays=round(as.numeric(levels(totaldays))[totaldays]),0)
time_between <- ggplot(output.df,
                       aes(x=tag_id, y=totaldays, fill=totaldays))
time_between + geom_bar(colour="black", stat="identity")

rm(time_between,graph_dates)
```

Prepare NDAR template
```{r}
#2018-09-14
# Info on correspondences should be in REDCap. If not, here's some more info:
# It is easier, and better for the NIH system if we keep a record of the correspondence between anonymized TAG ID and
# the NIH GUID or (especially) the pseudo-GUID. If the participant actually has all the correct 
# info: First, last, middle name; date of birth; city of birth; and sex; and if they already have a 
# GUID, we can just use that. If it becomes apparent that they have a mistaken GUID (because last time their
# city of birth was listed as NA which was erroneously used) then we need to email NDAHelp@mail.nih.gov.
# This happened to me, which is why it's probably important to check current participant info against older
# participant info in the confidential folder. We still don't have complete info for each participant meaning
# we could still get updates too.
#
# It is also possible that someone who didn't have complete info now has complete info. If they did not have complete
# info before, we uploaded data using a pseudo-GUID. We can now get a full GUID and promote the pseudo-GUID (see 
# https://data-archive.nimh.nih.gov/guid). 
#
# If we've used a pseudo-GUID in the past, it's important that we use the same one. This is why I started keeping
# track in the csv below of who has what GUID or pseudo-GUID. 
#
# Anyone without an existing GUID or pseudo-GUID, and who you are not able to generate a new GUID for just gets
# a pseudo-GUID which does not depend on their personal information (assign it arbitrarily).
#
# What NIH does check is whether the uploaded src_subject_id and NDAR subjectkey pair for the current upload matches
# the pair from the previous upload. If it does not, it throws an error.
#
# There are three correspondences you need to be aware of:
# 1) TAG ID in redcap to anonymized TAG ID in the TAG_RDoC_key.csv file
# 2) TAG ID in redcap to "ID" column in GUID_batch_subIDkey_*.csv file
# 3) "ID" column in the GUID_batch_*.csv files and the number in the output_guid_*.txt file, which also contains 
#    the NDAR GUID or pseudo GUID.
#
# Before running this you must have generated GUIDs for each participant to be uploaded
# Change file names below to match the dates of the actual files you're using

# If you need to read in new GUIDs or pseudo-GUIDs, here's an example:
#
# #read the output from the GUID tool, with added pseudo GUIDs if necessary
# rawGUIDoutput <- readr::read_lines(file.path(workdir,'RDoCdb/confidential/GUID_Batch_201806','guid_w_pguid_1531351660887.txt'))
# rawGUIDoutput_df <- dplyr::data_frame(unparsed = rawGUIDoutput) %>%
#   extract(unparsed, c('ID', 'guid'), '^(\\d+) - (.*)$') %>%
#   mutate(ID = as.numeric(ID))
#   
# # Load the subject key which has the original TAGID, an anonymized ID, and the GUID
# ndar_key_<-left_join(read.csv(file=paste0(workdir,"RDoCdb/confidential/GUID_Batch_201806/GUID_batch_subIDkey_2018-07-11.csv"),stringsAsFactors = FALSE),
#                     read.csv(file=paste0(workdir,"RDoCdb/confidential/TAG_RDoC_key.csv"),stringsAsFactors = FALSE),by="tagid")
# ndar_key <- left_join(ndar_key_, rawGUIDoutput_df, by = 'ID') 

# ndar_key should contain the tagid, anontagid, and the guid columns - find this info on redcap
ndar_key <- readr::read_csv(file.path(workdir,'RDoCdb/confidential/ndar_key.csv'))
# careful below, some code may also expect "ID" column which is just the row number. 
# I dont *think* this column matters, so you can add this by running:
ndar_key$ID <- 1:nrow(ndar_key)

# NDAR requires a constrained answer for a participants "race"
ethnicity_long<-cleaned_survey_data %>%
  filter(grepl("Ethnicity",item)) %>%
  filter(!value=="") %>%
  arrange(tagid) %>%
  select(-survey_name) %>%
  arrange(tagid)

figure_out_ethnicity=function(subid){
  subethnicity<-ethnicity_long %>%
    filter(tagid==as.character(subid)) %>%
    distinct()
  numethnicity<-nrow(subethnicity %>%
                       filter(!item=="Ethnicity_7_TEXT"))
  if (numethnicity<2 & (nrow(subethnicity)==1)){
    race=ifelse(subethnicity$item=="Ethnicity_1","Black or African American",
                ifelse(subethnicity$item=="Ethnicity_2","Unknown or not reported",
                       ifelse(subethnicity$item=="Ethnicity_3","American Indian/Alaska Native",
                              ifelse(subethnicity$item=="Ethnicity_4","White",
                                     ifelse(subethnicity$item=="Ethnicity_5","Asian",
                                            ifelse(subethnicity$item=="Ethnicity_10","Hawaiian or Pacific Islander",
                                                   ifelse(subethnicity$item=="Ethnicity_7",value,
                                                          ifelse(subethnicity$item=="Ethnicity_6","More than one race",
                                                                 ifelse(subethnicity$item=="Ethnicity_8","Unknown or not reported",
                                                                        ifelse(subethnicity$item=="Ethnicity_9","Unknown or not reported",""))))))))))
    cbind(subid,race)
  } else if (numethnicity<2 & (nrow(subethnicity)==2)){
    race=as.character(subethnicity %>%
                        filter(item=="Ethnicity_7_TEXT") %>%
                        select(value))
    cbind(subid,race)
  } else if (numethnicity>1) {
    race="More than one race"
    cbind(subid,race)
  }
}
ndar_ethnicity<-lapply(as.list(unique(ethnicity_long$tagid)),figure_out_ethnicity)
ndar_ethnicity.df<-data.frame(matrix(unlist(ndar_ethnicity), nrow=length(ndar_ethnicity), byrow=T),stringsAsFactors=FALSE)

ndar_race<- ndar_ethnicity.df %>%
  mutate(tagid=.[[1]],
         race=.[[2]]) %>%
  select(tagid, race) %>%
  mutate(race=case_when(
    race=="Asian white" ~ "More than one race",
    race=="Caucasian " ~ "White",
    race=="1/4 Mexican / white" ~ "More than one race",
    race=="Jewish" ~ "Unknown or not reported",
    TRUE ~ race))

#

participants_ndar_data <- redcap_cleaned %>% 
  filter(!is.na(dob),!is.na(sb_date)) %>%
  select(tagid, sa_date, dob) %>%
  arrange(tagid) %>%
  mutate(src_subject_id=tagid,
         interview_date=paste0(sprintf("%02d",month(sa_date)),"/",sprintf("%02d",day(sa_date)),"/",year(sa_date)),
         interview_age=round((interval(start = dob, end = sa_date) / duration(num = 1, units = "months")),0),
         gender="F",
         phenotype="Typical Control",
         phenotype_description="Typical Control",
         twins_study="No",
         sibling_study="No",
         family_study="No",
         sample_taken="Yes",
         sample_id_original="Session1_Saliva",
         sample_description="saliva",
         biorepository_name="NA",
         sample_id_biorepository="NA",
         patient_id_biorepository="NA",
         site="University of Oregon",
         comments_misc="Session1",
         study="UO TAG Study")
participants_ndar_data<-left_join(participants_ndar_data,(ndar_race %>%
                                                            filter(tagid %in% ndar_key$tagid)), by="tagid") %>%
  mutate(race=ifelse(is.na(race),"Unknown or not reported",race))
participants_ndar_data<-left_join(ndar_key,participants_ndar_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  select(-tagid,-sa_date,-dob,-anontagid,-ID,-guid) 

ndar_subject <- as.list(read.csv(paste0(workdir,"RDoCdb/templates/ndar_subject01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
ndar_subject_df<-data.frame(ndar_subject)
ndar_subject_df<-bind_rows(ndar_subject_df,participants_ndar_data)
ndar_subject_df_header<-rep(NA,length(ndar_subject_df))
ndar_subject_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/ndar_subject01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
ndar_subject_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/ndar_subject01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]
part2<-colnames(ndar_subject_df)
part3<-as.matrix(ndar_subject_df)
colnames(part3)<-NULL
together<-rbind(ndar_subject_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/ndar_subject01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(ndar_race,ethnicity_long,ndar_ethnicity,together,part3,part2,ndar_subject_df_header,ndar_subject,ndar_subject_df,ndar_ethnicity.df,participants_ndar_data)
```


Modified Answers
```{r}
mod_df <- read.csv(paste0(workdir, "Questionnaires/Modified_Answers.csv"))

```

Prep for Export
```{r}
redcap_cleaned_dates <- redcap_cleaned
redcap_cleaned$sa_date <- as.character(redcap_cleaned$sa_date)
redcap_cleaned$sb_date <- as.character(redcap_cleaned$sb_date)
redcap_cleaned$dob <- as.character(redcap_cleaned$dob)
```

Prepare BFI-10
```{r}
BFI10<-left_join(filter(cleaned_survey_data, grepl("BFI",item)) %>% 
                   mutate(value=as.numeric(value)) %>% 
                   filter(!is.na(value)) %>% 
                   distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                   spread(item,value),redcap_cleaned %>%
                   filter(!is.na(dob),!is.na(sa_date)) %>%
                   select(tagid, sa_date, sb_date, dob),by="tagid")

BFI10_Wave1<-left_join(BFI10,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>% 
  select(-value) %>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 1 - V4 - Current",sa_date,
                            ifelse(survey_name=="TAG - Sess 1 - V1",sa_date,
                                   ifelse(survey_name=="TAG - Sess 1 - V2",sa_date,
                                          ifelse(survey_name=="TAG - Sess 1 - V3",sa_date,
                                                 ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                                 )))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(BFI_10_1=ifelse(BFI_10_1==1,5,
                         ifelse(BFI_10_1==2,4,
                                ifelse(BFI_10_1==3,3,
                                       ifelse(BFI_10_1==4,2,
                                              ifelse(BFI_10_1==5,1,
                                                     BFI_10_1))))),
         BFI_10_3=ifelse(BFI_10_3==1,5,
                         ifelse(BFI_10_3==2,4,
                                ifelse(BFI_10_3==3,3,
                                       ifelse(BFI_10_3==4,2,
                                              ifelse(BFI_10_3==5,1,
                                                     BFI_10_3))))),
         BFI_10_4=ifelse(BFI_10_4==1,5,
                         ifelse(BFI_10_4==2,4,
                                ifelse(BFI_10_4==3,3,
                                       ifelse(BFI_10_4==4,2,
                                              ifelse(BFI_10_4==5,1,
                                                     BFI_10_4))))),
         BFI_10_5=ifelse(BFI_10_5==1,5,
                         ifelse(BFI_10_5==2,4,
                                ifelse(BFI_10_5==3,3,
                                       ifelse(BFI_10_5==4,2,
                                              ifelse(BFI_10_5==5,1,
                                                     BFI_10_5))))),
         BFI_10_7=ifelse(BFI_10_7==1,5,
                         ifelse(BFI_10_7==2,4,
                                ifelse(BFI_10_7==3,3,
                                       ifelse(BFI_10_7==4,2,
                                              ifelse(BFI_10_7==5,1,
                                                     BFI_10_7)))))) %>%
  mutate(BFI10_extra_N=2,
         BFI10_extra_missing=rowSums(is.na(cbind(BFI_10_1,BFI_10_6))),
         BFI10_extra_missing_perc=100*(rowSums(is.na(cbind(BFI_10_1,BFI_10_6)))/2),
         BFI10_extra_total=rowSums(cbind(BFI_10_1,BFI_10_6), na.rm=F),
         BFI10_extra_mean=rowMeans(cbind(BFI_10_1,BFI_10_6), na.rm=T),
         BFI10_agree_N=2,
         BFI10_agree_missing=rowSums(is.na(cbind(BFI_10_2,BFI_10_7))),
         BFI10_agree_missing_perc=100*(rowSums(is.na(cbind(BFI_10_2,BFI_10_7)))/2),
         BFI10_agree_total=rowSums(cbind(BFI_10_2,BFI_10_7), na.rm=F),
         BFI10_agree_mean=rowMeans(cbind(BFI_10_2,BFI_10_7), na.rm=T),
         BFI10_consc_N=2,
         BFI10_consc_missing=rowSums(is.na(cbind(BFI_10_3,BFI_10_8))),
         BFI10_consc_missing_perc=100*(rowSums(is.na(cbind(BFI_10_3,BFI_10_8)))/2),
         BFI10_consc_total=rowSums(cbind(BFI_10_3,BFI_10_8), na.rm=F),
         BFI10_consc_mean=rowMeans(cbind(BFI_10_3,BFI_10_8), na.rm=T),
         BFI10_neuro_N=2,
         BFI10_neuro_missing=rowSums(is.na(cbind(BFI_10_4,BFI_10_9))),
         BFI10_neuro_missing_perc=100*(rowSums(is.na(cbind(BFI_10_4,BFI_10_9)))/2),
         BFI10_neuro_total=rowSums(cbind(BFI_10_4,BFI_10_9), na.rm=F),
         BFI10_neuro_mean=rowMeans(cbind(BFI_10_4,BFI_10_9), na.rm=T),
         BFI10_open_N=2,
         BFI10_open_missing=rowSums(is.na(cbind(BFI_10_5,BFI_10_10))),
         BFI10_open_missing_perc=100*(rowSums(is.na(cbind(BFI_10_5,BFI_10_10)))/2),
         BFI10_open_total=rowSums(cbind(BFI_10_5,BFI_10_10), na.rm=F),
         BFI10_open_mean=rowMeans(cbind(BFI_10_5,BFI_10_10), na.rm=T))

## Save it
BFI10_Wave1_outdf <- BFI10_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(BFI10_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/BFI10_Wave1.csv"))

BFI10_Wave2_outdf <- BFI10_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(BFI10_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/BFI10_Wave2.csv"))

BFI10_Wave3_outdf <- BFI10_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(BFI10_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/BFI10_Wave3.csv"))

## Graph it
BFI10_Wave1_totals<-BFI10_Wave1 %>%
  select(tagid,BFI10_neuro_total,BFI10_open_total,BFI10_consc_total,BFI10_agree_total,BFI10_extra_total) %>%
  mutate(Neuroticism=BFI10_neuro_total,
         Opennes=BFI10_open_total,
         Conscientiousness=BFI10_consc_total,
         Agreeableness=BFI10_agree_total,
         Extraversion=BFI10_extra_total) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("BFI10",item))
BFI10_Wave1_totals_graph<-ggplot(BFI10_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("BFI Wave1 total for ",length(BFI10_Wave1_totals$tagid[!is.na(BFI10_Wave1_totals$tagid)])," participants"))

BFI10_Wave1_means<-BFI10_Wave1 %>%
  select(tagid,BFI10_neuro_mean,BFI10_open_mean,BFI10_consc_mean,BFI10_agree_mean,BFI10_extra_mean) %>%
  mutate(Neuroticism=BFI10_neuro_mean,
         Opennes=BFI10_open_mean,
         Conscientiousness=BFI10_consc_mean,
         Agreeableness=BFI10_agree_mean,
         Extraversion=BFI10_extra_mean) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("BFI10",item))
BFI10_Wave1_means_graph<-ggplot(BFI10_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3) +
  ggtitle(paste0("BFI Wave1 means for ",length(BFI10_Wave1_means$tagid[!is.na(BFI10_Wave1_means$tagid)])," participants"))

## Make RDOC ready file
ndar_bfi10_data <- left_join(BFI10_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         bfi10_1=BFI_10_1,
         bfi10_2=BFI_10_2,
         bfi10_3=BFI_10_3,
         bfi10_4=BFI_10_4,
         bfi10_5=BFI_10_5,
         bfi10_6=BFI_10_6,
         bfi10_7=BFI_10_7,
         bfi10_8=BFI_10_8,
         bfi10_9=BFI_10_9,
         bfi10_10=BFI_10_10
  )
ndar_bfi10_data <- left_join(ndar_key,ndar_bfi10_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("BFI",ignore.case = FALSE),-dob,-survey_date,-survey_type,-survey_name,-tagid,-anontagid,-ID,-guid)
bfi10_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/bfi1001_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
bfi10_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/bfi1001_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
bfi10_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/bfi1001_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

bfi10_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/bfi1001_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
bfi10_temp_df<-data.frame(bfi10_temp)
ndar_bfi10_data<-bind_rows(bfi10_temp_df,ndar_bfi10_data)

part2<-colnames(ndar_bfi10_data)
part3<-as.matrix(ndar_bfi10_data)
colnames(part3)<-NULL
together<-rbind(bfi10_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/bfi1001.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(BFI10,BFI10_Wave1,BFI10_Wave1_means,BFI10_Wave1_means_graph,BFI10_Wave1_totals,BFI10_Wave1_totals_graph,
   bfi10_df_header,bfi10_temp,bfi10_temp_df,part3,part2,together)
```

Prepare CAMM
```{r}
CAMM<-left_join(filter(cleaned_survey_data, grepl("CAMM",item)) %>% 
                  mutate(value=as.numeric(value)) %>% 
                  filter(!is.na(value)) %>% 
                  distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                  spread(item,value),redcap_cleaned %>%
                  filter(!is.na(dob),!is.na(sa_date)) %>%
                  select(tagid, sa_date, sb_date, dob),by="tagid")

CAMM_Wave1<-left_join(CAMM,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>% 
  select(-value) %>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 1 - V4 - Current",sa_date,
                            ifelse(survey_name=="TAG - Sess 1 - V1",sa_date,
                                   ifelse(survey_name=="TAG - Sess 1 - V2",sa_date,
                                          ifelse(survey_name=="TAG - Sess 1 - V3",sa_date,
                                                 ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                                 )))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(CAMM_1=ifelse(CAMM_1==4,0,
                       ifelse(CAMM_1==3,1,
                              ifelse(CAMM_1==2,2,
                                     ifelse(CAMM_1==1,3,
                                            ifelse(CAMM_1==0,4,
                                                   NA))))),
         CAMM_2=ifelse(CAMM_2==4,0,
                       ifelse(CAMM_2==3,1,
                              ifelse(CAMM_2==2,2,
                                     ifelse(CAMM_2==1,3,
                                            ifelse(CAMM_2==0,4,
                                                   NA))))),
         CAMM_3=ifelse(CAMM_3==4,0,
                       ifelse(CAMM_3==3,1,
                              ifelse(CAMM_3==2,2,
                                     ifelse(CAMM_3==1,3,
                                            ifelse(CAMM_3==0,4,
                                                   NA))))),
         CAMM_4=ifelse(CAMM_4==4,0,
                       ifelse(CAMM_4==3,1,
                              ifelse(CAMM_4==2,2,
                                     ifelse(CAMM_4==1,3,
                                            ifelse(CAMM_4==0,4,
                                                   NA))))),
         CAMM_5=ifelse(CAMM_5==4,0,
                       ifelse(CAMM_5==3,1,
                              ifelse(CAMM_5==2,2,
                                     ifelse(CAMM_5==1,3,
                                            ifelse(CAMM_5==0,4,
                                                   NA))))),
         CAMM_6=ifelse(CAMM_6==4,0,
                       ifelse(CAMM_6==3,1,
                              ifelse(CAMM_6==2,2,
                                     ifelse(CAMM_6==1,3,
                                            ifelse(CAMM_6==0,4,
                                                   NA))))),
         CAMM_7=ifelse(CAMM_7==4,0,
                       ifelse(CAMM_7==3,1,
                              ifelse(CAMM_7==2,2,
                                     ifelse(CAMM_7==1,3,
                                            ifelse(CAMM_7==0,4,
                                                   NA))))),
         CAMM_8=ifelse(CAMM_8==4,0,
                       ifelse(CAMM_8==3,1,
                              ifelse(CAMM_8==2,2,
                                     ifelse(CAMM_8==1,3,
                                            ifelse(CAMM_8==0,4,
                                                   NA))))),
         CAMM_9=ifelse(CAMM_9==4,0,
                       ifelse(CAMM_9==3,1,
                              ifelse(CAMM_9==2,2,
                                     ifelse(CAMM_9==1,3,
                                            ifelse(CAMM_9==0,4,
                                                   NA))))),
         CAMM_10=ifelse(CAMM_10==4,0,
                        ifelse(CAMM_10==3,1,
                               ifelse(CAMM_10==2,2,
                                      ifelse(CAMM_10==1,3,
                                             ifelse(CAMM_10==0,4,
                                                    NA))))))%>%
  mutate(CAMM_N=10,
         CAMM_missing=rowSums(is.na(cbind(CAMM_1,CAMM_2,CAMM_3,CAMM_4,CAMM_5,CAMM_6,CAMM_7,CAMM_8,CAMM_9,CAMM_10))),
         CAMM_missing_perc=100*(rowSums(is.na(cbind(CAMM_1,CAMM_2,CAMM_3,CAMM_4,CAMM_5,CAMM_6,CAMM_7,CAMM_8,CAMM_9,CAMM_10)))/10),
         CAMM_mean=rowMeans(cbind(CAMM_1,CAMM_2,CAMM_3,CAMM_4,CAMM_5,CAMM_6,CAMM_7,CAMM_8,CAMM_9,CAMM_10), na.rm=T),
         CAMM_total=rowSums(cbind(CAMM_1,CAMM_2,CAMM_3,CAMM_4,CAMM_5,CAMM_6,CAMM_7,CAMM_8,CAMM_9,CAMM_10), na.rm=F))

## Save it
CAMM_Wave1_outdf <- CAMM_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(CAMM_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/CAMM_Wave1.csv"))

CAMM_Wave2_outdf <- CAMM_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(CAMM_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/CAMM_Wave2.csv"))

## Graph it
CAMM_Wave1_total_graph<-ggplot(CAMM_Wave1, aes(x=CAMM_total, colour="deeppink")) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Child and Adolescent Mindfulness Wave1 totals for ",length(CAMM_Wave1$CAMM_total[!is.na(CAMM_Wave1$CAMM_total)])," participants"))

CAMM_Wave1_mean_graph<-ggplot(CAMM_Wave1, aes(x=CAMM_mean, colour="deeppink")) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Child and Adolescent Mindfulness Wave1 means for ",length(CAMM_Wave1$CAMM_mean[!is.na(CAMM_Wave1$CAMM_mean)])," participants"))

## Make RDOC ready file
ndar_camm_data <- left_join(CAMM_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         camm_1=CAMM_1,
         camm_2=CAMM_2,
         camm_3=CAMM_3,
         camm_4=CAMM_4,
         camm_5=CAMM_5,
         camm_6=CAMM_6,
         camm_7=CAMM_7,
         camm_8=CAMM_8,
         camm_9=CAMM_9,
         camm_10=CAMM_10,
         camm_tot=CAMM_total
  )
ndar_camm_data <- left_join(ndar_key,ndar_camm_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("CAMM",ignore.case = FALSE),-dob,-survey_date,-survey_type,-survey_name,-tagid,-anontagid,-ID,-guid)
camm_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/camm01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
camm_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/camm01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
camm_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/camm01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

camm_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/camm01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
camm_temp_df<-data.frame(camm_temp)
ndar_camm_data<-bind_rows(camm_temp_df,ndar_camm_data)

part2<-colnames(ndar_camm_data)
part3<-as.matrix(ndar_camm_data)
colnames(part3)<-NULL
together<-rbind(camm_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/camm01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(CAMM,CAMM_Wave1,CAMM_Wave1_mean_graph,CAMM_Wave1_total_graph,
   camm_df_header,camm_temp,camm_temp_df,part3,part2,together)
```

Prepare PDS
```{r}
PDS<-left_join(filter(cleaned_survey_data, grepl("PDS",item)) %>% 
                 mutate(value=as.numeric(value)) %>% 
                 filter(!grepl("Parent",survey_name)) %>%
                 filter(!is.na(value)) %>% 
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

#NV: Load in info about menstruation to update missing PDS_F6
Menstruation <- read.csv(paste0(workdir,'Questionnaires/Puberty/Puberty_Followup/Menstruation.csv'), header=T)

Menstruation <- Menstruation %>%
  select(tagid,menstruation_by_Wave1SB.before.wave.1) %>%
  mutate(w1_Menarche = ifelse(menstruation_by_Wave1SB.before.wave.1=="yes",1,0))
w1_Menarche = as.list(Menstruation %>% filter(w1_Menarche==1) %>% select(tagid) %>% arrange(tagid))
w1_NoMenarche = as.list(Menstruation %>% filter(w1_Menarche==0) %>% select(tagid) %>% arrange(tagid))

#NV: Update missing PDS_F6 in PDS dataframe with info on menstruation collected by other methods 
PDS <- PDS %>%
  mutate(PDS_F6 = ifelse((!grepl("W2|W3",survey_name) & is.na(PDS_F6) & (tagid %in% w1_Menarche$tagid)), 1, 
                         ifelse((!grepl("W2|W3",survey_name) & is.na(PDS_F6) & (tagid %in% w1_NoMenarche$tagid)), 0,
                                PDS_F6)))
                         
PDS_Wave1<-left_join(PDS,survey_date, by = c("tagid","survey_name")) %>% #NV: This dataframe is called PDS_W1, but it doesn't seem to be filtering W1 alone). However, I'm not editing this as it seems like the same dataframe is being used for the RDoC submission below.l
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>% 
  select(-value) %>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(peta=PDS_F1,
         petb=PDS_F2,
         petc=PDS_F3,
         petd=PDS_F4,
         pete=PDS_F5,
         fpete=PDS_F6,
         petaf=ifelse(PDS_F1==1,1,
                      ifelse(PDS_F1==2,2,
                             ifelse(PDS_F1==3,3,
                                    ifelse(PDS_F1==4,5,
                                           NA)))),
         petbf=ifelse(PDS_F2==1,1,
                      ifelse(PDS_F2==2,2,
                             ifelse(PDS_F2==3,4,
                                    ifelse(PDS_F2==4,5,
                                           NA)))),
         petcf=ifelse(PDS_F3==1,1,
                      ifelse(PDS_F3==2,2,
                             ifelse(PDS_F3==3,4,
                                    ifelse(PDS_F3==4,5,
                                           NA)))),
         petdf=ifelse(PDS_F4==1,1,
                      ifelse(PDS_F4==2,3,
                             ifelse(PDS_F4==3,4,
                                    ifelse(PDS_F4==4,5,
                                           NA)))),         
         petef=ifelse(PDS_F6==0,1,
                      ifelse(PDS_F6==1,5,
                             NA))) %>%
  mutate(adrenf=rowMeans(cbind(petbf,petcf),na.rm=F)) %>%
  mutate(adrenf2=ifelse(adrenf==1,1,
                        ifelse(petb==1 & adrenf==1.5,1,
                               ifelse(petb==2 & adrenf==1.5,2,
                                      ifelse(adrenf==2,2,
                                             ifelse(adrenf==2.5,3,
                                                    ifelse(adrenf==3,3,
                                                           ifelse(adrenf==3.5,4,
                                                                  ifelse(adrenf==4,4,
                                                                         ifelse(adrenf==4.5,5,
                                                                                ifelse(adrenf==5,5,
                                                                                       NA))))))))))) %>%
  mutate(gonadf=rowMeans(cbind(petaf,petdf),na.rm=F)) %>%
  mutate(gonadf2=ifelse(gonadf==1 & petef==1,1,
                        ifelse(gonadf==1.5 & petef==1,1,
                               ifelse(gonadf==2 & petef==1,2,
                                      ifelse(gonadf==2.5 & petef==1,2,
                                             ifelse(gonadf==3 & petef==1,3,
                                                    ifelse(gonadf==3.5 & petef==1,3,
                                                           ifelse(gonadf==4 & petef==1,3,
                                                                  ifelse(gonadf==4.5 & petef==1,4,
                                                                         ifelse(gonadf==5 & petef==1,4,
                                                                                ifelse(gonadf==1 & petef==5,2,
                                                                                       ifelse(gonadf==1.5 & petef==5,3,
                                                                                              ifelse(gonadf==2 & petef==5,4,
                                                                                                     ifelse(gonadf==2.5 & petef==5,4,
                                                                                                            ifelse(gonadf==3 & petef==5,4,
                                                                                                                   ifelse(gonadf==3.5 & petef==5,5,
                                                                                                                          ifelse(gonadf==4 & petef==5,5,
                                                                                                                                 ifelse(gonadf==4.5 & petef==5,5,
                                                                                                                                        ifelse(gonadf==5 & petef==5,5,
                                                                                                                                               NA))))))))))))))))))) %>%
  mutate(pdss=rowMeans(cbind(adrenf2,gonadf2),na.rm=F),
         pdss_N=5,
         pdss_missing=rowSums(is.na(cbind(PDS_F1,PDS_F2,PDS_F3,PDS_F4,PDS_F6))),
         pdss_missing_perc=100*(rowSums(is.na(cbind(PDS_F1,PDS_F2,PDS_F3,PDS_F4,PDS_F6)))/5),
         adrenf2_N=2,
         adrenf2_missing=rowSums(is.na(cbind(PDS_F2,PDS_F3))),
         adrenf2_missing_perc=100*(rowSums(is.na(cbind(PDS_F2,PDS_F3)))/2),
         gonadf2_N=3,
         gonadf2_missing=rowSums(is.na(cbind(PDS_F1,PDS_F4,PDS_F6))),
         gonadf2_missing_perc=100*(rowSums(is.na(cbind(PDS_F1,PDS_F4,PDS_F6)))/3),
         ) #NV added perc missing

## Save it
PDS_Wave1_outdf <- PDS_Wave1 %>% filter(!grepl("W2|W3",survey_name)) #NV: given comment above, I'm now saving another filtered PDS_wave1 document for saving output.
write.csv(PDS_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/PDS_Wave1.csv"))

PDS_Wave2_outdf <- PDS_Wave1 %>% filter(grepl("W2",survey_name))
write.csv(PDS_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/PDS_Wave2.csv"))

## Graph it
PDS_Wave1_pdss_graph<-ggplot(PDS_Wave1, aes(x=pdss, colour="deeppink")) +
  geom_density(alpha=.3)+
  ggtitle(paste0("PDSS scores for ",length(PDS_Wave1$pdss[!is.na(PDS_Wave1$pdss)])," Wave 1 participants"))

options(scipen=999)
PDS_withage<-(left_join(PDS_Wave1,redcap_cleaned,by="tagid") %>%
                filter(!is.na(survey_date),!survey_date=="")%>%
                mutate(age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "years")),2)))
PDS_Wave1_pdss_by_age_graph<-ggplot(PDS_withage, aes(x=age,y=pdss)) +
  geom_point(show.legend = FALSE)+
  ggtitle(paste0("PDSS by age for ",length(PDS_withage$pdss[!is.na(PDS_withage$pdss)])," Wave 1 participants. r = ",
                 round(cor.test(PDS_withage$age,PDS_withage$pdss,use=na.or.complete)[[4]],3)," p = ",
                 cor.test(PDS_withage$age,PDS_withage$pdss,use=na.or.complete)[[3]]))

## Make RDOC ready file
ndar_pds_data <- left_join(PDS_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         comments_misc=ifelse(grepl("Sess 1",survey_name),"Session1",
                              ifelse(grepl("Session 1",survey_name),"Session1",
                                     ifelse(grepl("Sess 2",survey_name),"Session2",
                                            ifelse(grepl("Session 2",survey_name),"Session2",
                                                   ifelse(grepl("Home",survey_name),"Home Questionnaires",NA))))),
         gender="F",
         respond=3,
         pds_1=PDS_F1,
         pds_2=PDS_F2,
         pds_3=PDS_F3,
         pds_6=PDS_F4,
         pds6g=PDS_F6,
         pds_7b_pv=PDS_F5,
         pds_girl_rs=999
  )

anthro$anthro_doc <- as.character.Date(anthro$anthro_doc, format = "%m/%d/%Y")

ndar_pds_data <- left_join(ndar_pds_data,anthro %>% select(tagid,weight,height,anthro_doc), by=c("tagid" = "tagid", "interview_date" = "anthro_doc")) %>%
  mutate(height_std=height,
         weight_std=weight)
ndar_pds_data <- left_join(ndar_key,ndar_pds_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("PDS",ignore.case = FALSE),-dob,-survey_date,-survey_type,-survey_name,-tagid,-anontagid,-ID,-guid,
         -contains("pet"),-contains("adren"),-contains("gonad"),-weight,-height,-contains("pdss", ignore.case = FALSE))
pds_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/pds01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
pds_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/pds01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
pds_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/pds01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

pds_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/pds01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
pds_temp_df<-data.frame(pds_temp)
ndar_pds_data<-bind_rows(pds_temp_df,ndar_pds_data)

part2<-colnames(ndar_pds_data)
part3<-as.matrix(ndar_pds_data)
colnames(part3)<-NULL
together<-rbind(pds_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/pds01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(pds_temp_df,pds_temp,pds_df_header,PDS_Wave1_pdss_by_age_graph,PDS_withage,PDS_Wave1_pdss_graph,
   PDS_Wave1,PDS)
```

Prepare PBIP
```{r}
PBIP<-left_join(filter(cleaned_survey_data, grepl("PBIP",item)) %>% 
                  mutate(value=as.numeric(value)) %>%
                  filter(!is.na(value)) %>% 
                  distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                  spread(item,value),
                redcap_cleaned %>%
                  filter(!is.na(dob),!is.na(sa_date)) %>%
                  select(tagid, sa_date, sb_date, dob),by="tagid")

PBIP_Wave1<-left_join(PBIP,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>% 
  select(-value) %>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob,-PBIP_1_Drawing,-PBIP_1_Question,-PBIP_2_Question,-PBIP_2_Drawing) %>%
  mutate(stage=rowMeans(cbind(PBIP_1A,PBIP_2A),na.rm=F), #NV: changed na.rm to False from True. Also removed filtering of those with missing stage.
         PBIP_stage_N=2,
         PBIP_stage_missing=rowSums(is.na(cbind(PBIP_1A,PBIP_2A))),
         PBIP_stage_missing_perc=100*(rowSums(is.na(cbind(PBIP_1A,PBIP_2A)))/2))  

## Save it
PBIP_Wave1_outdf <- PBIP_Wave1 %>% filter(!grepl("W2|W3",survey_name)) #NV: Same comment as PDS re filtering to wave 1.
write.csv(PBIP_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/PBIP_Wave1.csv"))

PBIP_Wave2_outdf <- PBIP_Wave1 %>% filter(grepl("W2",survey_name))
write.csv(PBIP_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/PBIP_Wave2.csv"))

## Graph it
PBIP_Wave1_pbip_graph<-ggplot(PBIP_Wave1, aes(x=stage, colour="deeppink")) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Tanner stage for ",length(PBIP_Wave1$stage[!is.na(PBIP_Wave1$stage)])," Wave 1 participants"))

options(scipen=999)
PBIP_PDS_Wave1<-left_join(PBIP_Wave1,read.csv(paste0(workdir,"Questionnaires/Wave1/PDS_Wave1.csv"),header=TRUE,stringsAsFactors = FALSE))
PBIP_Wave1_pbip_by_pds_graph<-ggplot(PBIP_PDS_Wave1, aes(x=pdss,y=stage)) +
  geom_point(show.legend = FALSE)+
  ggtitle(paste0("PDSS by age for ",length(PBIP_PDS_Wave1$stage[!is.na(PBIP_PDS_Wave1$stage)])," Wave 1 participants. r = ",
                 round(cor.test(PBIP_PDS_Wave1$stage,PBIP_PDS_Wave1$pdss,use=na.or.complete)[[4]],3)," p = ",
                 cor.test(PBIP_PDS_Wave1$stage,PBIP_PDS_Wave1$pdss,use=na.or.complete)[[3]]))

## Make RDOC ready file
ndar_pbip_data <- left_join(PBIP_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         site="University of Oregon, USA",
         tsmfemale=as.integer(stage),
         tsmmale=9999,
         tsmboth=9,
         tsftsg=PBIP_1A,
         tsftphg=PBIP_2A
  )
ndar_pbip_data <- left_join(ndar_key,ndar_pbip_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("PBIP",ignore.case = FALSE),-stage,-dob,-survey_date,-survey_type,-survey_name,-tagid,-anontagid,-ID,-guid)
pbip_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/tanner_sms01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
pbip_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/tanner_sms01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
pbip_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/tanner_sms01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

pbip_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/tanner_sms01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
pbip_temp_df<-data.frame(pbip_temp)
ndar_pbip_data<-bind_rows(pbip_temp_df,ndar_pbip_data)

part2<-colnames(ndar_pbip_data)
part3<-as.matrix(ndar_pbip_data)
colnames(part3)<-NULL
together<-rbind(pbip_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/tanner_sms01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(pbip_temp_df,pbip_temp,pbip_df_header,PBIP_Wave1_pbip_by_pds_graph,PBIP_PDS_Wave1,
   PBIP_Wave1_pbip_graph,PBIP_Wave1,PBIP,part3,part2,together)
```

Prepare CARE-R Soc
```{r}
CARE_R_SOC<-left_join(filter(cleaned_survey_data, grepl("CARE_R",item)) %>% 
                        mutate(value=as.numeric(value)) %>% 
                        filter(!is.na(value)) %>% 
                        distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                        spread(item,value),redcap_cleaned %>%
                        filter(!is.na(dob),!is.na(sa_date)) %>%
                        select(tagid, sa_date, sb_date, dob),by="tagid")

CARE_R_SOC_Wave1<-left_join(CARE_R_SOC,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>% 
  select(-value) %>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(carersoc_gen_N=2,
         carersoc_gen_missing=rowSums(is.na(cbind(CARE_R_I,CARE_R_II))),
         carersoc_gen_missing_perc=100*(rowSums(is.na(cbind(CARE_R_I,CARE_R_II)))/2),
         carersoc_gen=rowMeans(cbind(CARE_R_I,CARE_R_II),na.rm=T),
         carersoc_dosubstance_N=4,
         carersoc_dosubstance_missing=rowSums(is.na(cbind(CARE_R_2A,CARE_R_3A,CARE_R_4A,CARE_R_5A))), #NV: should CARE_R_1A be in her e too?
         carersoc_dosubstance_missing_perc=100*(rowSums(is.na(cbind(CARE_R_2A,CARE_R_3A,CARE_R_4A,CARE_R_5A)))/4),
         carersoc_dosubstance=round(rowMeans(cbind(CARE_R_2A,CARE_R_3A,CARE_R_4A,CARE_R_5A),na.rm=T),2),
         carersoc_avoidsubstance_N=4,
         carersoc_avoidsubstance_missing=rowSums(is.na(cbind(CARE_R_2B,CARE_R_3B,CARE_R_4B,CARE_R_5B))),
         carersoc_avoidsubstance_missing_perc=100*(rowSums(is.na(cbind(CARE_R_2B,CARE_R_3B,CARE_R_4B,CARE_R_5B)))/4),
         carersoc_avoidsubstance=round(rowMeans(cbind(CARE_R_2B,CARE_R_3B,CARE_R_4B,CARE_R_5B),na.rm=T),2),
         carersoc_doviolence_N=4,
         carersoc_doviolence_missing=rowSums(is.na(cbind(CARE_R_7A,CARE_R_9A,CARE_R_10A,CARE_R_11A))),
         carersoc_doviolence_missing_perc=100*(rowSums(is.na(cbind(CARE_R_7A,CARE_R_9A,CARE_R_10A,CARE_R_11A)))/4),
         carersoc_doviolence=round(rowMeans(cbind(CARE_R_7A,CARE_R_9A,CARE_R_10A,CARE_R_11A),na.rm=T),2),
         carersoc_avoidviolence_N=4,
         carersoc_avoidviolence_missing=rowSums(is.na(cbind(CARE_R_7B,CARE_R_9B,CARE_R_10B,CARE_R_11B))),
         carersoc_avoidviolence_missing_perc=100*(rowSums(is.na(cbind(CARE_R_7B,CARE_R_9B,CARE_R_10B,CARE_R_11B)))/4),
         carersoc_avoidviolence=round(rowMeans(cbind(CARE_R_7B,CARE_R_9B,CARE_R_10B,CARE_R_11B),na.rm=T),2),
         carersoc_dorecklessdriving_N=4,
         carersoc_dorecklessdriving_missing=rowSums(is.na(cbind(CARE_R_6A,CARE_R_12A,CARE_R_13A,CARE_R_14A))),
         carersoc_dorecklessdriving_missing_perc=100*(rowSums(is.na(cbind(CARE_R_6A,CARE_R_12A,CARE_R_13A,CARE_R_14A)))/4),
         carersoc_dorecklessdriving=round(rowMeans(cbind(CARE_R_6A,CARE_R_12A,CARE_R_13A,CARE_R_14A),na.rm=T),2),
         carersoc_avoidrecklessdriving_N=4,
         carersoc_avoidrecklessdriving_missing=rowSums(is.na(cbind(CARE_R_6B,CARE_R_12B,CARE_R_13B,CARE_R_14B))),
         carersoc_avoidrecklessdriving_missing_perc=100*(rowSums(is.na(cbind(CARE_R_6B,CARE_R_12B,CARE_R_13B,CARE_R_14B)))/4),
         carersoc_avoidrecklessdriving=round(rowMeans(cbind(CARE_R_6B,CARE_R_12B,CARE_R_13B,CARE_R_14B),na.rm=T),2),
         carersoc_dograffiti_N=1,
         carersoc_dograffiti_missing=rowSums(is.na(cbind(CARE_R_8A))),
         carersoc_dograffiti_missing_perc=100*(rowSums(is.na(cbind(CARE_R_8A)))/1),
         carersoc_dograffiti=CARE_R_8A,
         carersoc_avoidgraffiti_N=1,
         carersoc_avoidgraffiti_missing=rowSums(is.na(cbind(CARE_R_8B))),
         carersoc_avoidgraffiti_missing_perc=100*(rowSums(is.na(cbind(CARE_R_8B)))/1),
         carersoc_avoidgraffiti=CARE_R_8B)  

## Save it
CARE_R_SOC_Wave1_outdf <- CARE_R_SOC_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(CARE_R_SOC_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/CARE_R_SOC_Wave1.csv"))

CARE_R_SOC_Wave2_outdf <- CARE_R_SOC_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(CARE_R_SOC_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/CARE_R_SOC_Wave2.csv"))

## Graph it
CARE_R_SOC_Wave1_DO<-CARE_R_SOC_Wave1 %>%
  select(tagid,carersoc_gen,carersoc_dograffiti,carersoc_dosubstance,carersoc_doviolence,carersoc_dorecklessdriving) %>%
  mutate(General_Social_Care=carersoc_gen,
         Graffiti=carersoc_dograffiti,
         Substances=carersoc_dosubstance,
         Violence=carersoc_doviolence,
         Reckless_Driving=carersoc_dorecklessdriving) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("carersoc_",item))
CARE_R_SOC_Wave1_DO_graph<-ggplot(CARE_R_SOC_Wave1_DO, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("CARE-R Social Wave1: Doing these things would make people 1: like me a lot less to 5: like me a lot more. N= ",length(CARE_R_SOC_Wave1_DO$tagid[!is.na(CARE_R_SOC_Wave1_DO$tagid)])," participants"))

CARE_R_SOC_Wave1_DONT<-CARE_R_SOC_Wave1 %>%
  select(tagid,carersoc_gen,carersoc_avoidgraffiti,carersoc_avoidsubstance,carersoc_avoidviolence,carersoc_avoidrecklessdriving) %>%
  mutate(General_Social_Care=carersoc_gen,
         Graffiti=carersoc_avoidgraffiti,
         Substances=carersoc_avoidsubstance,
         Violence=carersoc_avoidviolence,
         Reckless_Driving=carersoc_avoidrecklessdriving) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("carersoc_",item))
CARE_R_SOC_Wave1_DONT_graph<-ggplot(CARE_R_SOC_Wave1_DONT, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("CARE-R Social Wave1: NOT doing these things would make people 1: like me a lot less to 5: like me a lot more. N= ",length(CARE_R_SOC_Wave1_DONT$tagid[!is.na(CARE_R_SOC_Wave1_DONT$tagid)])," participants"))


## Make RDOC ready file
ndar_carersoc_data <- left_join(CARE_R_SOC_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         version_form="CARE-R Social Outcome Appraisal Questions",
         comments_misc=ifelse(grepl("Sess 1",survey_name),"Session1",
                              ifelse(grepl("Session 1",survey_name),"Session1",
                                     ifelse(grepl("Sess 2",survey_name),"Session2",
                                            ifelse(grepl("Session 2",survey_name),"Session2",
                                                   ifelse(grepl("Home",survey_name),"Home Questionnaires",NA))))),
         gender="F",
         carersoc_1=CARE_R_I,
         carersoc_2=CARE_R_II,
         carersoc_3=CARE_R_1A,
         carersoc_4=CARE_R_1B,
         carersoc_5=CARE_R_2A,
         carersoc_6=CARE_R_2B,
         carersoc_7=CARE_R_3A,
         carersoc_8=CARE_R_3B,
         carersoc_9=CARE_R_4A,
         carersoc_10=CARE_R_4B,
         carersoc_11=CARE_R_5A,
         carersoc_12=CARE_R_5B,
         carersoc_13=CARE_R_6A,
         carersoc_14=CARE_R_6B,
         carersoc_15=CARE_R_7A,
         carersoc_16=CARE_R_7B,
         carersoc_17=CARE_R_8A,
         carersoc_18=CARE_R_8B,
         carersoc_19=CARE_R_9A,
         carersoc_20=CARE_R_9B,
         carersoc_21=CARE_R_10A,
         carersoc_22=CARE_R_10B,
         carersoc_23=CARE_R_11A,
         carersoc_24=CARE_R_11B,
         carersoc_25=CARE_R_12A,
         carersoc_26=CARE_R_12B,
         carersoc_27=CARE_R_13A,
         carersoc_28=CARE_R_13B,
         carersoc_29=CARE_R_14A,
         carersoc_30=CARE_R_14B
  )
ndar_carersoc_data <- left_join(ndar_key,ndar_carersoc_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("CARE_R",ignore.case = FALSE),-dob,-survey_date,-survey_type,-survey_name,-tagid,-anontagid,-ID,-guid,
         -contains("substance"),-carersoc_gen,-contains("violence"),-contains("graffiti"),-contains("reckless"), 
         -carersoc_gen_N,-carersoc_gen_missing, -carersoc_gen_missing_perc)
carersoc_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/caore01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
carersoc_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/caore01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
carersoc_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/caore01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

carersoc_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/caore01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
carersoc_temp_df<-data.frame(carersoc_temp)
ndar_carersoc_data<-bind_rows(carersoc_temp_df,ndar_carersoc_data)

part2<-colnames(ndar_carersoc_data)
part3<-as.matrix(ndar_carersoc_data)
colnames(part3)<-NULL
together<-rbind(carersoc_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/caore01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,carersoc_df_header,carersoc_temp,carersoc_temp_df,CARE_R_SOC,CARE_R_SOC_Wave1,CARE_R_SOC_Wave1_DO,
   CARE_R_SOC_Wave1_DO_graph,CARE_R_SOC_Wave1_DONT_graph,CARE_R_SOC_Wave1_DONT)
```

Prepare CES-DC 
```{r}
CESDC<-left_join(filter(cleaned_survey_data, grepl("CES_DC",item)) %>% 
                   mutate(value=as.numeric(value)) %>% 
                   filter(!is.na(value)) %>% 
                   distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                   spread(item,value),redcap_cleaned %>%
                   filter(!is.na(dob),!is.na(sa_date)) %>%
                   select(tagid, sa_date, sb_date, dob),by="tagid")

CESDC_Wave1<-left_join(CESDC,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>% 
  select(-value) %>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(CES_DC_4=ifelse(CES_DC_4==0,3,
                         ifelse(CES_DC_4==1,2,
                                ifelse(CES_DC_4==2,1,
                                       ifelse(CES_DC_4==3,0,
                                              NA)))),
         CES_DC_8=ifelse(CES_DC_8==0,3,
                         ifelse(CES_DC_8==1,2,
                                ifelse(CES_DC_8==2,1,
                                       ifelse(CES_DC_8==3,0,
                                              NA)))),
         CES_DC_12=ifelse(CES_DC_12==0,3,
                          ifelse(CES_DC_12==1,2,
                                 ifelse(CES_DC_12==2,1,
                                        ifelse(CES_DC_12==3,0,
                                               NA)))),
         CES_DC_16=ifelse(CES_DC_16==0,3,
                          ifelse(CES_DC_16==1,2,
                                 ifelse(CES_DC_16==2,1,
                                        ifelse(CES_DC_16==3,0,
                                               NA))))) %>%
  mutate(
    CES_DC_C=20,
    CES_DC_missing=rowSums(is.na(cbind(CES_DC_1,CES_DC_2,CES_DC_3,CES_DC_4,CES_DC_5,CES_DC_6,CES_DC_7,CES_DC_8,CES_DC_9,CES_DC_10,CES_DC_11,CES_DC_12,CES_DC_13,CES_DC_14,CES_DC_15,CES_DC_16,CES_DC_17,CES_DC_18,CES_DC_19,CES_DC_20))),
    CES_DC_missing_perc=100*(rowSums(is.na(cbind(CES_DC_1,CES_DC_2,CES_DC_3,CES_DC_4,CES_DC_5,CES_DC_6,CES_DC_7,CES_DC_8,CES_DC_9,CES_DC_10,CES_DC_11,CES_DC_12,CES_DC_13,CES_DC_14,CES_DC_15,CES_DC_16,CES_DC_17,CES_DC_18,CES_DC_19,CES_DC_20)))/20),
    CES_DC_mean=rowMeans(cbind(CES_DC_1,CES_DC_2,CES_DC_3,CES_DC_4,CES_DC_5,CES_DC_6,CES_DC_7,CES_DC_8,CES_DC_9,CES_DC_10,CES_DC_11,CES_DC_12,CES_DC_13,CES_DC_14,CES_DC_15,CES_DC_16,CES_DC_17,CES_DC_18,CES_DC_19,CES_DC_20), na.rm=T),
    CES_DC_total=rowSums(cbind(CES_DC_1,CES_DC_2,CES_DC_3,CES_DC_4,CES_DC_5,CES_DC_6,CES_DC_7,CES_DC_8,CES_DC_9,CES_DC_10,CES_DC_11,CES_DC_12,CES_DC_13,CES_DC_14,CES_DC_15,CES_DC_16,CES_DC_17,CES_DC_18,CES_DC_19,CES_DC_20), na.rm=F)) %>%
  mutate(CES_DC_total_75perc=ifelse(CES_DC_missing_perc <= 25,CES_DC_mean*20,NA))

## Save it
CESDC_Wave1_outdf <- CESDC_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(CESDC_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/CESDC_Wave1.csv"))

CESDC_Wave2_outdf <- CESDC_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(CESDC_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/CESDC_Wave2.csv"))

## Graph it
CESDC_Wave1_totals_graph<-ggplot(CESDC_Wave1, aes(x=CES_DC_total, colour="deeppink")) +
  geom_density(alpha=.3,show.legend = FALSE)+
  ggtitle(paste0("CESD-C total scores for ",length(CESDC_Wave1$CES_DC_total[!is.na(CESDC_Wave1$CES_DC_total)])," Wave 1 participants"))

CESDC_Wave1_means_graph<-ggplot(CESDC_Wave1, aes(x=CES_DC_mean, colour="dodgerblue")) +
  geom_density(alpha=.3, show.legend = FALSE)+
  ggtitle(paste0("CESD-C mean scores for ",length(CESDC_Wave1$CES_DC_mean[!is.na(CESDC_Wave1$CES_DC_mean)])," Wave 1 participants"))

## Make RDOC ready file
ndar_cesdc_data <- left_join(CESDC_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         version_form="Child version (CES-DC)",
         comments_misc=ifelse(grepl("Sess 1",survey_name),"Session1",
                              ifelse(grepl("Session 1",survey_name),"Session1",
                                     ifelse(grepl("Sess 2",survey_name),"Session2",
                                            ifelse(grepl("Session 2",survey_name),"Session2",
                                                   ifelse(grepl("Home",survey_name),"Home Questionnaires",NA))))),
         gender="F",bothered_by_things=CES_DC_1,
         appetite_poor=CES_DC_2,
         couldnt_shake_blues=CES_DC_3,
         just_as_good_people=CES_DC_4,
         trouble_keeping_mind=CES_DC_5,
         felt_depressed=CES_DC_6,
         everything_effort=CES_DC_7,
         hopeful_future=CES_DC_8,
         failure_life=CES_DC_9,
         fearful=CES_DC_10,
         sleep_restless=CES_DC_11,
         happy=CES_DC_12,
         talked_less_usual=CES_DC_13,
         felt_lonely=CES_DC_14,
         people_unfriendly=CES_DC_15,
         enjoyed_life=CES_DC_16,
         crying_spells=CES_DC_17,
         felt_sad=CES_DC_18,
         felt_people_dislike_me=CES_DC_19,
         couldnt_get_going=CES_DC_20,
         rarely_none_total=999,
         occasionally_total=999,
         some_little_total=999,
         most_time_total=999,
         cesd_score=ifelse(!is.na(CES_DC_total),CES_DC_total,"999"))

ndar_cesdc_data <- left_join(ndar_key,ndar_cesdc_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("CES",ignore.case = FALSE),-dob,-survey_date,-survey_type,-survey_name,-tagid,-anontagid,-ID,-guid)
cesdc_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/ces_d01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
cesdc_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/ces_d01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
cesdc_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/ces_d01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

cesdc_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/ces_d01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
cesdc_temp_df<-data.frame(cesdc_temp)
ndar_cesdc_data<-bind_rows(cesdc_temp_df,ndar_cesdc_data)

part2<-colnames(ndar_cesdc_data)
part3<-as.matrix(ndar_cesdc_data)
colnames(part3)<-NULL
together<-rbind(cesdc_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/ces_d01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,cesdc_df_header,cesdc_temp,cesdc_temp_df,CESDC,CESDC_Wave1,CESDC_Wave1_means_graph,CESDC_Wave1_totals_graph)
```

Prepare CRQ
```{r}
CRQ<-left_join(filter(cleaned_survey_data, grepl("CRQ",item)) %>% 
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>% 
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                 spread(item,value),redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

CRQ_Wave1<-left_join(CRQ,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>% 
  select(-value) %>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 1 - V2",sa_date,
                                   ifelse(survey_name=="TAG - Sess 1 - V4 - Current",sa_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(CRQ_N=27,
         CRQ_missing=rowSums(is.na(cbind(CRQ_1,CRQ_2,CRQ_3,CRQ_4,CRQ_5,CRQ_6,CRQ_7,CRQ_8,CRQ_9,CRQ_10,CRQ_11,CRQ_12,CRQ_13,CRQ_14,CRQ_15,CRQ_16,CRQ_17,CRQ_18,CRQ_19,CRQ_20,CRQ_21,CRQ_22,CRQ_23,CRQ_24,CRQ_25,CRQ_26,CRQ_27))),
         CRQ_missing_perc=100*(rowSums(is.na(cbind(CRQ_1,CRQ_2,CRQ_3,CRQ_4,CRQ_5,CRQ_6,CRQ_7,CRQ_8,CRQ_9,CRQ_10,CRQ_11,CRQ_12,CRQ_13,CRQ_14,CRQ_15,CRQ_16,CRQ_17,CRQ_18,CRQ_19,CRQ_20,CRQ_21,CRQ_22,CRQ_23,CRQ_24,CRQ_25,CRQ_26,CRQ_27)))/27),
         CRQ_mean=rowMeans(cbind(CRQ_1,CRQ_2,CRQ_3,CRQ_4,CRQ_5,CRQ_6,CRQ_7,CRQ_8,CRQ_9,CRQ_10,CRQ_11,CRQ_12,CRQ_13,CRQ_14,CRQ_15,CRQ_16,CRQ_17,CRQ_18,CRQ_19,CRQ_20,CRQ_21,CRQ_22,CRQ_23,CRQ_24,CRQ_25,CRQ_26,CRQ_27),na.rm=T),
         CRQ_total=rowSums(cbind(CRQ_1,CRQ_2,CRQ_3,CRQ_4,CRQ_5,CRQ_6,CRQ_7,CRQ_8,CRQ_9,CRQ_10,CRQ_11,CRQ_12,CRQ_13,CRQ_14,CRQ_15,CRQ_16,CRQ_17,CRQ_18,CRQ_19,CRQ_20,CRQ_21,CRQ_22,CRQ_23,CRQ_24,CRQ_25,CRQ_26,CRQ_27), na.rm=F),
         CRQ_rehashing_total=rowSums(cbind(CRQ_13,CRQ_14,CRQ_15,CRQ_16,CRQ_17,CRQ_18,CRQ_19,CRQ_20,CRQ_21,CRQ_22,CRQ_23,CRQ_24,CRQ_25,CRQ_26,CRQ_27), na.rm=F),
         CRQ_rehashing_mean=round(rowMeans(cbind(CRQ_13,CRQ_14,CRQ_15,CRQ_16,CRQ_17,CRQ_18,CRQ_19,CRQ_20,CRQ_21,CRQ_22,CRQ_23,CRQ_24,CRQ_25,CRQ_26,CRQ_27), na.rm=T),3),
         CRQ_mulling_total=rowSums(cbind(CRQ_3,CRQ_4,CRQ_7,CRQ_8,CRQ_9,CRQ_11,CRQ_12), na.rm=F),
         CRQ_mulling_mean=round(rowMeans(cbind(CRQ_3,CRQ_4,CRQ_7,CRQ_8,CRQ_9,CRQ_11,CRQ_12), na.rm=T),3),
         CRQ_problemtalk_total=rowSums(cbind(CRQ_2,CRQ_5,CRQ_6,CRQ_10), na.rm=F),
         CRQ_problemtalk_mean=round(rowMeans(cbind(CRQ_2,CRQ_5,CRQ_6,CRQ_10), na.rm=T),3))

## Save it
CRQ_Wave1_outdf <- CRQ_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(CRQ_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/CRQ_Wave1.csv"))

CRQ_Wave2_outdf <- CRQ_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(CRQ_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/CRQ_Wave2.csv"))

CRQ_Wave3_outdf <- CRQ_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(CRQ_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/CRQ_Wave3.csv"))

## Graph it
CRQ_Wave1_totals<-CRQ_Wave1 %>%
  select(tagid,CRQ_rehashing_total,CRQ_mulling_total,CRQ_problemtalk_total) %>%
  mutate(Rehashing=CRQ_rehashing_total,
         Mulling=CRQ_mulling_total,
         Problem_Talk=CRQ_problemtalk_total) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("CRQ_",item))
CRQ_Wave1_totals_graph<-ggplot(CRQ_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("CRQ total subscores for ",length(CRQ_Wave1$CRQ_total[!is.na(CRQ_Wave1$CRQ_total)])," participants"))

CRQ_Wave1_means<-CRQ_Wave1 %>%
  select(tagid,CRQ_rehashing_mean,CRQ_mulling_mean,CRQ_problemtalk_mean) %>%
  mutate(Rehashing=CRQ_rehashing_mean,
         Mulling=CRQ_mulling_mean,
         Problem_Talk=CRQ_problemtalk_mean) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("CRQ_",item))
CRQ_Wave1_means_graph<-ggplot(CRQ_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("CRQ mean subscores for ",length(CRQ_Wave1$CRQ_mean[!is.na(CRQ_Wave1$CRQ_mean)])," participants"))

## Make RDOC ready file
ndar_crq_data <- left_join(CRQ_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         corumq_1=CRQ_1,
         corumq_2=CRQ_2,
         corumq_3=CRQ_3,
         corumq_4=CRQ_4,
         corumq_5=CRQ_5,
         corumq_6=CRQ_6,
         corumq_7=CRQ_7,
         corumq_8=CRQ_8,
         corumq_9=CRQ_9,
         corumq_10=CRQ_10,
         corumq_11=CRQ_11,
         corumq_12=CRQ_12,
         corumq_13=CRQ_13,
         corumq_14=CRQ_14,
         corumq_15=CRQ_15,
         corumq_16=CRQ_16,
         corumq_17=CRQ_17,
         corumq_18=CRQ_18,
         corumq_19=CRQ_19,
         corumq_20=CRQ_20,
         corumq_21=CRQ_21,
         corumq_22=CRQ_22,
         corumq_23=CRQ_23,
         corumq_24=CRQ_24,
         corumq_25=CRQ_25,
         corumq_26=CRQ_26,
         corumq_27=CRQ_27
  )
ndar_crq_data <- left_join(ndar_key,ndar_crq_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("CRQ",ignore.case = FALSE),-dob,-survey_date,
         -survey_type,-survey_name,-tagid,-anontagid,-ID,-guid)
crq_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/crq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
crq_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/crq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
crq_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/crq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

crq_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/crq01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
crq_temp_df<-data.frame(crq_temp)
ndar_crq_data<-bind_rows(crq_temp_df,ndar_crq_data)

part2<-colnames(ndar_crq_data)
part3<-as.matrix(ndar_crq_data)
colnames(part3)<-NULL
together<-rbind(crq_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/crq01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,crq_df_header,crq_temp,crq_temp_df,CRQ,CRQ_Wave1,CRQ_Wave1_means,CRQ_Wave1_means_graph,CRQ_Wave1_totals,CRQ_Wave1_totals_graph)
```

Prepare CTQ
```{r}
CTQ<-left_join(filter(cleaned_survey_data, grepl("CTQ",item)) %>%
                 filter(!is.na(value)) %>% 
                 filter(!value=="") %>%
                 filter(!grepl("TEXT",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

CTQ_Wave1<-left_join(CTQ,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>% 
  select(-contains("TEXT")) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(CTQ_1=CTQ_1..1,
         CTQ_2=ifelse(CTQ_2..1==1,5,
                      ifelse(CTQ_2..1==2,4,
                             ifelse(CTQ_2..1==3,3,
                                    ifelse(CTQ_2..1==4,2,
                                           ifelse(CTQ_2..1==5,1,
                                                  NA))))),
         CTQ_3=CTQ_3..1,
         CTQ_4=CTQ_4..1,
         CTQ_5=ifelse(CTQ_5..1==1,5,
                      ifelse(CTQ_5..1==2,4,
                             ifelse(CTQ_5..1==3,3,
                                    ifelse(CTQ_5..1==4,2,
                                           ifelse(CTQ_5..1==5,1,
                                                  NA))))),
         CTQ_6=CTQ_6..1,
         CTQ_7=ifelse(CTQ_7..1==1,5,
                      ifelse(CTQ_7..1==2,4,
                             ifelse(CTQ_7..1==3,3,
                                    ifelse(CTQ_7..1==4,2,
                                           ifelse(CTQ_7..1==5,1,
                                                  NA))))),
         CTQ_8=CTQ_8..1,
         CTQ_9=CTQ_9..1,
         CTQ_10=CTQ_10..1,
         CTQ_11=CTQ_11..1,
         CTQ_12=CTQ_12..1,
         CTQ_13=ifelse(CTQ_13..1==1,5,
                       ifelse(CTQ_13..1==2,4,
                              ifelse(CTQ_13..1==3,3,
                                     ifelse(CTQ_13..1==4,2,
                                            ifelse(CTQ_13..1==5,1,
                                                   NA))))),
         CTQ_14=CTQ_14..1,
         CTQ_15=CTQ_15..1,
         CTQ_16=CTQ_16..1,
         CTQ_17=CTQ_17..1,
         CTQ_18=CTQ_18..1,
         CTQ_19=ifelse(CTQ_19..1==1,5,
                       ifelse(CTQ_19..1==2,4,
                              ifelse(CTQ_19..1==3,3,
                                     ifelse(CTQ_19..1==4,2,
                                            ifelse(CTQ_19..1==5,1,
                                                   NA))))),
         CTQ_20=CTQ_20..1,
         CTQ_21=CTQ_21..1,
         CTQ_22=CTQ_22..1,
         CTQ_23=CTQ_23..1,
         CTQ_24=CTQ_24..1,
         CTQ_25=CTQ_25..1,
         CTQ_26=ifelse(CTQ_26..1==1,5,
                       ifelse(CTQ_26..1==2,4,
                              ifelse(CTQ_26..1==3,3,
                                     ifelse(CTQ_26..1==4,2,
                                            ifelse(CTQ_26..1==5,1,
                                                   NA))))),
         CTQ_27=CTQ_27..1,
         CTQ_28=CTQ_28..1,
         CTQ_29=CTQ_29..1,
         CTQ_30=CTQ_30..1,
         CTQ_31=CTQ_31..1,
         CTQ_32=CTQ_32..1,
         CTQ_N=32) %>%
  mutate(CTQ_missing=rowSums(is.na(cbind(CTQ_1,CTQ_2,CTQ_3,CTQ_4,CTQ_5,CTQ_6,CTQ_7,CTQ_8,CTQ_9,CTQ_10,CTQ_11,CTQ_12,CTQ_13,CTQ_14,CTQ_15,CTQ_16,CTQ_17,CTQ_18,CTQ_19,CTQ_20,CTQ_21,CTQ_22,CTQ_23,CTQ_24,CTQ_25,CTQ_26,CTQ_27,CTQ_28,CTQ_29,CTQ_30,CTQ_31,CTQ_32))),
         CTQ_emotionalabuse_total=rowSums(cbind(CTQ_3,CTQ_8,CTQ_14,CTQ_18,CTQ_25,CTQ_31),na.rm=T),
         CTQ_emotionalneglect_total=rowSums(cbind(CTQ_5,CTQ_7,CTQ_13,CTQ_19,CTQ_28,CTQ_30),na.rm=T),
         CTQ_physicalabuse_total=rowSums(cbind(CTQ_9,CTQ_11,CTQ_12,CTQ_15,CTQ_17,CTQ_29),na.rm=T),
         CTQ_physicalneglect_total=rowSums(cbind(CTQ_1,CTQ_2,CTQ_4,CTQ_6,CTQ_26),na.rm=T),
         CTQ_sexualabuse_total=rowSums(cbind(CTQ_20,CTQ_21,CTQ_23,CTQ_24,CTQ_27),na.rm=T),
         CTQ_validity_total=rowSums(cbind(CTQ_10,CTQ_16,CTQ_22),na.rm=T),
         CTQ_emotionalabuse_mean=rowMeans(cbind(CTQ_3,CTQ_8,CTQ_14,CTQ_18,CTQ_25,CTQ_31),na.rm=F),
         CTQ_emotionalneglect_mean=rowMeans(cbind(CTQ_5,CTQ_7,CTQ_13,CTQ_19,CTQ_28,CTQ_30),na.rm=F),
         CTQ_physicalabuse_mean=rowMeans(cbind(CTQ_9,CTQ_11,CTQ_12,CTQ_15,CTQ_17,CTQ_29),na.rm=F),
         CTQ_physicalneglect_mean=rowMeans(cbind(CTQ_1,CTQ_2,CTQ_4,CTQ_6,CTQ_26),na.rm=F),
         CTQ_sexualabuse_mean=rowMeans(cbind(CTQ_20,CTQ_21,CTQ_23,CTQ_24,CTQ_27),na.rm=F),
         CTQ_validity_mean=rowMeans(cbind(CTQ_10,CTQ_16,CTQ_22),na.rm=F))

## Save it
CTQ_Wave1_outdf <- CTQ_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(CTQ_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/CTQ_Wave1.csv"))

CTQ_Wave2_outdf <- CTQ_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(CTQ_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/CTQ_Wave2.csv"))

## Graph it
CTQ_Wave1_totals<-CTQ_Wave1 %>%
  select(tagid,CTQ_emotionalabuse_total,CTQ_emotionalneglect_total,CTQ_physicalabuse_total,
         CTQ_physicalneglect_total,CTQ_sexualabuse_total,CTQ_validity_total) %>%
  mutate(Emotional_Abuse=CTQ_emotionalabuse_total,
         Emotional_Neglect=CTQ_emotionalneglect_total,
         Physical_Abust=CTQ_physicalabuse_total,
         Physical_Neglect=CTQ_physicalneglect_total,
         Sexual_Abuse=CTQ_sexualabuse_total,
         Validity=CTQ_validity_total) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("CTQ_",item))
CTQ_Wave1_totals_graph<-ggplot(CTQ_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("CTQ total subscores for ",length(unique(CTQ_Wave1$tagid[!is.na(CTQ_Wave1$tagid)]))," participants"))

CTQ_Wave1_means<-CTQ_Wave1 %>%
  select(tagid,CTQ_emotionalabuse_mean,CTQ_emotionalneglect_mean,CTQ_physicalabuse_mean,
         CTQ_physicalneglect_mean,CTQ_sexualabuse_mean,CTQ_validity_mean) %>%
  mutate(Emotional_Abuse=CTQ_emotionalabuse_mean,
         Emotional_Neglect=CTQ_emotionalneglect_mean,
         Physical_Abust=CTQ_physicalabuse_mean,
         Physical_Neglect=CTQ_physicalneglect_mean,
         Sexual_Abuse=CTQ_sexualabuse_mean,
         Validity=CTQ_validity_mean) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("CTQ_",item))
CTQ_Wave1_means_graph<-ggplot(CTQ_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("CTQ mean subscores for ",length(unique(CTQ_Wave1$tagid[!is.na(CTQ_Wave1$tagid)]))," participants"))

## Make RDOC ready file
ndar_ctq_data <- left_join(CTQ_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         site="University of Oregon",
         study="TAG study",
         ctq_01=CTQ_1,
         ctq_02=CTQ_2,
         ctq_03=CTQ_3,
         ctq_04=CTQ_4,
         ctq_05=CTQ_5,
         ctq_06=CTQ_6,
         ctq_07=CTQ_7,
         ctq_08=CTQ_8,
         ctq_09=CTQ_9,
         ctq_10=CTQ_10,
         ctq_11=CTQ_11,
         ctq_12=CTQ_12,
         ctq_13=CTQ_13,
         ctq_14=CTQ_14,
         ctq_15=CTQ_15,
         ctq_16=CTQ_16,
         ctq_17=CTQ_17,
         ctq_18=CTQ_18,
         ctq_19=CTQ_19,
         ctq_20=CTQ_20,
         ctq_21=CTQ_21,
         ctq_22=CTQ_22,
         ctq_23=CTQ_23,
         ctq_24=CTQ_24,
         ctq_25=CTQ_25,
         ctq_26=CTQ_26,
         ctq_27=CTQ_27,
         ctq_28=CTQ_28,
         ctq_29=CTQ_29,
         ctq_30=CTQ_30,
         ctq_31=CTQ_31,
         ctq_32=CTQ_32,
         ctqscore_ea=CTQ_emotionalabuse_total,
         ctqscore_en=CTQ_emotionalneglect_total,
         ctqscore_pa=CTQ_physicalabuse_total,
         ctqscore_pn=CTQ_physicalneglect_total,
         ctqscore_sa=CTQ_sexualabuse_total,
         ctqscore_val=CTQ_validity_total)
ndar_ctq_data <- left_join(ndar_key,ndar_ctq_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("CTQ",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
ctq_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/ctq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
ctq_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/ctq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
ctq_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/ctq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

ctq_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/ctq01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
ctq_temp_df<-data.frame(ctq_temp)
ndar_ctq_data<-bind_rows(ctq_temp_df,ndar_ctq_data)

part2<-colnames(ndar_ctq_data)
part3<-as.matrix(ndar_ctq_data)
colnames(part3)<-NULL
together<-rbind(ctq_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/ctq01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,ctq_df_header,ctq_temp,ctq_temp_df,CTQ,CTQ_Wave1,CTQ_Wave1_means,CTQ_Wave1_means_graph,CTQ_Wave1_totals,CTQ_Wave1_totals_graph)
```

Prepare DIT
```{r}
DIT<-left_join(filter(cleaned_survey_data, grepl("DIT",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

DIT_Wave1<-left_join(DIT,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 1 - V4 - Current",sa_date,
                            ifelse(survey_name=="TAG - Sess 1 - V1",sa_date,
                                   ifelse(survey_name=="TAG - Sess 1 - V2",sa_date,
                                          ifelse(survey_name=="TAG - Sess 1 - V3",sa_date,
                                                 ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                                 )))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(DIT_1=ifelse(DIT_1==1,5,
                      ifelse(DIT_1==2,4,
                             ifelse(DIT_1==3,3,
                                    ifelse(DIT_1==4,2,
                                           ifelse(DIT_1==5,1,
                                                  NA))))),
         DIT_2=ifelse(DIT_2==1,5,
                      ifelse(DIT_2==2,4,
                             ifelse(DIT_2==3,3,
                                    ifelse(DIT_2==4,2,
                                           ifelse(DIT_2==5,1,
                                                  NA))))),
         DIT_3=ifelse(DIT_3==1,5,
                      ifelse(DIT_3==2,4,
                             ifelse(DIT_3==3,3,
                                    ifelse(DIT_3==4,2,
                                           ifelse(DIT_3==5,1,
                                                  NA))))),
         DIT_4=ifelse(DIT_4==1,5,
                      ifelse(DIT_4==2,4,
                             ifelse(DIT_4==3,3,
                                    ifelse(DIT_4==4,2,
                                           ifelse(DIT_4==5,1,
                                                  NA)))))) %>%
  mutate(DIT_belonging_total=rowSums(cbind(DIT_1,DIT_2,DIT_3,DIT_4), na.rm=F),
         DIT_intel_total=rowSums(cbind(DIT_5,DIT_6,DIT_7), na.rm=F),
         DIT_moral_total=rowSums(cbind(DIT_8,DIT_9,DIT_10), na.rm=F),
         DIT_group_total=rowSums(cbind(DIT_11,DIT_12,DIT_13,DIT_14), na.rm=F),
         DIT_belonging_mean=round(rowMeans(cbind(DIT_1,DIT_2,DIT_3,DIT_4), na.rm=T),3),
         DIT_intel_mean=round(rowMeans(cbind(DIT_5,DIT_6,DIT_7), na.rm=T),3),
         DIT_moral_mean=round(rowMeans(cbind(DIT_8,DIT_9,DIT_10), na.rm=T),3),
         DIT_group_mean=round(rowMeans(cbind(DIT_11,DIT_12,DIT_13,DIT_14), na.rm=T),3))

## Save it
DIT_Wave1_outdf <- DIT_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(DIT_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/DIT_Wave1.csv"))

DIT_Wave2_outdf <- DIT_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(DIT_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/DIT_Wave2.csv"))

DIT_Wave3_outdf <- DIT_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(DIT_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/DIT_Wave3.csv"))

## Graph it
DIT_Wave1_totals<-DIT_Wave1 %>%
  select(tagid,DIT_belonging_total,DIT_intel_total,DIT_moral_total,
         DIT_group_total) %>%
  mutate(Social_Belonging=DIT_belonging_total,
         Intelligence_Malleability=DIT_intel_total,
         Morality_Malleability=DIT_moral_total,
         Group_Malleability=DIT_group_total) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("DIT_",item))
DIT_Wave1_totals_graph<-ggplot(DIT_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("DIT total subscores for ",length(unique(DIT_Wave1$tagid[!is.na(DIT_Wave1$tagid)]))," participants"))

DIT_Wave1_means<-DIT_Wave1 %>%
  select(tagid,DIT_belonging_mean,DIT_intel_mean,DIT_moral_mean,
         DIT_group_mean) %>%
  mutate(Social_Belonging=DIT_belonging_mean,
         Intelligence_Malleability=DIT_intel_mean,
         Morality_Malleability=DIT_moral_mean,
         Group_Malleability=DIT_group_mean) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("DIT_",item))
DIT_Wave1_means_graph<-ggplot(DIT_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("DIT mean subscores for ",length(unique(DIT_Wave1$tagid[!is.na(DIT_Wave1$tagid)]))," participants"))

## Make RDOC ready file
ndar_dit_data <- left_join(DIT_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         site="University of Oregon",
         study="TAG study",
         dit_1=DIT_1,
         dit_2=DIT_2,
         dit_3=DIT_3,
         dit_4=DIT_4,
         dit_5=DIT_5,
         dit_6=DIT_6,
         dit_7=DIT_7,
         dit_8=DIT_8,
         dit_9=DIT_9,
         dit_10=DIT_10,
         dit_11=DIT_11,
         dit_12=DIT_12,
         dit_13=DIT_13,
         dit_14=DIT_14,
         dit_intel=DIT_intel_total,
         dit_moral=DIT_moral_total,
         dit_group=DIT_group_total)
ndar_dit_data <- left_join(ndar_key,ndar_dit_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("DIT",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
dit_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/dit01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
dit_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/dit01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
dit_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/dit01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

dit_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/dit01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
dit_temp_df<-data.frame(dit_temp)
ndar_dit_data<-bind_rows(dit_temp_df,ndar_dit_data)

part2<-colnames(ndar_dit_data)
part3<-as.matrix(ndar_dit_data)
colnames(part3)<-NULL
together<-rbind(dit_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/dit01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,dit_df_header,dit_temp,dit_temp_df,DIT,DIT_Wave1,DIT_Wave1_means,DIT_Wave1_means_graph,DIT_Wave1_totals,DIT_Wave1_totals_graph)
```

Prepare DSHI
```{r}
DSHI<-left_join(filter(cleaned_survey_data, grepl("DSHI",item)) %>%
                 filter(!is.na(value)) %>%
                 # filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                  group_by(item, survey_name, tagid) %>%
                  do({
                    thing <- .
                    if(any(thing$value != '')){
                      retthing <- filter(thing, value != '')
                    } else {
                      retthing <- distinct(thing)
                    }
                    retthing
                  }) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(DSHI$tagid) == length(unique(DSHI$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

DSHI<- DSHI %>%
  filter(!(tagid=="TAG055" & grepl("Sess 2",survey_name)))

if (length(DSHI$tagid) == length(unique(DSHI$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

DSHI_Wave1<-left_join(DSHI,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                            ifelse(survey_name=="TAG - Sess 1 - V3",sa_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob)

## Save it
DSHI_Wave1_outdf <- DSHI_Wave1 
write.csv(DSHI_Wave1_outdf, file = paste0(workdir,"Questionnaires/Waves_12_RDOC/DSHI_Wave12.csv"))

## Make RDOC ready file
ndar_dshi_data <- left_join(DSHI_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         comments_misc="UO TAG Study",
         visit=ifelse(grepl("Sess 1",survey_name),"Session1",
                      ifelse(grepl("Session 1",survey_name),"Session1",
                             ifelse(grepl("Sess 2",survey_name),"Session2",
                                    ifelse(grepl("Session 2",survey_name),"Session2",
                                           ifelse(grepl("Home",survey_name),"Home Questionnaires",
                                           NA))))),
         gender="F",
         dshi_q1=ifelse(DSHI_1A==2,"N",
                        ifelse(DSHI_1A==2,"Y",NA)),
         dshi_q1a=ifelse(is.numeric(DSHI_1B_1_TEXT),DSHI_1B_1_TEXT,NA),
         dshi_q1b=ifelse(is.numeric(DSHI_1B_2_TEXT),DSHI_1B_2_TEXT,NA),
         dshi_q1c=ifelse(nchar(as.character(DSHI_1B_3_TEXT))<11,as.character(DSHI_1B_3_TEXT),NA),
         dshi_q1d=ifelse(is.numeric(DSHI_1B_4_TEXT),DSHI_1B_4_TEXT,NA),
         dshi_q1e=DSHI_1B_5_TEXT,
         dshi_q2=ifelse(DSHI_2A==2,"N",
                        ifelse(DSHI_2A==2,"Y",NA)),
         dshi_q2a=ifelse(is.numeric(DSHI_2B_1_TEXT),DSHI_2B_1_TEXT,NA),
         dshi_q2b=ifelse(is.numeric(DSHI_2B_2_TEXT),DSHI_2B_2_TEXT,NA),
         dshi_q2c=ifelse(nchar(as.character(DSHI_2B_3_TEXT))<11,as.character(DSHI_2B_3_TEXT),NA),
         dshi_q2d=ifelse(is.numeric(DSHI_2B_4_TEXT),DSHI_2B_4_TEXT,NA),
         dshi_q2e=DSHI_2B_5_TEXT,
         dshi_q3=ifelse(DSHI_3A==2,"N",
                        ifelse(DSHI_3A==2,"Y",NA)),
         dshi_q3a=ifelse(is.numeric(DSHI_3B_1_TEXT),DSHI_3B_1_TEXT,NA),
         dshi_q3b=ifelse(is.numeric(DSHI_3B_2_TEXT),DSHI_3B_2_TEXT,NA),
         dshi_q3c=ifelse(nchar(as.character(DSHI_3B_3_TEXT))<11,as.character(DSHI_3B_3_TEXT),NA),
         dshi_q3d=ifelse(is.numeric(DSHI_3B_4_TEXT),DSHI_3B_4_TEXT,NA),
         dshi_q3e=DSHI_3B_5_TEXT,
         dshi_q4=ifelse(DSHI_4A==2,"N",
                        ifelse(DSHI_4A==2,"Y",NA)),
         dshi_q4a=ifelse(is.numeric(DSHI_4B_1_TEXT),DSHI_4B_1_TEXT,NA),
         dshi_q4b=ifelse(is.numeric(DSHI_4B_2_TEXT),DSHI_4B_2_TEXT,NA),
         dshi_q4c=ifelse(nchar(as.character(DSHI_4B_3_TEXT))<11,as.character(DSHI_4B_3_TEXT),NA),
         dshi_q4d=ifelse(is.numeric(DSHI_4B_4_TEXT),DSHI_4B_4_TEXT,NA),
         dshi_q4e=DSHI_4B_5_TEXT,
         dshi_q5=ifelse(DSHI_5A==2,"N",
                        ifelse(DSHI_5A==2,"Y",NA)),
         dshi_q5a=ifelse(is.numeric(DSHI_5B_1_TEXT),DSHI_5B_1_TEXT,NA),
         dshi_q5b=ifelse(is.numeric(DSHI_5B_2_TEXT),DSHI_5B_2_TEXT,NA),
         dshi_q5c=ifelse(nchar(as.character(DSHI_5B_3_TEXT))<11,as.character(DSHI_5B_3_TEXT),NA),
         dshi_q5d=ifelse(is.numeric(DSHI_5B_4_TEXT),DSHI_5B_4_TEXT,NA),
         dshi_q5e=DSHI_5B_5_TEXT,
         dshi_q6=ifelse(DSHI_6A==2,"N",
                        ifelse(DSHI_6A==2,"Y",NA)),
         dshi_q6a=ifelse(is.numeric(DSHI_6B_1_TEXT),DSHI_6B_1_TEXT,NA),
         dshi_q6b=ifelse(is.numeric(DSHI_6B_2_TEXT),DSHI_6B_2_TEXT,NA),
         dshi_q6c=ifelse(nchar(as.character(DSHI_6B_3_TEXT))<11,as.character(DSHI_6B_3_TEXT),NA),
         dshi_q6d=ifelse(is.numeric(DSHI_6B_4_TEXT),DSHI_6B_4_TEXT,NA),
         dshi_q6e=DSHI_6B_5_TEXT,
         dshi_q7=ifelse(DSHI_7A==2,"N",
                        ifelse(DSHI_7A==2,"Y",NA)),
         dshi_q7a=ifelse(is.numeric(DSHI_7B_1_TEXT),DSHI_7B_1_TEXT,NA),
         dshi_q7b=DSHI_7B_2_TEXT,
         dshi_q7c=ifelse(nchar(as.character(DSHI_7B_3_TEXT))<11,as.character(DSHI_7B_3_TEXT),NA),
         dshi_q7d=DSHI_7B_4_TEXT,
         dshi_q7e=DSHI_7B_5_TEXT,
         dshi_q8=ifelse(DSHI_8A==2,"N",
                        ifelse(DSHI_8A==2,"Y",NA)),
         dshi_q8a=ifelse(is.numeric(DSHI_8B_1_TEXT),DSHI_8B_1_TEXT,NA),
         dshi_q8b=DSHI_8B_2_TEXT,
         dshi_q8c=ifelse(nchar(as.character(DSHI_8B_3_TEXT))<11,as.character(DSHI_8B_3_TEXT),NA),
         dshi_q8d=DSHI_8B_4_TEXT,
         dshi_q8e=DSHI_8B_5_TEXT,
         dshi_q9=ifelse(DSHI_9A==2,"N",
                        ifelse(DSHI_9A==2,"Y",NA)),
         dshi_q9a=ifelse("DSHI_9B_1_TEXT" %in% colnames(DSHI),DSHI_9B_1_TEXT,NA),
         dshi_q9b=ifelse("DSHI_9B_2_TEXT" %in% colnames(DSHI),DSHI_9B_2_TEXT,NA),
         dshi_q9c=ifelse("DSHI_9B_3_TEXT" %in% colnames(DSHI),DSHI_9B_3_TEXT,NA),
         dshi_q9d=ifelse("DSHI_9B_4_TEXT" %in% colnames(DSHI),DSHI_9B_4_TEXT,NA),
         dshi_q9e=ifelse("DSHI_9B_5_TEXT" %in% colnames(DSHI),DSHI_9B_5_TEXT,NA),
         dshi_q10=ifelse(DSHI_10A==2,"N",
                        ifelse(DSHI_10A==2,"Y",NA)),
         dshi_q10a=ifelse("DSHI_10B_1_TEXT" %in% colnames(DSHI),DSHI_10B_1_TEXT,NA),
         dshi_q10b=ifelse("DSHI_10B_2_TEXT" %in% colnames(DSHI),DSHI_10B_2_TEXT,NA),
         dshi_q10c=ifelse("DSHI_10B_3_TEXT" %in% colnames(DSHI),DSHI_10B_3_TEXT,NA),
         dshi_q10d=ifelse("DSHI_10B_4_TEXT" %in% colnames(DSHI),DSHI_10B_4_TEXT,NA),
         dshi_q10e=ifelse("DSHI_10B_5_TEXT" %in% colnames(DSHI),DSHI_10B_5_TEXT,NA),
         dshi_q11=ifelse(DSHI_11A==2,"N",
                        ifelse(DSHI_11A==2,"Y",NA)),
         dshi_q11a=ifelse(is.numeric(DSHI_11B_1_TEXT),DSHI_11B_1_TEXT,NA),
         dshi_q11b=ifelse(is.numeric(DSHI_11B_2_TEXT),DSHI_11B_2_TEXT,NA),
         dshi_q11c=ifelse(nchar(as.character(DSHI_11B_3_TEXT))<11,as.character(DSHI_11B_3_TEXT),NA),
         dshi_q11d=DSHI_11B_4_TEXT,
         dshi_q11e=DSHI_11B_5_TEXT,
         dshi_q12=ifelse(DSHI_12A==2,"N",
                        ifelse(DSHI_12A==2,"Y",NA)),
         dshi_q12a=ifelse("DSHI_12B_1_TEXT" %in% colnames(DSHI),DSHI_12B_1_TEXT,NA),
         dshi_q12b=ifelse("DSHI_12B_2_TEXT" %in% colnames(DSHI),DSHI_12B_2_TEXT,NA),
         dshi_q12c=ifelse("DSHI_12B_3_TEXT" %in% colnames(DSHI),DSHI_12B_3_TEXT,NA),
         dshi_q12d=ifelse("DSHI_12B_4_TEXT" %in% colnames(DSHI),DSHI_12B_4_TEXT,NA),
         dshi_q12e=ifelse("DSHI_12B_5_TEXT" %in% colnames(DSHI),DSHI_12B_5_TEXT,NA),
         dshi_q13=ifelse(DSHI_13A==2,"N",
                        ifelse(DSHI_13A==2,"Y",NA)),
         dshi_q13a=ifelse("DSHI_13B_1_TEXT" %in% colnames(DSHI),DSHI_13B_1_TEXT,NA),
         dshi_q13b=ifelse("DSHI_13B_2_TEXT" %in% colnames(DSHI),DSHI_13B_2_TEXT,NA),
         dshi_q13c=ifelse("DSHI_13B_3_TEXT" %in% colnames(DSHI),DSHI_13B_3_TEXT,NA),
         dshi_q13d=ifelse("DSHI_13B_4_TEXT" %in% colnames(DSHI),DSHI_13B_4_TEXT,NA),
         dshi_q13e=ifelse("DSHI_13B_5_TEXT" %in% colnames(DSHI),DSHI_13B_5_TEXT,NA),
         dshi_q14=ifelse(DSHI_14A==2,"N",
                        ifelse(DSHI_14A==2,"Y",NA)),
         dshi_q14a=ifelse(is.numeric(DSHI_14B_1_TEXT),DSHI_14B_1_TEXT,NA),
         dshi_q14b=ifelse(is.numeric(DSHI_14B_2_TEXT),DSHI_14B_2_TEXT,NA),
         dshi_q14c=ifelse(nchar(as.character(DSHI_14B_3_TEXT))<11,as.character(DSHI_14B_3_TEXT),NA),
         dshi_q14d=ifelse(is.numeric(DSHI_14B_4_TEXT),DSHI_14B_4_TEXT,NA),
         dshi_q14e=DSHI_14B_5_TEXT,
         dshi_q15=ifelse(DSHI_15A==2,"N",
                        ifelse(DSHI_15A==2,"Y",NA)),
         dshi_q15a=DSHI_15B_1_TEXT,
         dshi_q15b=DSHI_15B_2_TEXT,
         dshi_q15c=ifelse(nchar(as.character(DSHI_15B_3_TEXT))<11,as.character(DSHI_15B_3_TEXT),NA),
         dshi_q15d=DSHI_15B_4_TEXT,
         dshi_q15e=DSHI_15B_5_TEXT,
         dshi_q16=ifelse(DSHI_16A==2,"N",
                        ifelse(DSHI_16A==2,"Y",NA)),
         dshi_q16a=ifelse(is.numeric(DSHI_16B_1_TEXT),DSHI_16B_1_TEXT,NA),
         dshi_q16b=ifelse(is.numeric(DSHI_16B_2_TEXT),DSHI_16B_2_TEXT,NA),
         dshi_q16c=ifelse(nchar(as.character(DSHI_16B_3_TEXT))<11,as.character(DSHI_16B_3_TEXT),NA),
         dshi_q16d=ifelse(is.numeric(DSHI_16B_4_TEXT),DSHI_16B_4_TEXT,NA),
         dshi_q16e=DSHI_16B_5_TEXT,
         dshi_q17=ifelse(DSHI_17A==2,"N",
                        ifelse(DSHI_17A==2,"Y",NA)),
         dshi_q17a=ifelse(is.numeric(DSHI_17B_1_TEXT),DSHI_17B_1_TEXT,NA),
         dshi_q17b=ifelse(is.numeric(DSHI_17B_2_TEXT),DSHI_17B_2_TEXT,NA),
         dshi_q17c=ifelse(nchar(as.character(DSHI_17B_3_TEXT))<11,as.character(DSHI_17B_3_TEXT),NA),
         dshi_q17d=ifelse(is.numeric(DSHI_17B_4_TEXT),DSHI_17B_4_TEXT,NA),
         dshi_q17e=DSHI_17B_5_TEXT,
         dshi_totalscore=-999)
ndar_dshi_data <- filter(ndar_dshi_data, 
                         survey_name != 'TAG - Sess 1 - V3', tagid != 'TAG042')
ndar_dshi_data <- left_join(ndar_key,ndar_dshi_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("DSHI",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
dshi_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/dshi01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
dshi_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/dshi01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
dshi_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/dshi01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

dshi_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/dshi01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
dshi_temp_df<-data.frame(dshi_temp)
ndar_dshi_data<-bind_rows(dshi_temp_df,ndar_dshi_data)

part2<-colnames(ndar_dshi_data)
part3<-as.matrix(ndar_dshi_data)
colnames(part3)<-NULL
together<-rbind(dshi_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/dshi01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,dshi_df_header,dshi_temp,dshi_temp_df,DSHI,DSHI_Wave1)
```

Prepare EHI
```{r}
EHI<-left_join(filter(cleaned_survey_data, grepl("EHI",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

EHI_Wave1<-left_join(EHI,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 1 - V1",sa_date,
                            ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                            ))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(EHI_1r=ifelse(EHI_1==1,-2,
                       ifelse(EHI_1==2,-1,
                              ifelse(EHI_1==3,0,
                                     ifelse(EHI_1==4,1,
                                            ifelse(EHI_1==5,2,NA))))),
         EHI_2r=ifelse(EHI_2==1,-2,
                       ifelse(EHI_2==2,-1,
                              ifelse(EHI_2==3,0,
                                     ifelse(EHI_2==4,1,
                                            ifelse(EHI_2==5,2,NA))))),
         EHI_3r=ifelse(EHI_3==1,-2,
                       ifelse(EHI_3==2,-1,
                              ifelse(EHI_3==3,0,
                                     ifelse(EHI_3==4,1,
                                            ifelse(EHI_3==5,2,NA))))),
         EHI_4r=ifelse(EHI_4==1,-2,
                       ifelse(EHI_4==2,-1,
                              ifelse(EHI_4==3,0,
                                     ifelse(EHI_4==4,1,
                                            ifelse(EHI_4==5,2,NA))))),
         EHI_5r=ifelse(EHI_5==1,-2,
                       ifelse(EHI_5==2,-1,
                              ifelse(EHI_5==3,0,
                                     ifelse(EHI_5==4,1,
                                            ifelse(EHI_5==5,2,NA))))),
         EHI_6r=ifelse(EHI_6==1,-2,
                       ifelse(EHI_6==2,-1,
                              ifelse(EHI_6==3,0,
                                     ifelse(EHI_6==4,1,
                                            ifelse(EHI_6==5,2,NA))))),
         EHI_7r=ifelse(EHI_7==1,-2,
                       ifelse(EHI_7==2,-1,
                              ifelse(EHI_7==3,0,
                                     ifelse(EHI_7==4,1,
                                            ifelse(EHI_7==5,2,NA))))),
         EHI_8r=ifelse(EHI_8==1,-2,
                       ifelse(EHI_8==2,-1,
                              ifelse(EHI_8==3,0,
                                     ifelse(EHI_8==4,1,
                                            ifelse(EHI_8==5,2,NA))))),
         EHI_9r=ifelse(EHI_9==1,-2,
                       ifelse(EHI_9==2,-1,
                              ifelse(EHI_9==3,0,
                                     ifelse(EHI_9==4,1,
                                            ifelse(EHI_9==5,2,NA))))),
         EHI_10r=ifelse(EHI_10==1,-2,
                       ifelse(EHI_10==2,-1,
                              ifelse(EHI_10==3,0,
                                     ifelse(EHI_10==4,1,
                                            ifelse(EHI_10==5,2,NA)))))) %>%
  mutate(EHI_sum = rowSums(cbind(EHI_1r,EHI_2r,EHI_3r,EHI_4r,EHI_5r,
                                   EHI_6r,EHI_7r,EHI_8r,EHI_9r,EHI_10r),na.rm=T),
         EHI_compN = rowSums(!is.na(cbind(EHI_1r,EHI_2r,EHI_3r,EHI_4r,EHI_5r,
                                   EHI_6r,EHI_7r,EHI_8r,EHI_9r,EHI_10r))),
         EHI_missing_perc = 100*(rowSums(is.na(cbind(EHI_1r,EHI_2r,EHI_3r,EHI_4r,EHI_5r,
                                   EHI_6r,EHI_7r,EHI_8r,EHI_9r,EHI_10r)))/10)) %>%
  mutate(EHI_score = ifelse(EHI_missing_perc < 25, 100*(EHI_sum/(2*EHI_compN)),NA)) %>%
  mutate(EHI_handedness = ifelse(EHI_score <= -20, "LH",
                                 ifelse(EHI_score >= 20, "RH",
                                        ifelse((EHI_score > -20 & EHI_score < 20), "ambi", NA)))) %>%
  select(-EHI_sum,-EHI_compN)
                                        
## Save it
EHI_Wave1_outdf <- EHI_Wave1 %>% filter(!grepl("W2|W3",survey_name)) %>% 
  mutate(EHI_1=EHI_1r,EHI_2=EHI_2r,EHI_3=EHI_3r,EHI_4=EHI_4r,EHI_5=EHI_5r,
         EHI_6=EHI_6r,EHI_7=EHI_7r,EHI_8=EHI_8r,EHI_9=EHI_9r,EHI_10=EHI_10r)
write.csv(EHI_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/EHI_Wave1.csv"))

EHI_Wave2_outdf <- EHI_Wave1 %>% filter(grepl("W2",survey_name)) %>% 
  mutate(EHI_1=EHI_1r,EHI_2=EHI_2r,EHI_3=EHI_3r,EHI_4=EHI_4r,EHI_5=EHI_5r,
         EHI_6=EHI_6r,EHI_7=EHI_7r,EHI_8=EHI_8r,EHI_9=EHI_9r,EHI_10=EHI_10r)
write.csv(EHI_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/EHI_Wave2.csv"))

EHI_Wave3_outdf <- EHI_Wave1 %>% filter(grepl("W3",survey_name)) %>% 
  mutate(EHI_1=EHI_1r,EHI_2=EHI_2r,EHI_3=EHI_3r,EHI_4=EHI_4r,EHI_5=EHI_5r,
         EHI_6=EHI_6r,EHI_7=EHI_7r,EHI_8=EHI_8r,EHI_9=EHI_9r,EHI_10=EHI_10r)
write.csv(EHI_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/EHI_Wave3.csv"))

## Make RDOC ready file
ndar_ehi_data <- left_join(EHI_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         site="University of Oregon",
         study="TAG study",
         writing=ifelse(EHI_1==1,"spl",
                        ifelse(EHI_1==2,"left",
                               ifelse(EHI_1==3,"np",
                                      ifelse(EHI_1==4,"right",
                                             ifelse(EHI_1==5,"spr",
                                                    NA))))),
         drawing=ifelse(EHI_2==1,"spl",
                        ifelse(EHI_2==2,"left",
                               ifelse(EHI_2==3,"np",
                                      ifelse(EHI_2==4,"right",
                                             ifelse(EHI_2==5,"spr",
                                                    NA))))),
         throwing=ifelse(EHI_3==1,"spl",
                         ifelse(EHI_3==2,"left",
                                ifelse(EHI_3==3,"np",
                                       ifelse(EHI_3==4,"right",
                                              ifelse(EHI_3==5,"spr",
                                                     NA))))),
         scissors=ifelse(EHI_4==1,"spl",
                         ifelse(EHI_4==2,"left",
                                ifelse(EHI_4==3,"np",
                                       ifelse(EHI_4==4,"right",
                                              ifelse(EHI_4==5,"spr",
                                                     NA))))),
         toothbrush=ifelse(EHI_5==1,"spl",
                           ifelse(EHI_5==2,"left",
                                  ifelse(EHI_5==3,"np",
                                         ifelse(EHI_5==4,"right",
                                                ifelse(EHI_5==5,"spr",
                                                       NA))))),
         knife_no_fork=ifelse(EHI_6==1,"spl",
                              ifelse(EHI_6==2,"left",
                                     ifelse(EHI_6==3,"np",
                                            ifelse(EHI_6==4,"right",
                                                   ifelse(EHI_6==5,"spr",
                                                          NA))))),
         spoon=ifelse(EHI_7==1,"spl",
                      ifelse(EHI_7==2,"left",
                             ifelse(EHI_7==3,"np",
                                    ifelse(EHI_7==4,"right",
                                           ifelse(EHI_7==5,"spr",
                                                  NA))))),
         broom=ifelse(EHI_8==1,"spl",
                      ifelse(EHI_8==2,"left",
                             ifelse(EHI_8==3,"np",
                                    ifelse(EHI_8==4,"right",
                                           ifelse(EHI_8==5,"spr",
                                                  NA))))),
         match=ifelse(EHI_9==1,"spl",
                      ifelse(EHI_9==2,"left",
                             ifelse(EHI_9==3,"np",
                                    ifelse(EHI_9==4,"right",
                                           ifelse(EHI_9==5,"spr",
                                                  NA))))),
         box=ifelse(EHI_10==1,"spl",
                    ifelse(EHI_10==2,"left",
                           ifelse(EHI_10==3,"np",
                                  ifelse(EHI_10==4,"right",
                                         ifelse(EHI_10==5,"spr",
                                                NA))))),
         foot=ifelse(EHI_11==1,"spl",
                     ifelse(EHI_11==2,"left",
                            ifelse(EHI_11==3,"np",
                                   ifelse(EHI_11==4,"right",
                                          ifelse(EHI_11==5,"spr",
                                                 NA))))),
         eye=ifelse(EHI_12==1,"spl",
                    ifelse(EHI_12==2,"left",
                           ifelse(EHI_12==3,"np",
                                  ifelse(EHI_12==4,"right",
                                         ifelse(EHI_12==5,"spr",
                                                NA))))))
ndar_ehi_data <- left_join(ndar_key,ndar_ehi_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("EHI",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
ehi_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/edinburgh_hand01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
ehi_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/edinburgh_hand01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
ehi_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/edinburgh_hand01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

ehi_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/edinburgh_hand01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
ehi_temp_df<-data.frame(ehi_temp)
ndar_ehi_data<-bind_rows(ehi_temp_df,ndar_ehi_data)

part2<-colnames(ndar_ehi_data)
part3<-as.matrix(ndar_ehi_data)
colnames(part3)<-NULL
together<-rbind(ehi_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/edinburgh_hand01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,ehi_df_header,ehi_temp,ehi_temp_df,EHI,EHI_Wave1)
```

Prepare ERQ
```{r}
ERQ<-left_join(filter(cleaned_survey_data, grepl("ERQ",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

ERQ_Wave1<-left_join(ERQ,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 1 - V1",sa_date,
                            ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                                 ))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(ERQ_reappraisal_N=6,
         ERQ_reappraisal_missing=rowSums(is.na(cbind(ERQ_1, ERQ_3, ERQ_5, ERQ_7, ERQ_8, ERQ_10))),
         ERQ_reappraisal_missing_perc=100*(rowSums(is.na(cbind(ERQ_1, ERQ_3, ERQ_5, ERQ_7, ERQ_8, ERQ_10)))/6),
         ERQ_reappraisal_mean=round(rowMeans(cbind(ERQ_1, ERQ_3, ERQ_5, ERQ_7, ERQ_8, ERQ_10), na.rm=T),3),
         ERQ_reappraisal_total=rowSums(cbind(ERQ_1, ERQ_3, ERQ_5, ERQ_7, ERQ_8, ERQ_10), na.rm=F),
         ERQ_suppression_N=4,
         ERQ_suppression_missing=rowSums(is.na(cbind(ERQ_2, ERQ_4, ERQ_6, ERQ_9))),
         ERQ_suppression_missing_perc=100*(rowSums(is.na(cbind(ERQ_2, ERQ_4, ERQ_6, ERQ_9)))/4),
         ERQ_suppression_mean=round(rowMeans(cbind(ERQ_2, ERQ_4, ERQ_6, ERQ_9),na.rm=T),3),
         ERQ_suppression_total=rowSums(cbind(ERQ_2, ERQ_4, ERQ_6, ERQ_9),na.rm=F))

## Save it
ERQ_Wave1_outdf <- ERQ_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(ERQ_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/ERQ_Wave1.csv"))

ERQ_Wave2_outdf <- ERQ_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(ERQ_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/ERQ_Wave2.csv"))

ERQ_Wave3_outdf <- ERQ_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(ERQ_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/ERQ_Wave3.csv"))

## Graph it
ERQ_Wave1_totals<-ERQ_Wave1 %>%
  select(tagid,ERQ_reappraisal_total,ERQ_suppression_total) %>%
  mutate(Emotion_Reappraisal=ERQ_reappraisal_total,
         Emotion_Suppression=ERQ_suppression_total) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("ERQ_",item))
ERQ_Wave1_totals_graph<-ggplot(ERQ_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("ERQ total subscores for ",length(unique(ERQ_Wave1$tagid[!is.na(ERQ_Wave1$tagid)]))," participants"))

ERQ_Wave1_means<-ERQ_Wave1 %>%
  select(tagid,ERQ_reappraisal_mean,ERQ_suppression_mean) %>%
  mutate(Emotion_Reappraisal=ERQ_reappraisal_mean,
         Emotion_Suppression=ERQ_suppression_mean) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("ERQ_",item))
ERQ_Wave1_means_graph<-ggplot(ERQ_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("ERQ mean subscores for ",length(unique(ERQ_Wave1$tagid[!is.na(ERQ_Wave1$tagid)]))," participants"))

## Make RDOC ready file
ndar_erq_data <- left_join(ERQ_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",

         version_form="ERQ; Gross & John, 9/03",
         erq_1=ERQ_1,
         erq_2=ERQ_2,
         erq_3=ERQ_3,
         erq_4=ERQ_4,
         erq_5=ERQ_5,
         erq_6=ERQ_6,
         erq_7=ERQ_7,
         erq_8=ERQ_8,
         erq_9=ERQ_9,
         erq_10=ERQ_10,
         erq_reappraisal=ifelse(!is.na(ERQ_reappraisal_total),ERQ_reappraisal_total,999),
         erq_suppression=ifelse(!is.na(ERQ_suppression_total),ERQ_suppression_total,999))

ndar_erq_data <- left_join(ndar_key,ndar_erq_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("ERQ",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)

erq_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/emrq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
erq_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/emrq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
erq_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/emrq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

erq_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/emrq01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
erq_temp_df<-data.frame(erq_temp)
ndar_erq_data<-bind_rows(erq_temp_df,ndar_erq_data)

part2<-colnames(ndar_erq_data)
part3<-as.matrix(ndar_erq_data)
colnames(part3)<-NULL
together<-rbind(erq_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/emrq01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,erq_df_header,erq_temp,erq_temp_df,ERQ,ERQ_Wave1,ERQ_Wave1_means,ERQ_Wave1_means_graph,
   ERQ_Wave1_totals,ERQ_Wave1_totals_graph)

```

Prepare IFS
```{r}
IFS<-left_join(filter(cleaned_survey_data, grepl("IFS",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(IFS$tagid) == length(unique(IFS$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

IFS_Wave1<-left_join(IFS,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                                 ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(IFS_frankness_total=rowSums(cbind(IFS_1,IFS_2,IFS_3,IFS_4),na.rm=FALSE),
         IFS_frankness_mean=round(rowMeans(cbind(IFS_1,IFS_2,IFS_3,IFS_4),na.rm=TRUE),3),
         IFS_sensitivity_total=rowSums(cbind(IFS_5,IFS_6,IFS_7,IFS_8),na.rm=FALSE),
         IFS_sensitivity_mean=round(rowMeans(cbind(IFS_5,IFS_6,IFS_7,IFS_8),na.rm=TRUE),3),
         IFS_attachment_total=rowSums(cbind(IFS_9,IFS_10,IFS_11,IFS_12),na.rm=FALSE),
         IFS_attachment_mean=round(rowMeans(cbind(IFS_9,IFS_10,IFS_11,IFS_12),na.rm=TRUE),3),
         IFS_exclusiveness_total=rowSums(cbind(IFS_13,IFS_14,IFS_15,IFS_16),na.rm=FALSE),
         IFS_exclusiveness_mean=round(rowMeans(cbind(IFS_13,IFS_14,IFS_15,IFS_16),na.rm=TRUE),3),
         IFS_sharing_total=rowSums(cbind(IFS_17,IFS_18,IFS_19,IFS_20),na.rm=FALSE),
         IFS_sharing_mean=round(rowMeans(cbind(IFS_17,IFS_18,IFS_19,IFS_20),na.rm=TRUE),3),
         IFS_impose_total=rowSums(cbind(IFS_21,IFS_22,IFS_23,IFS_24),na.rm=FALSE),
         IFS_impose_mean=round(rowMeans(cbind(IFS_21,IFS_22,IFS_23,IFS_24),na.rm=TRUE),3),
         IFS_common_total=rowSums(cbind(IFS_25,IFS_26,IFS_27,IFS_28),na.rm=FALSE),
         IFS_common_mean=round(rowMeans(cbind(IFS_25,IFS_26,IFS_27,IFS_28),na.rm=TRUE),3),
         IFS_trust_total=rowSums(cbind(IFS_29,IFS_30,IFS_31,IFS_32),na.rm=FALSE),
         IFS_trust_mean=round(rowMeans(cbind(IFS_29,IFS_30,IFS_31,IFS_32),na.rm=TRUE),3),
         IFS_total_mean=round(rowMeans(cbind(IFS_1,IFS_2,IFS_3,IFS_4,
                                            IFS_9,IFS_10,IFS_11,IFS_12,
                                            IFS_13,IFS_14,IFS_15,IFS_16,
                                            IFS_17,IFS_18,IFS_19,IFS_20,
                                            IFS_21,IFS_22,IFS_23,IFS_24,
                                            IFS_25,IFS_26,IFS_27,IFS_28,
                                            IFS_29,IFS_30,IFS_31,IFS_32),na.rm=TRUE),3),
         IFS_N=32,
         IFS_missing=rowSums(is.na(cbind(IFS_1,IFS_2,IFS_3,IFS_4,
                                            IFS_9,IFS_10,IFS_11,IFS_12,
                                            IFS_13,IFS_14,IFS_15,IFS_16,
                                            IFS_17,IFS_18,IFS_19,IFS_20,
                                            IFS_21,IFS_22,IFS_23,IFS_24,
                                            IFS_25,IFS_26,IFS_27,IFS_28,
                                            IFS_29,IFS_30,IFS_31,IFS_32))),
         IFS_missing_perc=100*(rowSums(is.na(cbind(IFS_1,IFS_2,IFS_3,IFS_4,
                                            IFS_9,IFS_10,IFS_11,IFS_12,
                                            IFS_13,IFS_14,IFS_15,IFS_16,
                                            IFS_17,IFS_18,IFS_19,IFS_20,
                                            IFS_21,IFS_22,IFS_23,IFS_24,
                                            IFS_25,IFS_26,IFS_27,IFS_28,
                                            IFS_29,IFS_30,IFS_31,IFS_32))))/32) #NV added info on % missing items

## Save it
IFS_Wave1_outdf <- IFS_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(IFS_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/IFS_Wave1.csv"))

IFS_Wave2_outdf <- IFS_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(IFS_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/IFS_Wave2.csv"))

## Graph it
IFS_Wave1_totals<-IFS_Wave1 %>%
  select(tagid,IFS_frankness_total,IFS_trust_total,IFS_common_total,
         IFS_impose_total,IFS_sharing_total,IFS_exclusiveness_total,
         IFS_attachment_total,IFS_sensitivity_total) %>%
  mutate(Frankness_Spontaneity=IFS_frankness_total,
         Trust_Loyalty=IFS_trust_total,
         Common_Activities=IFS_common_total,
         Imposition=IFS_impose_total,
         Giving_Sharing=IFS_sharing_total,
         Exclusiveness=IFS_exclusiveness_total,
         Sensitivity_Knowing=IFS_sensitivity_total,
         Attachment=IFS_attachment_total) %>%
  select(-contains("IFS")) %>%
  gather('item','value',2:length(.)) 
IFS_Wave1_totals_graph<-ggplot(IFS_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("IFS totals for ",length(unique(IFS_Wave1$tagid[!is.na(IFS_Wave1$IFS_attachment_total)]))," participants"))

IFS_Wave1_means<-IFS_Wave1 %>%
  select(tagid,IFS_frankness_mean,IFS_trust_mean,IFS_common_mean,
         IFS_impose_mean,IFS_sharing_mean,IFS_exclusiveness_mean,
         IFS_attachment_mean,IFS_sensitivity_mean) %>%
  mutate(Frankness_Spontaneity=IFS_frankness_mean,
         Trust_Loyalty=IFS_trust_mean,
         Common_Activities=IFS_common_mean,
         Imposition=IFS_impose_mean,
         Giving_Sharing=IFS_sharing_mean,
         Exclusiveness=IFS_exclusiveness_mean,
         Sensitivity_Knowing=IFS_sensitivity_mean,
         Attachment=IFS_attachment_mean) %>%
  select(-contains("IFS")) %>%
  gather('item','value',2:length(.)) 
IFS_Wave1_means_graph<-ggplot(IFS_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("IFS means for ",length(unique(IFS_Wave1$tagid[!is.na(IFS_Wave1$IFS_attachment_mean)]))," participants"))


## Make RDOC ready file
ndar_ifs_data <- left_join(IFS_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         comments_misc=ifelse(grepl("Sess 1",survey_name),"Session1",
                      ifelse(grepl("Session 1",survey_name),"Session1",
                             ifelse(grepl("Sess 2",survey_name),"Session2",
                                    ifelse(grepl("Session 2",survey_name),"Session2",
                                           ifelse(grepl("Home",survey_name),"Home Questionnaires",
                                                  NA))))),
         site="University of Oregon",
         study="Transitions in Adolescent Girls (TAG) Study",
         gender="F",
         ifs_1=IFS_1,
         ifs_2=IFS_2,
         ifs_3=IFS_3,
         ifs_4=IFS_4,
         ifs_5=IFS_5,
         ifs_6=IFS_6,
         ifs_7=IFS_7,
         ifs_8=IFS_8,
         ifs_9=IFS_9,
         ifs_10=IFS_10,
         ifs_11=IFS_11,
         ifs_12=IFS_12,
         ifs_13=IFS_13,
         ifs_14=IFS_14,
         ifs_15=IFS_15,
         ifs_16=IFS_16,
         ifs_17=IFS_17,
         ifs_18=IFS_18,
         ifs_19=IFS_19,
         ifs_20=IFS_20,
         ifs_21=IFS_21,
         ifs_22=IFS_22,
         ifs_23=IFS_23,
         ifs_24=IFS_24,
         ifs_25=IFS_25,
         ifs_26=IFS_26,
         ifs_27=IFS_27,
         ifs_28=IFS_28,
         ifs_29=IFS_29,
         ifs_30=IFS_30,
         ifs_31=IFS_31,
         ifs_32=IFS_32,
         ifs_fs=as.integer(IFS_frankness_mean),
         ifs_sk=as.integer(IFS_sensitivity_mean),
         ifs_aa=as.integer(IFS_attachment_mean),
         ifs_e=as.integer(IFS_exclusiveness_mean),
         ifs_gh=as.integer(IFS_sharing_mean),
         ifs_it=as.integer(IFS_impose_mean),
         ifs_ca=as.integer(IFS_common_mean),
         ifs_tl=as.integer(IFS_trust_mean),
         ifs_ts=as.integer(IFS_total_mean))

ndar_ifs_data <- left_join(ndar_key,ndar_ifs_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("IFS",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
ifs_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/ifs01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
ifs_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/ifs01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
ifs_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/ifs01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

ifs_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/ifs01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
ifs_temp_df<-data.frame(ifs_temp)
ndar_ifs_data<-bind_rows(ifs_temp_df,ndar_ifs_data)

part2<-colnames(ndar_ifs_data)
part3<-as.matrix(ndar_ifs_data)
colnames(part3)<-NULL
together<-rbind(ifs_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/ifs01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,ifs_df_header,ifs_temp,ifs_temp_df,IFS,IFS_Wave1_means,IFS_Wave1,IFS_Wave1_totals,IFS_Wave1_totals_graph)

```

Prepare IRI
```{r}
IRI<-left_join(filter(cleaned_survey_data, grepl("IRI",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

IRI_Wave1<-left_join(IRI,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 1 - V2",sa_date,
                                   ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                   )))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  # select(-IRI_1,-IRI_5,-IRI_7,-IRI_12,-IRI_16,-IRI_23,-IRI_26) %>%
  mutate(IRI_3=ifelse(IRI_3==0,4,
                      ifelse(IRI_3==1,3,
                             ifelse(IRI_3==2,2,
                                    ifelse(IRI_3==3,1,
                                           ifelse(IRI_3==4,0,
                                                  NA))))),
         IRI_4=ifelse(IRI_4==0,4,
                      ifelse(IRI_4==1,3,
                             ifelse(IRI_4==2,2,
                                    ifelse(IRI_4==3,1,
                                           ifelse(IRI_4==4,0,
                                                  NA))))),
         IRI_13=ifelse(IRI_13==0,4,
                       ifelse(IRI_13==1,3,
                              ifelse(IRI_13==2,2,
                                     ifelse(IRI_13==3,1,
                                            ifelse(IRI_13==4,0,
                                                   NA))))),
         IRI_14=ifelse(IRI_14==0,4,
                       ifelse(IRI_14==1,3,
                              ifelse(IRI_14==2,2,
                                     ifelse(IRI_14==3,1,
                                            ifelse(IRI_14==4,0,
                                                   NA))))),
         IRI_15=ifelse(IRI_15==0,4,
                       ifelse(IRI_15==1,3,
                              ifelse(IRI_15==2,2,
                                     ifelse(IRI_15==3,1,
                                            ifelse(IRI_15==4,0,
                                                   NA))))),
         IRI_18=ifelse(IRI_18==0,4,
                       ifelse(IRI_18==1,3,
                              ifelse(IRI_18==2,2,
                                     ifelse(IRI_18==3,1,
                                            ifelse(IRI_18==4,0,
                                                   NA))))),
         IRI_19=ifelse(IRI_19==0,4,
                       ifelse(IRI_19==1,3,
                              ifelse(IRI_19==2,2,
                                     ifelse(IRI_19==3,1,
                                            ifelse(IRI_19==4,0,
                                                   NA)))))) %>%
  mutate(IRI_PT=7,
         IRI_PT_missing=rowSums(is.na(cbind(IRI_3,IRI_8,IRI_11,IRI_15,IRI_21,IRI_25,IRI_28))),
         IRI_PT_missing_perc=100*(rowSums(is.na(cbind(IRI_3,IRI_8,IRI_11,IRI_15,IRI_21,IRI_25,IRI_28))))/7,
         IRI_PT_total=rowSums(cbind(IRI_3,IRI_8,IRI_11,IRI_15,IRI_21,IRI_25,IRI_28), na.rm=F),
         IRI_PT_mean=rowMeans(cbind(IRI_3,IRI_8,IRI_11,IRI_15,IRI_21,IRI_25,IRI_28), na.rm=T),
         IRI_EC=7,
         IRI_EC_missing=rowSums(is.na(cbind(IRI_2,IRI_4,IRI_9,IRI_14,IRI_18,IRI_20,IRI_22))),
         IRI_EC_missing_perc=100*(rowSums(is.na(cbind(IRI_2,IRI_4,IRI_9,IRI_14,IRI_18,IRI_20,IRI_22))))/7,
         IRI_EC_total=rowSums(cbind(IRI_2,IRI_4,IRI_9,IRI_14,IRI_18,IRI_20,IRI_22), na.rm=F),
         IRI_EC_mean=rowMeans(cbind(IRI_2,IRI_4,IRI_9,IRI_14,IRI_18,IRI_20,IRI_22), na.rm=T),
         IRI_PD=7,
         IRI_PD_missing=rowSums(is.na(cbind(IRI_6,IRI_10,IRI_13,IRI_17,IRI_19,IRI_24,IRI_27))),
         IRI_PD_missing_perc=100*(rowSums(is.na(cbind(IRI_6,IRI_10,IRI_13,IRI_17,IRI_19,IRI_24,IRI_27))))/7,
         IRI_PD_total=rowSums(cbind(IRI_6,IRI_10,IRI_13,IRI_17,IRI_19,IRI_24,IRI_27), na.rm=F),
         IRI_PD_mean=rowMeans(cbind(IRI_6,IRI_10,IRI_13,IRI_17,IRI_19,IRI_24,IRI_27), na.rm=T),
         IRI_FS_total = NA)

## Save it
IRI_Wave1_outdf <- IRI_Wave1 %>% filter(!grepl("W2|W3",survey_name))
write.csv(IRI_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/IRI_Wave1.csv"))

IRI_Wave2_outdf <- IRI_Wave1 %>% filter(grepl("W2",survey_name))
write.csv(IRI_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/IRI_Wave2.csv"))

IRI_Wave3_outdf <- IRI_Wave1 %>% filter(grepl("W3",survey_name))
write.csv(IRI_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/IRI_Wave3.csv"))

## Graph it
IRI_Wave1_totals<-IRI_Wave1 %>%
  select(tagid,IRI_PT_total,IRI_EC_total,IRI_PD_total) %>%
  mutate(Perspective_Taking=IRI_PT_total,
         Empathic_Concern=IRI_EC_total,
         Personal_Distress=IRI_PD_total) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("IRI_",item))
IRI_Wave1_totals_graph<-ggplot(IRI_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("IRI total subscores for ",length(unique(IRI_Wave1$tagid[!is.na(IRI_Wave1$tagid)]))," participants"))

IRI_Wave1_means<-IRI_Wave1 %>%
  select(tagid,IRI_PT_mean,IRI_EC_mean,IRI_PD_mean) %>%
  mutate(Perspective_Taking=IRI_PT_mean,
         Empathic_Concern=IRI_EC_mean,
         Personal_Distress=IRI_PD_mean) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("IRI_",item))
IRI_Wave1_means_graph<-ggplot(IRI_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("IRI mean subscores for ",length(unique(IRI_Wave1$tagid[!is.na(IRI_Wave1$tagid)]))," participants"))

## Make RDOC ready file
ndar_iri_data <- left_join(IRI_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         comments_misc=ifelse(grepl("Sess 1",survey_name),"Session1",
                              ifelse(grepl("Sess 2",survey_name),"Session2",
                                     ifelse(grepl("Home",survey_name),"Home Questionnaires",NA))),
         gender="F",
         daydream=IRI_1,
         tender_feelings=IRI_2,
         difficult_other_pov=IRI_3,
         dont_feel_sorry_problems=IRI_4,
         involved_characters=IRI_5,
         emergency_apprehension=IRI_6,
         objective_watching=IRI_7,
         all_sides_disagreement=IRI_8,
         protective=IRI_9,
         helpless=IRI_10,
         other_perspective=IRI_11,
         involved_rare=IRI_12,
         hurt_stay_calm=IRI_13,
         misfortunes_not_disturbed=IRI_14,
         arguments_dont_listen=IRI_15,
         movie_characters=IRI_16,
         tense_emotional=IRI_17,
         unfairly_pity=IRI_18,
         effective_emergencies=IRI_19,
         touched=IRI_20,
         see_both_sides=IRI_21,
         describe_soft_hearted=IRI_22,
         movie_characters_relate=IRI_23,
         emergencies_lose_control=IRI_24,
         upset_try_shoes=IRI_25,
         novel_if_in_story=IRI_26,
         help_go_to_pieces=IRI_27,
         before_criticizing=IRI_28,
         iripd=ifelse(is.na(IRI_PD_total),999,IRI_PD_total),
         iript=ifelse(is.na(IRI_PT_total),999,IRI_PT_total),
         iriec=ifelse(is.na(IRI_EC_total),999,IRI_EC_total),
         irifs=ifelse(is.na(IRI_FS_total),999,IRI_FS_total))
ndar_iri_data <- left_join(ndar_key,ndar_iri_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("IRI",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
iri_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/iri01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
iri_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/iri01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
iri_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/iri01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

iri_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/iri01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
iri_temp_df<-data.frame(iri_temp)
ndar_iri_data<-bind_rows(iri_temp_df,ndar_iri_data)

part2<-colnames(ndar_iri_data)
part3<-as.matrix(ndar_iri_data)
colnames(part3)<-NULL
together<-rbind(iri_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/iri01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,iri_df_header,iri_temp,iri_temp_df,IRI,IRI_Wave1,IRI_Wave1_means,IRI_Wave1_means_graph,IRI_Wave1_totals,IRI_Wave1_totals_graph)

```

Prepare K-SRQ 
```{r}
#duplicate identifiers - needs to be fixed
KSRQ<-left_join(filter(cleaned_survey_data, grepl("K_SRQ",item)) %>%
                  mutate(value=as.numeric(value)) %>% 
                  filter(!is.na(value)) %>%
                  filter(!value=="") %>%
                  distinct(tagid,item,survey_name,value,.keep_all = FALSE) %>% 
                  group_by(tagid,item,survey_name) %>%
                  mutate(nrow = n(),
                         value = ifelse(nrow > 1, NA, value)) %>%
                  distinct(tagid,item,survey_name,value,.keep_all = FALSE) %>% 
                  spread(item,value),
                redcap_cleaned %>%
                  filter(!is.na(dob),!is.na(sa_date)) %>%
                  select(tagid, sa_date, sb_date, dob),by="tagid")

KSRQ<-left_join(filter(cleaned_survey_data, grepl("K_SRQ",item)) %>%
                  mutate(value=as.numeric(value)) %>% 
                  filter(!is.na(value)) %>%
                  filter(!value=="") %>%
                  distinct(tagid,item,value,.keep_all = FALSE) %>% 
                  mutate(survey_name="Sess 1") %>%
                  spread(item,value),
                redcap_cleaned %>%
                  filter(!is.na(dob),!is.na(sa_date)) %>%
                  select(tagid, sa_date, sb_date, dob),by="tagid")

KSRQ_Wave1<-left_join(KSRQ,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=qualtrics_date) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(KSRQ_adm_mean=round(rowMeans(cbind(K_SRQ_1,K_SRQ_7,K_SRQ_11,K_SRQ_17), na.rm=T),3),
         KSRQ_negsoc_mean=round(rowMeans(cbind(K_SRQ_3,K_SRQ_5,K_SRQ_13,K_SRQ_16), na.rm=T),3),
         KSRQ_pass_mean=round(rowMeans(cbind(K_SRQ_12,K_SRQ_20,K_SRQ_22), na.rm=T),3),
         KSRQ_prosoc_mean=round(rowMeans(cbind(K_SRQ_2,K_SRQ_6,K_SRQ_15,K_SRQ_18,K_SRQ_21), na.rm=T),3),
         KSRQ_sex_mean=round(rowMeans(cbind(K_SRQ_9,K_SRQ_19), na.rm=T),3),
         KSRQ_social_mean=round(rowMeans(cbind(K_SRQ_4,K_SRQ_10,K_SRQ_14), na.rm=T),3))

## Save it
KSRQ_Wave1_outdf <- KSRQ_Wave1 %>% filter(!grepl("W2|W3",survey_name))
write.csv(KSRQ_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/KSRQ_Wave1.csv"))

KSRQ_Wave2_outdf <- KSRQ_Wave1 %>% filter(grepl("W2",survey_name))
write.csv(KSRQ_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/KSRQ_Wave2.csv"))

KSRQ_Wave3_outdf <- KSRQ_Wave1 %>% filter(grepl("W3",survey_name))
write.csv(KSRQ_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/KSRQ_Wave3.csv"))

## Graph it
KSRQ_Wave1_means<-KSRQ_Wave1 %>%
  select(tagid,KSRQ_adm_mean,KSRQ_negsoc_mean,KSRQ_pass_mean,KSRQ_prosoc_mean,
         KSRQ_sex_mean,KSRQ_social_mean) %>%
  mutate(Admiration=KSRQ_adm_mean,
         Negative_Social_Potency=KSRQ_negsoc_mean,
         Passivity=KSRQ_pass_mean,
         Prosocial_Interactions=KSRQ_prosoc_mean,
         Sexual_Relationships=KSRQ_sex_mean,
         Sociability=KSRQ_social_mean) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("KSRQ_",item))
KSRQ_Wave1_means_graph<-ggplot(KSRQ_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("KSRQ mean subscores for ",length(unique(KSRQ_Wave1$tagid[!is.na(KSRQ_Wave1$tagid)]))," participants"))

## Make RDOC ready file
ndar_ksrq_data <- left_join(KSRQ_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date)) %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         comments_misc=ifelse(grepl("Sess 1",survey_name),"Session1",
                             ifelse(grepl("Sess 2",survey_name),"Session2",
                                           ifelse(grepl("Home",survey_name),"Home Questionnaires",NA))),
         version_form="Child version",
         site="University of Oregon",
         study="Transitions in Adolescent Girls (TAG) Study",
         ksrq_1=K_SRQ_1,
         ksrq_2=K_SRQ_2,
         ksrq_3=K_SRQ_3,
         ksrq_4=K_SRQ_4,
         ksrq_5=K_SRQ_5,
         ksrq_6=K_SRQ_6,
         ksrq_7=K_SRQ_7,
         ksrq_8=K_SRQ_8,
         ksrq_9=K_SRQ_9,
         ksrq_10=K_SRQ_10,
         ksrq_11=K_SRQ_11,
         ksrq_12=K_SRQ_12,
         ksrq_13=-99,
         ksrq_14=K_SRQ_13,
         ksrq_15=K_SRQ_14,
         ksrq_16=K_SRQ_15,
         ksrq_17=K_SRQ_16,
         ksrq_18=K_SRQ_17,
         ksrq_19=K_SRQ_18,
         ksrq_20=K_SRQ_19,
         ksrq_21=K_SRQ_20,
         ksrq_22=K_SRQ_21,
         ksrq_23=K_SRQ_22,
         ksrq_adm=KSRQ_adm_mean,
         krsq_negsoc=KSRQ_negsoc_mean,
         krsq_pass=KSRQ_pass_mean,
         krsq_prosoc=KSRQ_prosoc_mean,
         krsq_sex=KSRQ_sex_mean,
         krsq_social=KSRQ_social_mean)
ndar_ksrq_data <- left_join(ndar_key,ndar_ksrq_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("SRQ",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
ksrq_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/srq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
ksrq_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/srq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
ksrq_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/srq01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

ksrq_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/srq01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
ksrq_temp_df<-data.frame(ksrq_temp)
ndar_ksrq_data<-bind_rows(ksrq_temp_df,ndar_ksrq_data)

part2<-colnames(ndar_ksrq_data)
part3<-as.matrix(ndar_ksrq_data)
colnames(part3)<-NULL
together<-rbind(ksrq_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/srq01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,ksrq_df_header,ksrq_temp,ksrq_temp_df,KSRQ,KSRQ_Wave1,KSRQ_Wave1_means,KSRQ_Wave1_means_graph)
```

Prepare MSPSS
```{r}
MSPSS<-left_join(filter(cleaned_survey_data, grepl("MSPSS",item)) %>%
                  mutate(value=as.numeric(value)) %>% 
                  filter(!is.na(value)) %>%
                  filter(!value=="") %>%
                  distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                  spread(item,value),
                redcap_cleaned %>%
                  filter(!is.na(dob),!is.na(sa_date)) %>%
                  select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(MSPSS$tagid) == length(unique(MSPSS$tagid))){
  print("No duplicate tagids in data")
}

TAG023_special<-left_join(filter(cleaned_survey_data, grepl("MSPSS",item)) %>%
                            mutate(value=as.numeric(value)) %>% 
                            filter(!is.na(value)) %>%
                            filter(!value=="") %>%
                            filter(tagid=="TAG023") %>%
                            filter(!grepl("W2", survey_name)) %>% 
                            distinct(tagid,item,value,.keep_all = FALSE) %>%
                            spread(item,value),
                          redcap_cleaned %>%
                            filter(wave==1,!is.na(dob),!is.na(sa_date),tagid=="TAG023") %>%
                            select(tagid, sa_date, sb_date, dob),by="tagid") %>%
  mutate(survey_name="TAG - Sess 1 - V1")

MSPSS <- bind_rows(MSPSS %>% filter(!tagid=="TAG023"),TAG023_special)

MSPSS_Wave1<-left_join(MSPSS,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 1 - V4 - Current",sa_date,
                            ifelse(survey_name=="TAG - Sess 1 - V1",sa_date,
                                   ifelse(survey_name=="TAG - Sess 1 - V2",sa_date,
                                          ifelse(survey_name=="TAG - Sess 1 - V3",sa_date,
                                                 ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                                 )))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(MSPSS_fam_total=rowSums(cbind(MSPSS_3,MSPSS_4,MSPSS_8,MSPSS_11), na.rm=F),
         MSPSS_fri_total=rowSums(cbind(MSPSS_6,MSPSS_7,MSPSS_9,MSPSS_12), na.rm=F),
         MSPSS_so_total=rowSums(cbind(MSPSS_1,MSPSS_2,MSPSS_5,MSPSS_10), na.rm=F),
         MSPSS_fam_mean=rowMeans(cbind(MSPSS_3,MSPSS_4,MSPSS_8,MSPSS_11), na.rm=T),
         MSPSS_fri_mean=rowMeans(cbind(MSPSS_6,MSPSS_7,MSPSS_9,MSPSS_12), na.rm=T),
         MSPSS_so_mean=rowMeans(cbind(MSPSS_1,MSPSS_2,MSPSS_5,MSPSS_10), na.rm=T),
         MSPSS_mean=rowMeans(cbind(MSPSS_1,MSPSS_2,MSPSS_3,MSPSS_4,MSPSS_5,MSPSS_6,MSPSS_7,
                                   MSPSS_8,MSPSS_9,MSPSS_10,MSPSS_11,MSPSS_12), na.rm=T)) %>%
  mutate(MSPSS_total=rowSums(cbind(MSPSS_fam_total,MSPSS_fri_total,MSPSS_so_total), na.rm=F),
         MSPSS_fam_N=4,
         MSPSS_fam_missing=rowSums(is.na(cbind(MSPSS_3,MSPSS_4,MSPSS_8,MSPSS_11))),
         MSPSS_fam_missing_perc=100*(rowSums(is.na(cbind(MSPSS_3,MSPSS_4,MSPSS_8,MSPSS_11))))/4,
         MSPSS_fri_N=4,
         MSPSS_fri_missing=rowSums(is.na(cbind(MSPSS_6,MSPSS_7,MSPSS_9,MSPSS_12))),
         MSPSS_fri_missing_perc=100*(rowSums(is.na(cbind(MSPSS_6,MSPSS_7,MSPSS_9,MSPSS_12))))/4,
         MSPSS_so_N=4,
         MSPSS_so_missing=rowSums(is.na(cbind(MSPSS_1,MSPSS_2,MSPSS_5,MSPSS_10))),
         MSPSS_so_missing_perc=100*(rowSums(is.na(cbind(MSPSS_1,MSPSS_2,MSPSS_5,MSPSS_10))))/4,
         MSPSS_N=12,
         MSPSS_missing=rowSums(is.na(cbind(MSPSS_1,MSPSS_2,MSPSS_3,MSPSS_4,MSPSS_5,MSPSS_6,MSPSS_7,MSPSS_8,MSPSS_9,MSPSS_10,MSPSS_11,MSPSS_12))),
         MSPSS_missing_perc=100*(rowSums(is.na(cbind(MSPSS_1,MSPSS_2,MSPSS_3,MSPSS_4,MSPSS_5,MSPSS_6,MSPSS_7,MSPSS_8,MSPSS_9,MSPSS_10,MSPSS_11,MSPSS_12))))/12) #NV added info on % missing items

## Save it
MSPSS_Wave1_outdf <- MSPSS_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(MSPSS_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/MSPSS_Wave1.csv"))

MSPSS_Wave2_outdf <- MSPSS_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(MSPSS_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/MSPSS_Wave2.csv"))

MSPSS_Wave3_outdf <- MSPSS_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(MSPSS_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/MSPSS_Wave3.csv"))

## Graph it
MSPSS_Wave1_totals<-MSPSS_Wave1 %>%
  select(tagid,MSPSS_fam_total,MSPSS_fri_total,MSPSS_so_total) %>%
  mutate(Family_Support=MSPSS_fam_total,
         Friend_Support=MSPSS_fri_total,
         SigOther_Support=MSPSS_so_total) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("MSPSS_",item))
MSPSS_Wave1_totals_graph<-ggplot(MSPSS_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("MSPSS total subscores for ",length(unique(MSPSS_Wave1$tagid[!is.na(MSPSS_Wave1$tagid)]))," participants"))

MSPSS_Wave1_means<-MSPSS_Wave1 %>%
  select(tagid,MSPSS_fam_mean,MSPSS_fri_mean,MSPSS_so_mean) %>%
  mutate(Family_Support=MSPSS_fam_mean,
         Friend_Support=MSPSS_fri_mean,
         SigOther_Support=MSPSS_so_mean) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("MSPSS_",item))
MSPSS_Wave1_means_graph<-ggplot(MSPSS_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("MSPSS mean subscores for ",length(unique(MSPSS_Wave1$tagid[!is.na(MSPSS_Wave1$tagid)]))," participants"))

## Make RDOC ready file
ndar_mspss_data <- left_join(MSPSS_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         timept=1,
         mspss_1=MSPSS_1,
         mspss_2=MSPSS_2,
         mspss_3=MSPSS_3,
         mspss_4=MSPSS_4,
         mspss_5=MSPSS_5,
         mspss_6=MSPSS_6,
         mspss_7=MSPSS_7,
         mspss_8=MSPSS_8,
         mspss_9=MSPSS_9,
         mspss_10=MSPSS_10,
         mspss_11=MSPSS_11,
         mspss_12=MSPSS_12,
         mspss_fam=ifelse(is.na(MSPSS_fam_total),999,MSPSS_fam_total),
         mspss_fri=ifelse(is.na(MSPSS_fri_total),999,MSPSS_fri_total),
         mspss_so=ifelse(is.na(MSPSS_so_total),999,MSPSS_so_total),
         mspss_total=ifelse(is.na(MSPSS_total),999,MSPSS_total))
ndar_mspss_data <- left_join(ndar_key,ndar_mspss_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("MSPSS",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
mspss_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/mspss01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
mspss_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/mspss01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
mspss_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/mspss01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

mspss_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/mspss01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
mspss_temp_df<-data.frame(mspss_temp)
ndar_mspss_data<-bind_rows(mspss_temp_df,ndar_mspss_data)

part2<-colnames(ndar_mspss_data)
part3<-as.matrix(ndar_mspss_data)
colnames(part3)<-NULL
together<-rbind(mspss_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/mspss01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,mspss_df_header,mspss_temp,mspss_temp_df,MSPSS,MSPSS_Wave1,MSPSS_Wave1_means,MSPSS_Wave1_means_graph,
   MSPSS_Wave1_totals,MSPSS_Wave1_totals_graph)
```

Prepare PSS
```{r}
PSS<-left_join(filter(cleaned_survey_data, grepl("^PSS",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 mutate(value=ifelse(tagid=="TAG132" && item=="PSS_5",4,
                                     ifelse(tagid=="TAG132" && item=="PSS_6",2,
                                            ifelse(tagid=="TAG132" && item=="PSS_7",3,
                                                   ifelse(tagid=="TAG132" && item=="PSS_9",2,value))))
                 ) %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(PSS$tagid) == length(unique(PSS$tagid))){
  print("No duplicate tagids in data")
}

PSS_Wave1<-left_join(PSS,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 1 - V4 - Current",sa_date,
                            ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                          ifelse(survey_name=="TAG - Sess 1 - V3",sa_date,
                                                 ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                                 )))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>% # remove this line when making RDoC db document
  mutate(PSS_4=ifelse(PSS_4==0,4,
                      ifelse(PSS_4==1,3,
                             ifelse(PSS_4==2,2,
                                    ifelse(PSS_4==3,1,
                                           ifelse(PSS_4==4,0,
                                                  88))))),
         PSS_5=ifelse(PSS_5==0,4,
                      ifelse(PSS_5==1,3,
                             ifelse(PSS_5==2,2,
                                    ifelse(PSS_5==3,1,
                                           ifelse(PSS_5==4,0,
                                                  88))))),
         PSS_7=ifelse(PSS_7==0,4,
                      ifelse(PSS_7==1,3,
                             ifelse(PSS_7==2,2,
                                    ifelse(PSS_7==3,1,
                                           ifelse(PSS_7==4,0,
                                                  88))))),
         PSS_8=ifelse(PSS_8==0,4,
                      ifelse(PSS_8==1,3,
                             ifelse(PSS_8==2,2,
                                    ifelse(PSS_8==3,1,
                                           ifelse(PSS_8==4,0,
                                                  88)))))) %>%
  mutate(PSS_total=rowSums(cbind(PSS_1,PSS_2,PSS_3,PSS_4,PSS_5,PSS_6,PSS_7,PSS_8,PSS_9,PSS_10), na.rm=F),
         PSS_mean=rowMeans(cbind(PSS_1,PSS_2,PSS_3,PSS_4,PSS_5,PSS_6,PSS_7,PSS_8,PSS_9,PSS_10), na.rm=T))
  
## Save it
PSS_Wave1_outdf <- PSS_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(PSS_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/PSS_Wave1.csv"))

PSS_Wave2_outdf <- PSS_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(PSS_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/PSS_Wave2.csv"))

PSS_Wave3_outdf <- PSS_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(PSS_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/PSS_Wave3.csv"))

## Graph it
PSS_Wave1_totals<-PSS_Wave1 %>%
  select(tagid,PSS_total) %>%
  mutate(Perceived_Stress=PSS_total) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("PSS_",item))
PSS_Wave1_totals_graph<-ggplot(PSS_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("PSS total score for ",length(unique(PSS_Wave1$tagid[!is.na(PSS_Wave1$PSS_total)]))," participants"))

PSS_Wave1_means<-PSS_Wave1 %>%
  select(tagid,PSS_mean) %>%
  mutate(Perceived_Stress=PSS_mean) %>%
  gather('item','value',2:length(.)) %>%
  filter(!grepl("PSS_",item))
PSS_Wave1_means_graph<-ggplot(PSS_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("PSS mean score for ",length(unique(PSS_Wave1$tagid[!is.na(PSS_Wave1$tagid)]))," participants"))


## Make RDOC ready file
ndar_pss_data <- left_join(PSS_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         visit=ifelse(grepl("Sess 1",survey_name),"Session1",
                      ifelse(grepl("Session 1",survey_name),"Session1",
                             ifelse(grepl("Sess 2",survey_name),"Session2",
                                    ifelse(grepl("Session 2",survey_name),"Session2",
                                           ifelse(grepl("Home",survey_name),"Home Questionnaires",
                                           NA))))),
         version_form="PSS-10",
         respondent="Child",
         pssp1_1=PSS_1,
         pssp1_2=PSS_2,
         pssp1_3=PSS_3,
         pssp2_1=PSS_4,
         pssp2_2=PSS_5,
         pssp2_3=PSS_6,
         pssp2_4=PSS_7,
         pssp2_5=PSS_8,
         pssp3_1=PSS_9,
         pssp3_4=PSS_10,
         pss_totalscore=ifelse(is.na(PSS_total),999,PSS_total))

ndar_pss_data <- left_join(ndar_key,ndar_pss_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("PSS",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
pss_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/pss01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
pss_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/pss01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
pss_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/pss01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

pss_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/pss01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
pss_temp_df<-data.frame(pss_temp)
ndar_pss_data<-bind_rows(pss_temp_df,ndar_pss_data)

part2<-colnames(ndar_pss_data)
part3<-as.matrix(ndar_pss_data)
colnames(part3)<-NULL
together<-rbind(pss_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/pss01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,pss_df_header,pss_temp,pss_temp_df,PSS,PSS_Wave1,PSS_Wave1_means,PSS_Wave1_means_graph,
   PSS_Wave1_totals,PSS_Wave1_totals_graph)
```

Prepare RMET
```{r}
RMET<-left_join(filter(cleaned_survey_data, grepl("RMET",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(RMET$tagid) == length(unique(RMET$tagid))){
  print("No duplicate TAGIDs in data")
}

RMET_Wave1<-left_join(RMET,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 1 - V2",sa_date,
                                   ifelse(survey_name=="TAG - Sess 1 - V3",sa_date,
                                          ifelse(survey_name=="TAG - Sess 1 - V4 - Current",sa_date,
                                                 ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                                 )))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>% 
  mutate(RMET_1_correct=ifelse(RMET_1==1,0,
                               ifelse(RMET_1==2,0,
                                      ifelse(RMET_1==3,1,
                                             ifelse(RMET_1==4,0,NA)))),
         RMET_2_correct=ifelse(RMET_2==1,0,
                               ifelse(RMET_2==2,0,
                                      ifelse(RMET_2==3,0,
                                             ifelse(RMET_2==4,1,NA)))),
         RMET_3_correct=ifelse(RMET_3==1,1,
                               ifelse(RMET_3==2,0,
                                      ifelse(RMET_3==3,0,
                                             ifelse(RMET_3==4,0,NA)))),
         RMET_4_correct=ifelse(RMET_4==1,0,
                               ifelse(RMET_4==2,1,
                                      ifelse(RMET_4==3,0,
                                             ifelse(RMET_4==4,0,NA)))),
         RMET_5_correct=ifelse(RMET_5==1,0,
                               ifelse(RMET_5==2,1,
                                      ifelse(RMET_5==3,0,
                                             ifelse(RMET_5==4,0,NA)))),
         RMET_6_correct=ifelse(RMET_6==1,0,
                               ifelse(RMET_6==2,0,
                                      ifelse(RMET_6==3,1,
                                             ifelse(RMET_6==4,0,NA)))),
         RMET_7_correct=ifelse(RMET_7==1,0,
                               ifelse(RMET_7==2,0,
                                      ifelse(RMET_7==3,1,
                                             ifelse(RMET_7==4,0,NA)))),
         RMET_8_correct=ifelse(RMET_8==1,1,
                               ifelse(RMET_8==2,0,
                                      ifelse(RMET_8==3,0,
                                             ifelse(RMET_8==4,0,NA)))),
         RMET_9_correct=ifelse(RMET_9==1,0,
                               ifelse(RMET_9==2,0,
                                      ifelse(RMET_9==3,0,
                                             ifelse(RMET_9==4,1,NA)))),
         RMET_10_correct=ifelse(RMET_10==1,0,
                               ifelse(RMET_10==2,0,
                                      ifelse(RMET_10==3,1,
                                             ifelse(RMET_10==4,0,NA)))),
         RMET_11_correct=ifelse(RMET_11==1,0,
                               ifelse(RMET_11==2,1,
                                      ifelse(RMET_11==3,0,
                                             ifelse(RMET_11==4,0,NA)))),
         RMET_12_correct=ifelse(RMET_12==1,0,
                               ifelse(RMET_12==2,0,
                                      ifelse(RMET_12==3,0,
                                             ifelse(RMET_12==4,1,NA)))),
         RMET_13_correct=ifelse(RMET_13==1,1,
                               ifelse(RMET_13==2,0,
                                      ifelse(RMET_13==3,0,
                                             ifelse(RMET_13==4,0,NA)))),
         RMET_14_correct=ifelse(RMET_14==1,0,
                               ifelse(RMET_14==2,1,
                                      ifelse(RMET_14==3,0,
                                             ifelse(RMET_14==4,0,NA)))),
         RMET_15_correct=ifelse(RMET_15==1,1,
                               ifelse(RMET_15==2,0,
                                      ifelse(RMET_15==3,0,
                                             ifelse(RMET_15==4,0,NA)))),
         RMET_16_correct=ifelse(RMET_16==1,1,
                               ifelse(RMET_16==2,0,
                                      ifelse(RMET_16==3,0,
                                             ifelse(RMET_16==4,0,NA)))),
         RMET_17_correct=ifelse(RMET_17==1,0,
                               ifelse(RMET_17==2,0,
                                      ifelse(RMET_17==3,0,
                                             ifelse(RMET_17==4,1,NA)))),
         RMET_18_correct=ifelse(RMET_18==1,1,
                               ifelse(RMET_18==2,0,
                                      ifelse(RMET_18==3,0,
                                             ifelse(RMET_18==4,0,NA)))),
         RMET_19_correct=ifelse(RMET_19==1,0,
                               ifelse(RMET_19==2,0,
                                      ifelse(RMET_19==3,0,
                                             ifelse(RMET_19==4,1,NA)))),
         RMET_20_correct=ifelse(RMET_20==1,0,
                               ifelse(RMET_20==2,0,
                                      ifelse(RMET_20==3,1,
                                             ifelse(RMET_20==4,0,NA)))),
         RMET_21_correct=ifelse(RMET_21==1,1,
                               ifelse(RMET_21==2,0,
                                      ifelse(RMET_21==3,0,
                                             ifelse(RMET_21==4,0,NA)))),
         RMET_22_correct=ifelse(RMET_22==1,0,
                               ifelse(RMET_22==2,0,
                                      ifelse(RMET_22==3,0,
                                             ifelse(RMET_22==4,1,NA)))),
         RMET_23_correct=ifelse(RMET_23==1,0,
                               ifelse(RMET_23==2,1,
                                      ifelse(RMET_23==3,0,
                                             ifelse(RMET_23==4,0,NA)))),
         RMET_24_correct=ifelse(RMET_24==1,1,
                               ifelse(RMET_24==2,0,
                                      ifelse(RMET_24==3,0,
                                             ifelse(RMET_24==4,0,NA)))),
         RMET_25_correct=ifelse(RMET_25==1,0,
                               ifelse(RMET_25==2,0,
                                      ifelse(RMET_25==3,0,
                                             ifelse(RMET_25==4,1,NA)))),
         RMET_26_correct=ifelse(RMET_26==1,0,
                               ifelse(RMET_26==2,0,
                                      ifelse(RMET_26==3,1,
                                             ifelse(RMET_26==4,0,NA)))),
         RMET_27_correct=ifelse(RMET_27==1,0,
                               ifelse(RMET_27==2,0,
                                      ifelse(RMET_27==3,1,
                                             ifelse(RMET_27==4,0,NA)))),
         RMET_28_correct=ifelse(RMET_28==1,0,
                               ifelse(RMET_28==2,0,
                                      ifelse(RMET_28==3,1,
                                             ifelse(RMET_28==4,0,NA)))),
         RMET_missing=rowSums(is.na(cbind(RMET_1,RMET_2,RMET_3,RMET_4,RMET_5,RMET_6,
                                          RMET_7,RMET_8,RMET_9,RMET_10,RMET_11,RMET_12,
                                          RMET_13,RMET_14,RMET_15,RMET_16,RMET_17,
                                          RMET_18,RMET_19,RMET_20,RMET_21,RMET_22,
                                          RMET_23,RMET_24,RMET_25,RMET_26,
                                          RMET_27,RMET_28))))%>%
  mutate(RMET_1_numcompleted=(28-RMET_missing),
         RMET_Total_Score=rowSums(cbind(RMET_1_correct,RMET_2_correct,
                                        RMET_3_correct,RMET_4_correct,
                                        RMET_5_correct,RMET_6_correct,
                                        RMET_7_correct,RMET_8_correct,
                                        RMET_9_correct,RMET_10_correct,
                                        RMET_11_correct,RMET_12_correct,
                                        RMET_13_correct,RMET_14_correct,
                                        RMET_15_correct,RMET_16_correct,
                                        RMET_17_correct,RMET_18_correct,
                                        RMET_19_correct,RMET_20_correct,
                                        RMET_21_correct,RMET_22_correct,
                                        RMET_23_correct,RMET_24_correct,
                                        RMET_25_correct,RMET_26_correct,
                                        RMET_27_correct,RMET_28_correct),na.rm = F)) %>%
  mutate(RMET_Percent_Correct=(rowSums(cbind(RMET_1_correct,RMET_2_correct,
                                        RMET_3_correct,RMET_4_correct,
                                        RMET_5_correct,RMET_6_correct,
                                        RMET_7_correct,RMET_8_correct,
                                        RMET_9_correct,RMET_10_correct,
                                        RMET_11_correct,RMET_12_correct,
                                        RMET_13_correct,RMET_14_correct,
                                        RMET_15_correct,RMET_16_correct,
                                        RMET_17_correct,RMET_18_correct,
                                        RMET_19_correct,RMET_20_correct,
                                        RMET_21_correct,RMET_22_correct,
                                        RMET_23_correct,RMET_24_correct,
                                        RMET_25_correct,RMET_26_correct,
                                        RMET_27_correct,RMET_28_correct),na.rm = T)/RMET_1_numcompleted)*100)
## Save it
RMET_Wave1_outdf <- RMET_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(RMET_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/RMET_Wave1.csv"))

RMET_Wave2_outdf <- RMET_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(RMET_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/RMET_Wave2.csv"))

RMET_Wave3_outdf <- RMET_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(RMET_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/RMET_Wave3.csv"))

## Graph it
RMET_Wave1_percentcorrect<-RMET_Wave1 %>%
  select(tagid,RMET_Percent_Correct) %>%
  gather('item','value',2:length(.)) 
RMET_Wave1_percentcorrect_graph<-ggplot(RMET_Wave1_percentcorrect, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("RMET Percent Correct for ",length(unique(RMET_Wave1$tagid[!is.na(RMET_Wave1$RMET_Percent_Correct)]))," participants"))


## Make RDOC ready file
ndar_rmet_data <- left_join(RMET_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         visit=ifelse(grepl("Sess 1",survey_name),"Session1",
                      ifelse(grepl("Session 1",survey_name),"Session1",
                             ifelse(grepl("Sess 2",survey_name),"Session2",
                                    ifelse(grepl("Session 2",survey_name),"Session2",
                                           ifelse(grepl("Home",survey_name),"Home Questionnaires",
                                                  NA))))),
         version_form="Child Version",
         site="University of Oregon",
         gender="F",
         rmet_cv001=RMET_1,
         rmet_cv002=RMET_2,
         rmet_cv003=RMET_3,
         rmet_cv004=RMET_4,
         rmet_cv005=RMET_5,
         rmet_cv006=RMET_6,
         rmet_cv007=RMET_7,
         rmet_cv008=RMET_8,
         rmet_cv009=RMET_9,
         rmet_cv010=RMET_10,
         rmet_cv011=RMET_11,
         rmet_cv012=RMET_12,
         rmet_cv013=RMET_13,
         rmet_cv014=RMET_14,
         rmet_cv015=RMET_15,
         rmet_cv016=RMET_16,
         rmet_cv017=RMET_17,
         rmet_cv018=RMET_18,
         rmet_cv019=RMET_19,
         rmet_cv020=RMET_20,
         rmet_cv021=RMET_21,
         rmet_cv022=RMET_22,
         rmet_cv023=RMET_23,
         rmet_cv024=RMET_24,
         rmet_cv025=RMET_25,
         rmet_cv026=RMET_26,
         rmet_cv027=RMET_27,
         rmet_cv028=RMET_28,
         form_completed=ifelse(RMET_1_numcompleted==28,1,2),
         form_explain=ifelse(!RMET_1_numcompleted==28,87,86),
         assessment_complete=ifelse(RMET_1_numcompleted==28,2,0),
         child_eyestotal=ifelse(!is.na(RMET_Total_Score),RMET_Total_Score,"")
  )

ndar_rmet_data <- left_join(ndar_key,ndar_rmet_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("RMET",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
rmet_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/rmet_cv01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
rmet_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/rmet_cv01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
rmet_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/rmet_cv01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

rmet_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/rmet_cv01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
rmet_temp_df<-data.frame(rmet_temp)
ndar_rmet_data<-bind_rows(rmet_temp_df,ndar_rmet_data)

part2<-colnames(ndar_rmet_data)
part3<-as.matrix(ndar_rmet_data)
colnames(part3)<-NULL
together<-rbind(rmet_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/rmet_cv01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,rmet_df_header,rmet_temp,rmet_temp_df,RMET,RMET_Wave1,RMET_Wave1_percentcorrect,RMET_Wave1_percentcorrect_graph)
```

Prepare R-SCS-C
```{r}
RSCS<-left_join(filter(cleaned_survey_data, grepl("R_SCS",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                  group_by(tagid,item,survey_name) %>%
                  mutate(nrow = n(),
                         value = ifelse(nrow > 1, NA, value)) %>%
                  distinct(tagid,item,survey_name,value,.keep_all = FALSE) %>% 
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(RSCS$tagid) == length(unique(RSCS$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

TAG023_special<-left_join(filter(cleaned_survey_data, grepl("R_SCS",item)) %>%
                            mutate(value=as.numeric(value)) %>% 
                            filter(!is.na(value)) %>%
                            filter(!value=="") %>%
                            filter(tagid=="TAG023") %>%
                            distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                            spread(item,value),
                          redcap_cleaned %>%
                            filter(!is.na(dob),!is.na(sa_date),tagid=="TAG023") %>%
                            select(tagid, sa_date, sb_date, dob),by="tagid") %>%
  mutate(survey_name="TAG - Sess 1 - V1 - (EATQ-R_2 & on)")

RSCS <- bind_rows(RSCS %>% filter(!tagid=="TAG023"),TAG023_special)
  

if (length(RSCS$tagid) == length(unique(RSCS$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

RSCS_Wave1<-left_join(RSCS,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 1 - V4 - Current",sa_date,
                            ifelse(survey_name=="TAG - Sess 1 - V1",sa_date,
                                   ifelse(survey_name=="TAG - Sess 1 - V2",sa_date,
                                          ifelse(survey_name=="TAG - Sess 1 - V3",sa_date,
                                                 ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                                 )))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(RSCS_publicsc_total=rowSums(cbind(R_SCS_C_1,R_SCS_C_2,R_SCS_C_3,R_SCS_C_7,R_SCS_C_10,R_SCS_C_12,R_SCS_C_14,
                                      R_SCS_C_15,R_SCS_C_16,R_SCS_C_21,R_SCS_C_28), na.rm=F),
         RSCS_privatesc_total=rowSums(cbind(R_SCS_C_4,R_SCS_C_5,R_SCS_C_6,R_SCS_C_8,R_SCS_C_9,R_SCS_C_11,R_SCS_C_20,
                                       R_SCS_C_22,R_SCS_C_23,R_SCS_C_24,R_SCS_C_27), na.rm=F),
         RSCS_socanx_total=rowSums(cbind(R_SCS_C_13,R_SCS_C_17,R_SCS_C_18,R_SCS_C_19,R_SCS_C_25,R_SCS_C_26,R_SCS_C_29), na.rm=F),
         RSCS_publicsc_mean=rowMeans(cbind(R_SCS_C_1,R_SCS_C_2,R_SCS_C_3,R_SCS_C_7,R_SCS_C_10,R_SCS_C_12,R_SCS_C_14,
                                      R_SCS_C_15,R_SCS_C_16,R_SCS_C_21,R_SCS_C_28), na.rm=T),
         RSCS_privatesc_mean=rowMeans(cbind(R_SCS_C_4,R_SCS_C_5,R_SCS_C_6,R_SCS_C_8,R_SCS_C_9,R_SCS_C_11,R_SCS_C_20,
                                       R_SCS_C_22,R_SCS_C_23,R_SCS_C_24,R_SCS_C_27), na.rm=T),
         RSCS_socanx_mean=rowMeans(cbind(R_SCS_C_13,R_SCS_C_17,R_SCS_C_18,R_SCS_C_19,R_SCS_C_25,R_SCS_C_26,R_SCS_C_29), na.rm=T))

## Save it
RSCS_Wave1_outdf <- RSCS_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(RSCS_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/RSCS_Wave1.csv"))

RSCS_Wave2_outdf <- RSCS_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(RSCS_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/RSCS_Wave2.csv"))

RSCS_Wave3_outdf <- RSCS_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(RSCS_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/RSCS_Wave3.csv"))

## Graph it
RSCS_Wave1_totals<-RSCS_Wave1 %>%
  select(tagid,RSCS_publicsc_total,RSCS_privatesc_total,RSCS_socanx_total) %>%
  mutate(Public_Self_Consicousness=RSCS_publicsc_total,
         Private_Self_Consicousness=RSCS_privatesc_total,
         Social_Anxiousness=RSCS_socanx_total) %>%
  select(-contains("RSCS")) %>%
  gather('item','value',2:length(.)) 
RSCS_Wave1_totals_graph<-ggplot(RSCS_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("RSCS totals for ",length(unique(RSCS_Wave1$tagid[!is.na(RSCS_Wave1$RSCS_publicsc_total)]))," participants"))

RSCS_Wave1_means<-RSCS_Wave1 %>%
  select(tagid,RSCS_publicsc_mean,RSCS_privatesc_mean,RSCS_socanx_mean) %>%
  mutate(Public_Self_Consicousness=RSCS_publicsc_mean,
         Private_Self_Consicousness=RSCS_privatesc_mean,
         Social_Anxiousness=RSCS_socanx_mean) %>%
  select(-contains("RSCS")) %>%
  gather('item','value',2:length(.)) 
RSCS_Wave1_means_graph<-ggplot(RSCS_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("RSCS means for ",length(unique(RSCS_Wave1$tagid))," participants"))


## Make RDOC ready file
ndar_rscs_data <- left_join(RSCS_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         comments_misc=ifelse(grepl("Sess 1",survey_name),"Session1",
                      ifelse(grepl("Session 1",survey_name),"Session1",
                             ifelse(grepl("Sess 2",survey_name),"Session2",
                                    ifelse(grepl("Session 2",survey_name),"Session2",
                                           ifelse(grepl("Home",survey_name),"Home Questionnaires",
                                                  NA))))),
         site="University of Oregon",
         study="Transitions in Adolescent Girls (TAG) Study",
         gender="F",
         rscsc_1=R_SCS_C_1,
         rscsc_2=R_SCS_C_2,
         rscsc_3=R_SCS_C_3,
         rscsc_4=R_SCS_C_4,
         rscsc_5=R_SCS_C_5,
         rscsc_6=R_SCS_C_6,
         rscsc_7=R_SCS_C_7,
         rscsc_8=R_SCS_C_8,
         rscsc_9=R_SCS_C_9,
         rscsc_10=R_SCS_C_10,
         rscsc_11=R_SCS_C_11,
         rscsc_12=R_SCS_C_12,
         rscsc_13=R_SCS_C_13,
         rscsc_14=R_SCS_C_14,
         rscsc_15=R_SCS_C_15,
         rscsc_16=R_SCS_C_16,
         rscsc_17=R_SCS_C_17,
         rscsc_18=R_SCS_C_18,
         rscsc_19=R_SCS_C_19,
         rscsc_20=R_SCS_C_20,
         rscsc_21=R_SCS_C_21,
         rscsc_22=R_SCS_C_22,
         rscsc_23=R_SCS_C_23,
         rscsc_24=R_SCS_C_24,
         rscsc_25=R_SCS_C_25,
         rscsc_26=R_SCS_C_26,
         rscsc_27=R_SCS_C_27,
         rscsc_28=R_SCS_C_28,
         rscsc_29=R_SCS_C_29,
         rscsc_publicsc=ifelse(!is.na(RSCS_publicsc_total),RSCS_publicsc_total,999),
         rscsc_privatesc=ifelse(!is.na(RSCS_privatesc_total),RSCS_privatesc_total,999),
         rscsc_socanx=ifelse(!is.na(RSCS_socanx_total),RSCS_socanx_total,999))

ndar_rscs_data <- left_join(ndar_key,ndar_rscs_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("SCS",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
rscs_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/rscsc01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
rscs_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/rscsc01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
rscs_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/rscsc01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

rscs_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/rscsc01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
rscs_temp_df<-data.frame(rscs_temp)
ndar_rscs_data<-bind_rows(rscs_temp_df,ndar_rscs_data)

part2<-colnames(ndar_rscs_data)
part3<-as.matrix(ndar_rscs_data)
colnames(part3)<-NULL
together<-rbind(rscs_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/rscsc01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,rscs_df_header,rscs_temp,rscs_temp_df,RSCS,RSCS_Wave1_means,RSCS_Wave1,RSCS_Wave1_totals,RSCS_Wave1_totals_graph,
   TAG023_special)


#NOTE: No total score calculated for this questionnaire
```

Prepare SAQ
```{r}
SAQ<-left_join(filter(cleaned_survey_data, grepl("SAQ",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(SAQ$tagid) == length(unique(SAQ$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

TAG023_special<-left_join(filter(cleaned_survey_data, grepl("SAQ",item)) %>%
                            mutate(value=as.numeric(value)) %>% 
                            filter(!is.na(value)) %>%
                            filter(!value=="") %>%
                            filter(tagid=="TAG023") %>%
                            filter(survey_name=="TAG - Sess 1 - V1 - (EATQ-R_2 & on)") %>%
                            distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                            spread(item,value),
                          redcap_cleaned %>%
                            filter(!is.na(dob),!is.na(sa_date),tagid=="TAG023") %>%
                            select(tagid, sa_date, sb_date, dob),by="tagid") 

TAG002_special<-left_join(filter(cleaned_survey_data, grepl("SAQ",item)) %>%
                            mutate(value=as.numeric(value)) %>% 
                            filter(!is.na(value)) %>%
                            filter(!value=="") %>%
                            filter(tagid=="TAG002") %>% 
                            distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                            #filter(survey_name=="TAG - Sess 1 - V1 - (SAQ & on)"|survey_name=="TAG - Sess 1 - V1") %>% 
                            spread(item,value),
                          redcap_cleaned %>%
                            filter(!is.na(dob),!is.na(sa_date),tagid=="TAG002") %>%
                            select(tagid, sa_date, sb_date, dob),by="tagid")

TAG002_w23_special <- filter(TAG002_special, grepl("W2|W3",survey_name))

TAG002_w1_special <- TAG002_special %>% 
  filter(survey_name=="TAG - Sess 1 - V1 - (SAQ & on)"|survey_name=="TAG - Sess 1 - V1") %>%
                        gather("item","value") %>% 
                        distinct(item,value,.keep_all = F) %>% 
                        filter(!value=="") %>% 
                        filter(!value=="TAG - Sess 1 - V1") %>% 
  filter(!grepl("2017|2018|2019",value)) %>% 
  spread(item,value,convert = T)

TAG002_special <- rbind(TAG002_w1_special,TAG002_w23_special)

SAQ <- bind_rows(SAQ %>% filter(!tagid=="TAG023"),TAG023_special)
SAQ <- bind_rows(SAQ %>% filter(!tagid=="TAG002"),TAG002_special)
SAQ <- SAQ %>% filter(!(tagid=="TAG145" & survey_name=="TAG - Home Qs - V3 - with SID embedded"))
  

if (length(SAQ$tagid) == length(unique(SAQ$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

SAQ_Wave1<-left_join(SAQ,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=
           ifelse(survey_name=="TAG - Sess 1 - V1",sa_date,
                  ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                  )))%>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(SAQ_socdevgoals_total=rowSums(cbind(SAQ_1,SAQ_2,SAQ_3,SAQ_4,SAQ_5,SAQ_6,SAQ_7,SAQ_8), na.rm=F),
         SAQ_approachgoals_total=rowSums(cbind(SAQ_9,SAQ_10,SAQ_11,SAQ_12,SAQ_13,SAQ_14), na.rm=F),
         SAQ_avoidgoals_total=rowSums(cbind(SAQ_15,SAQ_16,SAQ_17,SAQ_18,SAQ_19,SAQ_20,SAQ_21), na.rm=F),
         SAQ_socdevgoals_mean=rowMeans(cbind(SAQ_1,SAQ_2,SAQ_3,SAQ_4,SAQ_5,SAQ_6,SAQ_7,SAQ_8), na.rm=T),
         SAQ_approachgoals_mean=rowMeans(cbind(SAQ_9,SAQ_10,SAQ_11,SAQ_12,SAQ_13,SAQ_14), na.rm=T),
         SAQ_avoidgoals_mean=rowMeans(cbind(SAQ_15,SAQ_16,SAQ_17,SAQ_18,SAQ_19,SAQ_20,SAQ_21), na.rm=T))

## Save it
SAQ_Wave1_outdf <- SAQ_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(SAQ_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/SAQ_Wave1.csv"))

SAQ_Wave2_outdf <- SAQ_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(SAQ_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/SAQ_Wave2.csv"))

SAQ_Wave3_outdf <- SAQ_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(SAQ_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/SAQ_Wave3.csv"))

## Graph it
SAQ_Wave1_totals<-SAQ_Wave1 %>%
  select(tagid,SAQ_socdevgoals_total,SAQ_approachgoals_total,SAQ_avoidgoals_total) %>%
  mutate(Social_Development_Goals=SAQ_socdevgoals_total,
         Social_Approach_Goals=SAQ_approachgoals_total,
         Social_Avoidance_Goals=SAQ_avoidgoals_total) %>%
  select(-contains("SAQ")) %>%
  gather('item','value',2:length(.)) 
SAQ_Wave1_totals_graph<-ggplot(SAQ_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("SAQ totals for ",length(unique(SAQ_Wave1$tagid[!is.na(SAQ_Wave1$SAQ_approachgoals_total)]))," participants"))

SAQ_Wave1_socdev_items<-SAQ_Wave1 %>%
  select(tagid,SAQ_1,SAQ_2,SAQ_3,SAQ_4,SAQ_5,SAQ_6,SAQ_7,SAQ_8) %>%
  gather('item','value',2:length(.)) 
SAQ_Wave1_socdev_items_graph<-ggplot(SAQ_Wave1_socdev_items, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("SAQ Social Development Goals items for ",length(unique(SAQ_Wave1$tagid[!is.na(SAQ_Wave1$tagid)]))," participants"))

SAQ_Wave1_means<-SAQ_Wave1 %>%
  select(tagid,SAQ_socdevgoals_mean,SAQ_approachgoals_mean,SAQ_avoidgoals_mean) %>%
  mutate(Social_Development_Goals=SAQ_socdevgoals_mean,
         Social_Approach_Goals=SAQ_approachgoals_mean,
         Social_Avoidance_Goals=SAQ_avoidgoals_mean) %>%
  select(-contains("SAQ")) %>%
  gather('item','value',2:length(.)) 
SAQ_Wave1_means_graph<-ggplot(SAQ_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("SAQ means for ",length(unique(SAQ_Wave1$tagid[!is.na(SAQ_Wave1$SAQ_approachgoals_mean)]))," participants"))


## Make RDOC ready file
ndar_saq_data <- left_join(SAQ_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         sagq_1=SAQ_1,
         sagq_2=SAQ_2,
         sagq_3=SAQ_3,
         sagq_4=SAQ_4,
         sagq_5=SAQ_5,
         sagq_6=SAQ_6,
         sagq_7=SAQ_7,
         sagq_8=SAQ_8,
         sagq_9=SAQ_9,
         sagq_10=SAQ_10,
         sagq_11=SAQ_11,
         sagq_12=SAQ_12,
         sagq_13=SAQ_13,
         sagq_14=SAQ_14,
         sagq_15=SAQ_15,
         sagq_16=SAQ_16,
         sagq_17=SAQ_17,
         sagq_18=SAQ_18,
         sagq_19=SAQ_19,
         sagq_20=SAQ_20,
         sagq_21=SAQ_21,
         sag_sdg=ifelse(!is.na(SAQ_socdevgoals_total),SAQ_socdevgoals_total,NA),
         sag_dapg=ifelse(!is.na(SAQ_approachgoals_total),SAQ_approachgoals_total,NA),
         sag_davg=ifelse(!is.na(SAQ_avoidgoals_total),SAQ_avoidgoals_total,NA))

ndar_saq_data <- left_join(ndar_key,ndar_saq_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("SAQ",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
saq_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/sag01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
saq_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/sag01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
saq_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/sag01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

saq_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/sag01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
saq_temp_df<-data.frame(saq_temp)
ndar_saq_data<-bind_rows(saq_temp_df,ndar_saq_data)

part2<-colnames(ndar_saq_data)
part3<-as.matrix(ndar_saq_data)
colnames(part3)<-NULL
together<-rbind(saq_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/sag01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,saq_df_header,saq_temp,saq_temp_df,SAQ,SAQ_Wave1,SAQ_Wave1_means,SAQ_Wave1_means_graph,SAQ_Wave1_socdev_items,
   SAQ_Wave1_socdev_items_graph,SAQ_Wave1_totals,SAQ_Wave1_totals_graph,TAG002_special,TAG023_special)


```

Prepare SCARED-R 
```{r}
SCARED<-left_join(filter(cleaned_survey_data, grepl("SCARED",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(SCARED$tagid) == length(unique(SCARED$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

SCARED_Wave1<-left_join(SCARED,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,
                                                 ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                                 ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(SCARED_total=rowSums(cbind(SCARED_R_1,SCARED_R_2,SCARED_R_3,SCARED_R_4,SCARED_R_5,
                                    SCARED_R_6,SCARED_R_7,SCARED_R_8,SCARED_R_9),na.rm=F),
         SCARED_ptsd_total=rowSums(cbind(SCARED_R_6,SCARED_R_7,SCARED_R_8,SCARED_R_8),na.rm=F),
         SCARED_anxiety_total=rowSums(cbind(SCARED_R_1,SCARED_R_2,SCARED_R_3,SCARED_R_4,SCARED_R_5),na.rm=F),
         SCARED_mean=round(rowMeans(cbind(SCARED_R_1,SCARED_R_2,SCARED_R_3,SCARED_R_4,SCARED_R_5,
                                    SCARED_R_6,SCARED_R_7,SCARED_R_8,SCARED_R_8),na.rm=T),3),
         SCARED_ptsd_mean=round(rowMeans(cbind(SCARED_R_6,SCARED_R_7,SCARED_R_8,SCARED_R_8),na.rm=T),3),
         SCARED_anxiety_mean=round(rowMeans(cbind(SCARED_R_1,SCARED_R_2,SCARED_R_3,SCARED_R_4,SCARED_R_5),na.rm=T),3))
  

## Save it
SCARED_Wave1_outdf <- SCARED_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(SCARED_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/SCARED_Wave1.csv"))

SCARED_Wave2_outdf <- SCARED_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(SCARED_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/SCARED_Wave2.csv"))

## Graph it
SCARED_Wave1_totals<-SCARED_Wave1 %>%
  select(tagid,SCARED_total,SCARED_ptsd_total,SCARED_anxiety_total)%>%
  gather('item','value',2:length(.)) 
SCARED_Wave1_totals_graph<-ggplot(SCARED_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("SCARED totals for ",length(unique(SCARED_Wave1$tagid[!is.na(SCARED_Wave1$SCARED_total)]))," participants"))

SCARED_Wave1_means<-SCARED_Wave1 %>%
  select(tagid,SCARED_mean,SCARED_ptsd_mean,SCARED_anxiety_mean)%>%
  gather('item','value',2:length(.)) 
SCARED_Wave1_means_graph<-ggplot(SCARED_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("SCARED means for ",length(unique(SCARED_Wave1$tagid[!is.na(SCARED_Wave1$SCARED_mean)]))," participants"))

## Make RDOC ready file
ndar_scared_data <- left_join(SCARED_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         scared_version="Brief",
         visit=ifelse(grepl("Sess 1",survey_name),"Session1",
                      ifelse(grepl("Session 1",survey_name),"Session1",
                             ifelse(grepl("Sess 2",survey_name),"Session2",
                                    ifelse(grepl("Session 2",survey_name),"Session2",
                                           ifelse(grepl("Home",survey_name),"Home Questionnaires",NA))))),
         comments_misc="SCARED Brief Assessment of Anxiety and PTS Symptoms (ages 7-17)",
         scared_24=ifelse(!is.na(SCARED_R_1),SCARED_R_1,88),
         scared_25=ifelse(!is.na(SCARED_R_2),SCARED_R_2,88),
         scared_28=ifelse(!is.na(SCARED_R_3),SCARED_R_3,88),
         scared_36=ifelse(!is.na(SCARED_R_4),SCARED_R_4,88),
         scared_41=ifelse(!is.na(SCARED_R_5),SCARED_R_5,88),
         briefscared_1=ifelse(!is.na(SCARED_R_6),SCARED_R_6,88),
         briefscared_2=ifelse(!is.na(SCARED_R_7),SCARED_R_7,88),
         briefscared_3=ifelse(!is.na(SCARED_R_8),SCARED_R_8,88),
         briefscared_4=ifelse(!is.na(SCARED_R_9),SCARED_R_9,88),
         scared_total=999,
         scared_ptsd_score=ifelse(!is.na(SCARED_ptsd_total),SCARED_ptsd_total,999),
         scared_pd_score=999,
         scared_gad_score=999,
         scared_sad_score=999,
         scared_socad_score=999,
         scared_ssa_score=999)

ndar_scared_data <- left_join(ndar_key,ndar_scared_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("SCARED",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
scared_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/scared01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
scared_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/scared01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
scared_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/scared01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

scared_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/scared01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
scared_temp_df<-data.frame(scared_temp)
ndar_scared_data<-bind_rows(scared_temp_df,ndar_scared_data)

part2<-colnames(ndar_scared_data)
part3<-as.matrix(ndar_scared_data)
colnames(part3)<-NULL
together<-rbind(scared_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/scared01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,scared_df_header,scared_temp,scared_temp_df,SCARED,SCARED_Wave1,SCARED_Wave1_means,SCARED_Wave1_means_graph,
   SCARED_Wave1_totals,SCARED_Wave1_totals_graph)
```

Prepare SCC
```{r}
SCC<-left_join(filter(cleaned_survey_data, grepl("^SCC",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(SCC$tagid) == length(unique(SCC$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

SCC <- SCC %>% filter(!(tagid=="TAG145" & survey_name=="TAG - Home Qs - V3 - with SID embedded"))

if (length(SCC$tagid) == length(unique(SCC$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

SCC_Wave1<-left_join(SCC,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                            ))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(SCC_1=ifelse(SCC_1==1,5,
                      ifelse(SCC_1==2,4,
                             ifelse(SCC_1==3,3,
                                    ifelse(SCC_1==4,2,
                                           ifelse(SCC_1==5,1,
                                                  NA))))),
         SCC_2=ifelse(SCC_2==1,5,
                      ifelse(SCC_2==2,4,
                             ifelse(SCC_2==3,3,
                                    ifelse(SCC_2==4,2,
                                           ifelse(SCC_2==5,1,
                                                  NA))))),
         SCC_3=ifelse(SCC_3==1,5,
                      ifelse(SCC_3==2,4,
                             ifelse(SCC_3==3,3,
                                    ifelse(SCC_3==4,2,
                                           ifelse(SCC_3==5,1,
                                                  NA))))),
         SCC_4=ifelse(SCC_4==1,5,
                      ifelse(SCC_4==2,4,
                             ifelse(SCC_4==3,3,
                                    ifelse(SCC_4==4,2,
                                           ifelse(SCC_4==5,1,
                                                  NA))))),
         SCC_5=ifelse(SCC_5==1,5,
                      ifelse(SCC_5==2,4,
                             ifelse(SCC_5==3,3,
                                    ifelse(SCC_5==4,2,
                                           ifelse(SCC_5==5,1,
                                                  NA))))),
         SCC_6=SCC_6,
         SCC_7=ifelse(SCC_7==1,5,
                      ifelse(SCC_7==2,4,
                             ifelse(SCC_7==3,3,
                                    ifelse(SCC_7==4,2,
                                           ifelse(SCC_7==5,1,
                                                  NA))))),
         SCC_8=ifelse(SCC_8==1,5,
                      ifelse(SCC_8==2,4,
                             ifelse(SCC_8==3,3,
                                    ifelse(SCC_8==4,2,
                                           ifelse(SCC_8==5,1,
                                                  NA))))),
         SCC_9=ifelse(SCC_9==1,5,
                      ifelse(SCC_9==2,4,
                             ifelse(SCC_9==3,3,
                                    ifelse(SCC_9==4,2,
                                           ifelse(SCC_9==5,1,
                                                  NA))))),
         SCC_10=ifelse(SCC_10==1,5,
                       ifelse(SCC_10==2,4,
                              ifelse(SCC_10==3,3,
                                     ifelse(SCC_10==4,2,
                                            ifelse(SCC_10==5,1,
                                                   NA))))),
         SCC_11=SCC_11,
         SCC_12=ifelse(SCC_12==1,5,
                       ifelse(SCC_12==2,4,
                              ifelse(SCC_12==3,3,
                                     ifelse(SCC_12==4,2,
                                            ifelse(SCC_12==5,1,
                                                   NA)))))) %>%
  mutate(SCC_N=10,
         SCC_missing=rowSums(is.na(cbind(SCC_1,SCC_2,SCC_3,SCC_4,SCC_5,SCC_6,SCC_7,SCC_8,SCC_9,SCC_10,SCC_11,SCC_12))),
         SCC_total=rowSums(cbind(SCC_1,SCC_2,SCC_3,SCC_4,SCC_5,SCC_6,SCC_7,SCC_8,SCC_9,SCC_10,SCC_11,SCC_12), na.rm=F),
         SCC_mean=rowMeans(cbind(SCC_1,SCC_2,SCC_3,SCC_4,SCC_5,SCC_6,SCC_7,SCC_8,SCC_9,SCC_10,SCC_11,SCC_12), na.rm=T))

## Save it
SCC_Wave1_outdf <- SCC_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(SCC_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/SCC_Wave1.csv"))

SCC_Wave2_outdf <- SCC_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(SCC_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/SCC_Wave2.csv"))

SCC_Wave3_outdf <- SCC_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(SCC_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/SCC_Wave3.csv"))

## Graph it
SCC_Wave1_total<-SCC_Wave1 %>%
  select(tagid,SCC_total) %>%
  gather('item','value',2:length(.)) 
SCC_Wave1_total_graph<-ggplot(SCC_Wave1_total, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Self-Concept Clarity total score for ",length(unique(SCC_Wave1$tagid[!is.na(SCC_Wave1$SCC_total)]))," participants"))

SCC_Wave1_mean<-SCC_Wave1 %>%
  select(tagid,SCC_mean)%>%
  gather('item','value',2:length(.)) 
SCC_Wave1_mean_graph<-ggplot(SCC_Wave1_mean, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Self-Concept Clarity mean score for ",length(unique(SCC_Wave1$tagid[!is.na(SCC_Wave1$SCC_mean)]))," participants"))

## Make RDOC ready file
ndar_scc_data <- left_join(SCC_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         scc_1=SCC_1,
         scc_2=SCC_2,
         scc_3=SCC_3,
         scc_4=SCC_4,
         scc_5=SCC_5,
         scc_6=SCC_6,
         scc_7=SCC_7,
         scc_8=SCC_8,
         scc_9=SCC_9,
         scc_10=SCC_10,
         scc_11=SCC_11,
         scc_12=SCC_12,
         scc_tot=ifelse(!is.na(SCC_total),SCC_total,"999"))
         

ndar_scc_data <- left_join(ndar_key,ndar_scc_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("SCC",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)

scc_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/scc01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
scc_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/scc01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
scc_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/scc01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

scc_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/scc01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
scc_temp_df<-data.frame(scc_temp)
ndar_scc_data<-bind_rows(scc_temp_df,ndar_scc_data)

part2<-colnames(ndar_scc_data)
part3<-as.matrix(ndar_scc_data)
colnames(part3)<-NULL
together<-rbind(scc_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/scc01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,scc_df_header,scc_temp,scc_temp_df,SCC,SCC_Wave1,SCC_Wave1_mean,SCC_Wave1_mean_graph,
   SCC_Wave1_total,SCC_Wave1_total_graph)
```

Prepare SPPA
```{r}
SPPA<-left_join(filter(cleaned_survey_data, grepl("SPPA",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(SPPA$tagid) == length(unique(SPPA$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

SPPA <- SPPA %>% filter(!(tagid=="TAG145" & survey_name=="TAG - Home Qs - V3 - with SID embedded"))

if (length(SPPA$tagid) == length(unique(SPPA$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

SPPA_Wave1<-left_join(SPPA,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                            ))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(ha1=ifelse(SPPA_1==1 & SPPA_2==2,4,
                    ifelse(SPPA_1==1 & SPPA_2==1,3,
                           ifelse(SPPA_1==2 & SPPA_2==1,2,
                                  ifelse(SPPA_1==2 & SPPA_2==2,1,
                                         NA)))),
         ha2=ifelse(SPPA_3==1 & SPPA_4==2,1,
                    ifelse(SPPA_3==1 & SPPA_4==1,2,
                           ifelse(SPPA_3==2 & SPPA_4==1,3,
                                  ifelse(SPPA_3==2 & SPPA_4==2,4,
                                         NA)))),
         ha3=ifelse(SPPA_5==1 & SPPA_6==2,4,
                    ifelse(SPPA_5==1 & SPPA_6==1,3,
                           ifelse(SPPA_5==2 & SPPA_6==1,2,
                                  ifelse(SPPA_5==2 & SPPA_6==2,1,
                                         NA)))),
         ha4=ifelse(SPPA_7==1 & SPPA_8==2,1,
                    ifelse(SPPA_7==1 & SPPA_8==1,2,
                           ifelse(SPPA_7==2 & SPPA_8==1,3,
                                  ifelse(SPPA_7==2 & SPPA_8==2,4,
                                         NA)))),
         ha7=ifelse(SPPA_9==1 & SPPA_10==2,4,
                    ifelse(SPPA_9==1 & SPPA_10==1,3,
                           ifelse(SPPA_9==2 & SPPA_10==1,2,
                                  ifelse(SPPA_9==2 & SPPA_10==2,1,
                                         NA)))),
         ha8=ifelse(SPPA_11==1 & SPPA_12==2,4,
                    ifelse(SPPA_11==1 & SPPA_12==1,3,
                           ifelse(SPPA_11==2 & SPPA_12==1,2,
                                  ifelse(SPPA_11==2 & SPPA_12==2,1,
                                         NA)))),
         ha9=ifelse(SPPA_13==1 & SPPA_14==2,1,
                    ifelse(SPPA_13==1 & SPPA_14==1,2,
                           ifelse(SPPA_13==2 & SPPA_14==1,3,
                                  ifelse(SPPA_13==2 & SPPA_14==2,4,
                                         NA)))),
         ha10=ifelse(SPPA_15==1 & SPPA_16==2,1,
                     ifelse(SPPA_15==1 & SPPA_16==1,2,
                            ifelse(SPPA_15==2 & SPPA_16==1,3,
                                   ifelse(SPPA_15==2 & SPPA_16==2,4,
                                          NA)))),
         ha11=ifelse(SPPA_17==1 & SPPA_18==2,4,
                     ifelse(SPPA_17==1 & SPPA_18==1,3,
                            ifelse(SPPA_17==2 & SPPA_18==1,2,
                                   ifelse(SPPA_17==2 & SPPA_18==2,1,
                                          NA)))),
         ha12=ifelse(SPPA_19==1 & SPPA_20==2,4,
                     ifelse(SPPA_19==1 & SPPA_20==1,3,
                            ifelse(SPPA_19==2 & SPPA_20==1,2,
                                   ifelse(SPPA_19==2 & SPPA_20==2,1,
                                          NA)))),
         ha13=ifelse(SPPA_21==1 & SPPA_22==2,1,
                     ifelse(SPPA_21==1 & SPPA_22==1,2,
                            ifelse(SPPA_21==2 & SPPA_22==1,3,
                                   ifelse(SPPA_21==2 & SPPA_22==2,4,
                                          NA)))),
         ha16=ifelse(SPPA_23==1 & SPPA_24==2,1,
                     ifelse(SPPA_23==1 & SPPA_24==1,2,
                            ifelse(SPPA_23==2 & SPPA_24==1,3,
                                   ifelse(SPPA_23==2 & SPPA_24==2,4,
                                          NA)))),
         ha17=ifelse(SPPA_25==1 & SPPA_26==2,1,
                     ifelse(SPPA_25==1 & SPPA_26==1,2,
                            ifelse(SPPA_25==2 & SPPA_26==1,3,
                                   ifelse(SPPA_25==2 & SPPA_26==2,4,
                                          NA)))),
         ha18=ifelse(SPPA_27==1 & SPPA_28==2,1,
                     ifelse(SPPA_27==1 & SPPA_28==1,2,
                            ifelse(SPPA_27==2 & SPPA_28==1,3,
                                   ifelse(SPPA_27==2 & SPPA_28==2,4,
                                          NA)))),
         ha19=ifelse(SPPA_29==1 & SPPA_30==2,4,
                     ifelse(SPPA_29==1 & SPPA_30==1,3,
                            ifelse(SPPA_29==2 & SPPA_30==1,2,
                                   ifelse(SPPA_29==2 & SPPA_30==2,1,
                                          NA)))),
         ha20=ifelse(SPPA_31==1 & SPPA_32==2,1,
                     ifelse(SPPA_31==1 & SPPA_32==1,2,
                            ifelse(SPPA_31==2 & SPPA_32==1,3,
                                   ifelse(SPPA_31==2 & SPPA_32==2,4,
                                          NA)))),
         ha21=ifelse(SPPA_33==1 & SPPA_34==2,4,
                     ifelse(SPPA_33==1 & SPPA_34==1,3,
                            ifelse(SPPA_33==2 & SPPA_34==1,2,
                                   ifelse(SPPA_33==2 & SPPA_34==2,1,
                                          NA)))),
         ha22=ifelse(SPPA_35==1 & SPPA_36==2,1,
                     ifelse(SPPA_35==1 & SPPA_36==1,2,
                            ifelse(SPPA_35==2 & SPPA_36==1,3,
                                   ifelse(SPPA_35==2 & SPPA_36==2,4,
                                          NA)))),
         ha25=ifelse(SPPA_37==1 & SPPA_38==2,4,
                     ifelse(SPPA_37==1 & SPPA_38==1,3,
                            ifelse(SPPA_37==2 & SPPA_38==1,2,
                                   ifelse(SPPA_37==2 & SPPA_38==2,1,
                                          NA)))),
         ha26=ifelse(SPPA_39==1 & SPPA_40==2,4,
                     ifelse(SPPA_39==1 & SPPA_40==1,3,
                            ifelse(SPPA_39==2 & SPPA_40==1,2,
                                   ifelse(SPPA_39==2 & SPPA_40==2,1,
                                          NA)))),
         ha27=ifelse(SPPA_41==1 & SPPA_42==2,4,
                     ifelse(SPPA_41==1 & SPPA_42==1,3,
                            ifelse(SPPA_41==2 & SPPA_42==1,2,
                                   ifelse(SPPA_41==2 & SPPA_42==2,1,
                                          NA)))),
         ha28=ifelse(SPPA_43==1 & SPPA_44==2,1,
                     ifelse(SPPA_43==1 & SPPA_44==1,2,
                            ifelse(SPPA_43==2 & SPPA_44==1,3,
                                   ifelse(SPPA_43==2 & SPPA_44==2,4,
                                          NA)))),
         ha29=ifelse(SPPA_45==1 & SPPA_46==2,4,
                     ifelse(SPPA_45==1 & SPPA_46==1,3,
                            ifelse(SPPA_45==2 & SPPA_46==1,2,
                                   ifelse(SPPA_45==2 & SPPA_46==2,1,
                                          NA)))),
         ha30=ifelse(SPPA_47==1 & SPPA_48==2,1,
                     ifelse(SPPA_47==1 & SPPA_48==1,2,
                            ifelse(SPPA_47==2 & SPPA_48==1,3,
                                   ifelse(SPPA_47==2 & SPPA_48==2,4,
                                          NA)))),
         ha31=ifelse(SPPA_49==1 & SPPA_50==2,4,
                     ifelse(SPPA_49==1 & SPPA_50==1,3,
                            ifelse(SPPA_49==2 & SPPA_50==1,2,
                                   ifelse(SPPA_49==2 & SPPA_50==2,1,
                                          NA)))),
         ha34=ifelse(SPPA_51==1 & SPPA_52==2,1,
                     ifelse(SPPA_51==1 & SPPA_52==1,2,
                            ifelse(SPPA_51==2 & SPPA_52==1,3,
                                   ifelse(SPPA_51==2 & SPPA_52==2,4,
                                          NA)))),
         ha35=ifelse(SPPA_53==1 & SPPA_54==2,1,
                     ifelse(SPPA_53==1 & SPPA_54==1,2,
                            ifelse(SPPA_53==2 & SPPA_54==1,3,
                                   ifelse(SPPA_53==2 & SPPA_54==2,4,
                                          NA)))),
         ha36=ifelse(SPPA_55==1 & SPPA_56==2,4,
                     ifelse(SPPA_55==1 & SPPA_56==1,3,
                            ifelse(SPPA_55==2 & SPPA_56==1,2,
                                   ifelse(SPPA_55==2 & SPPA_56==2,1,
                                          NA)))),
         ha37=ifelse(SPPA_57==1 & SPPA_58==2,4,
                     ifelse(SPPA_57==1 & SPPA_58==1,3,
                            ifelse(SPPA_57==2 & SPPA_58==1,2,
                                   ifelse(SPPA_57==2 & SPPA_58==2,1,
                                          NA)))),
         ha38=ifelse(SPPA_59==1 & SPPA_60==2,4,
                     ifelse(SPPA_59==1 & SPPA_60==1,3,
                            ifelse(SPPA_59==2 & SPPA_60==1,2,
                                   ifelse(SPPA_59==2 & SPPA_60==2,1,
                                          NA)))),
         ha39=ifelse(SPPA_61==1 & SPPA_62==2,1,
                     ifelse(SPPA_61==1 & SPPA_62==1,2,
                            ifelse(SPPA_61==2 & SPPA_62==1,3,
                                   ifelse(SPPA_61==2 & SPPA_62==2,4,
                                          NA)))),
         ha40=ifelse(SPPA_63==1 & SPPA_64==2,4,
                     ifelse(SPPA_63==1 & SPPA_64==1,3,
                            ifelse(SPPA_63==2 & SPPA_64==1,2,
                                   ifelse(SPPA_63==2 & SPPA_64==2,1,
                                          NA)))),
         ha43=ifelse(SPPA_65==1 & SPPA_66==2,4,
                     ifelse(SPPA_65==1 & SPPA_66==1,3,
                            ifelse(SPPA_65==2 & SPPA_66==1,2,
                                   ifelse(SPPA_65==2 & SPPA_66==2,1,
                                          NA)))),
         ha44=ifelse(SPPA_67==1 & SPPA_68==2,1,
                     ifelse(SPPA_67==1 & SPPA_68==1,2,
                            ifelse(SPPA_67==2 & SPPA_68==1,3,
                                   ifelse(SPPA_67==2 & SPPA_68==2,4,
                                          NA)))),
         ha45=ifelse(SPPA_69==1 & SPPA_70==2,4,
                     ifelse(SPPA_69==1 & SPPA_70==1,3,
                            ifelse(SPPA_69==2 & SPPA_70==1,2,
                                   ifelse(SPPA_69==2 & SPPA_70==2,1,
                                          NA))))) %>%
  mutate(SPPA_scholasticcomp_total=rowSums(cbind(ha1,ha10,ha19,ha28,ha37),na.rm=F),
         SPPA_socialcomp_total=rowSums(cbind(ha2,ha11,ha20,ha29,ha38),na.rm=F),
         SPPA_athleticcomp_total=rowSums(cbind(ha3,ha12,ha21,ha30,ha39),na.rm=F),
         SPPA_physicalappear_total=rowSums(cbind(ha4,ha13,ha22,ha31,ha40),na.rm=F),
         SPPA_behavconduct_total=rowSums(cbind(ha7,ha16,ha25,ha34,ha43),na.rm=F),
         SPPA_closefriend_total=rowSums(cbind(ha8,ha17,ha26,ha35,ha44),na.rm=F),
         SPPA_globalselfworth_total=rowSums(cbind(ha9,ha18,ha27,ha36,ha45),na.rm=F),
         SPPA_scholasticcomp_mean=round(rowMeans(cbind(ha1,ha10,ha19,ha28,ha37),na.rm=T),3),
         SPPA_socialcomp_mean=round(rowMeans(cbind(ha2,ha11,ha20,ha29,ha38),na.rm=T),3),
         SPPA_athleticcomp_mean=round(rowMeans(cbind(ha3,ha12,ha21,ha30,ha39),na.rm=T),3),
         SPPA_physicalappear_mean=round(rowMeans(cbind(ha4,ha13,ha22,ha31,ha40),na.rm=T),3),
         SPPA_behavconduct_mean=round(rowMeans(cbind(ha7,ha16,ha25,ha34,ha43),na.rm=T),3),
         SPPA_closefriend_mean=round(rowMeans(cbind(ha8,ha17,ha26,ha35,ha44),na.rm=T),3),
         SPPA_globalselfworth_mean=round(rowMeans(cbind(ha9,ha18,ha27,ha36,ha45),na.rm=T),3),
         SPPA_scholasticcomp_N=5,
         SPPA_scholasticcomp_missing=rowSums(is.na(cbind(ha1,ha10,ha19,ha28,ha37))),
         SPPA_scholasticcomp_missing_perc=100*(rowSums(is.na(cbind(ha1,ha10,ha19,ha28,ha37)))/5),
         SPPA_socialcomp_N=5,
         SPPA_socialcomp_missing=rowSums(is.na(cbind(ha2,ha11,ha20,ha29,ha38))),
         SPPA_socialcomp_missing_perc=100*(rowSums(is.na(cbind(ha2,ha11,ha20,ha29,ha38)))/5),
         SPPA_athleticcomp_N=5,
         SPPA_athleticcomp_missing=rowSums(is.na(cbind(ha3,ha12,ha21,ha30,ha39))),
         SPPA_athleticcomp_missing_perc=100*(rowSums(is.na(cbind(ha3,ha12,ha21,ha30,ha39)))/5),
         SPPA_physicalappear_N=5,
         SPPA_physicalappear_missing=rowSums(is.na(cbind(ha4,ha13,ha22,ha31,ha40))),
         SPPA_physicalappear_missing_perc=100*(rowSums(is.na(cbind(ha4,ha13,ha22,ha31,ha40)))/5),
         SPPA_behavconduct_N=5,
         SPPA_behavconduct_missing=rowSums(is.na(cbind(ha7,ha16,ha25,ha34,ha43))),
         SPPA_behavconduct_missing_perc=100*(rowSums(is.na(cbind(ha7,ha16,ha25,ha34,ha43)))/5),
         SPPA_closefriend_N=5,
         SPPA_closefriend_missing=rowSums(is.na(cbind(ha8,ha17,ha26,ha35,ha44))),
         SPPA_closefriend_missing_perc=100*(rowSums(is.na(cbind(ha8,ha17,ha26,ha35,ha44)))/5),
         SPPA_globalselfworth_N=5,
         SPPA_globalselfworth_missing=rowSums(is.na(cbind(ha9,ha18,ha27,ha36,ha45))),
         SPPA_globalselfworth_missing_perc=100*(rowSums(is.na(cbind(ha9,ha18,ha27,ha36,ha45)))/5))

## Save it
SPPA_Wave1_outdf <- SPPA_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(SPPA_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/SPPA_Wave1.csv"))

SPPA_Wave2_outdf <- SPPA_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(SPPA_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/SPPA_Wave2.csv"))

SPPA_Wave3_outdf <- SPPA_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(SPPA_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/SPPA_Wave3.csv"))

## Graph it
SPPA_Wave1_totals<-SPPA_Wave1 %>%
  select(tagid,SPPA_scholasticcomp_total,SPPA_socialcomp_total,SPPA_athleticcomp_total,
         SPPA_physicalappear_total,SPPA_behavconduct_total,SPPA_closefriend_total,
         SPPA_globalselfworth_total) %>%
  mutate(Scholastic_Competence=SPPA_scholasticcomp_total,
         Social_Competence=SPPA_socialcomp_total,
         Athletic_Competence=SPPA_athleticcomp_total,
         Physical_Appearance=SPPA_physicalappear_total,
         Behavioral_Conduct=SPPA_behavconduct_total,
         Close_Friendship=SPPA_closefriend_total,
         Global_Self_Worht=SPPA_globalselfworth_total) %>%
  select(-contains("SPPA")) %>%
  gather('item','value',2:length(.)) 
SPPA_Wave1_totals_graph<-ggplot(SPPA_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Self-Perception Profile for Adolescents total subscores for ",length(unique(SPPA_Wave1$tagid[!is.na(SPPA_Wave1$SPPA_scholasticcomp_total)]))," participants"))

SPPA_Wave1_means<-SPPA_Wave1 %>%
  select(tagid,SPPA_scholasticcomp_mean,SPPA_socialcomp_mean,SPPA_athleticcomp_mean,
         SPPA_physicalappear_mean,SPPA_behavconduct_mean,SPPA_closefriend_mean,
         SPPA_globalselfworth_mean) %>%
  mutate(Scholastic_Competence=SPPA_scholasticcomp_mean,
         Social_Competence=SPPA_socialcomp_mean,
         Athletic_Competence=SPPA_athleticcomp_mean,
         Physical_Appearance=SPPA_physicalappear_mean,
         Behavioral_Conduct=SPPA_behavconduct_mean,
         Close_Friendship=SPPA_closefriend_mean,
         Global_Self_Worht=SPPA_globalselfworth_mean) %>%
  select(-contains("SPPA")) %>%
  gather('item','value',2:length(.)) 
SPPA_Wave1_means_graph<-ggplot(SPPA_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Self-Perception Profile for Adolescents mean subscores for ",length(unique(SPPA_Wave1$tagid[!is.na(SPPA_Wave1$SPPA_scholasticcomp_mean)]))," participants"))

## Make RDOC ready file
ndar_sppa_data <- left_join(SPPA_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         site="University of Oregon",
         hascx=SPPA_scholasticcomp_mean,
         hasct=ifelse(!is.na(SPPA_scholasticcomp_total),SPPA_scholasticcomp_total,NA),
         hasax=SPPA_socialcomp_mean,
         hasat=ifelse(!is.na(SPPA_socialcomp_total),SPPA_socialcomp_total,NA),
         haacx=SPPA_athleticcomp_mean,
         haact=ifelse(!is.na(SPPA_athleticcomp_total),SPPA_athleticcomp_total,NA),
         hapax=SPPA_physicalappear_mean,
         hapat=ifelse(!is.na(SPPA_physicalappear_total),SPPA_physicalappear_total,NA),
         habcx=SPPA_behavconduct_mean,
         habct=ifelse(!is.na(SPPA_behavconduct_total),SPPA_behavconduct_total,NA),
         hacfx=SPPA_closefriend_mean,
         hacft=ifelse(!is.na(SPPA_closefriend_total),SPPA_closefriend_total,NA),
         hagswx=SPPA_globalselfworth_mean,
         hagswt=ifelse(!is.na(SPPA_globalselfworth_total),SPPA_globalselfworth_total,NA))

ndar_sppa_data <- left_join(ndar_key,ndar_sppa_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("SPPA",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)

sppa_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/harterac01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
sppa_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/harterac01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
sppa_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/harterac01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

sppa_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/harterac01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
sppa_temp_df<-data.frame(sppa_temp)
ndar_sppa_data<-bind_rows(sppa_temp_df,ndar_sppa_data)

part2<-colnames(ndar_sppa_data)
part3<-as.matrix(ndar_sppa_data)
colnames(part3)<-NULL
together<-rbind(sppa_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/harterac01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,sppa_df_header,sppa_temp,sppa_temp_df,SPPA,SPPA_Wave1,SPPA_Wave1_means,SPPA_Wave1_means_graph,
   SPPA_Wave1_totals,SPPA_Wave1_totals_graph)
```

Prepare SSDS
```{r}
SSDS<-left_join(filter(cleaned_survey_data, grepl("SSDS",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(SSDS$tagid) == length(unique(SSDS$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

TAG149_special<-left_join(filter(cleaned_survey_data, grepl("SSDS",item)) %>%
                            mutate(value=as.numeric(value)) %>% 
                            filter(!is.na(value)) %>%
                            filter(!value=="") %>%
                            filter(tagid=="TAG149") %>%
                            filter(!grepl("W2", survey_name)) %>% 
                            distinct(tagid,item,value,.keep_all = FALSE) %>%
                            spread(item,value),
                          redcap_cleaned %>%
                            filter(!is.na(dob),!is.na(sa_date),tagid=="TAG149") %>%
                            select(tagid, sa_date, sb_date, dob),by="tagid") %>%
  mutate(survey_name="TAG - Sess 2 - V3 for Home - (SSDS_2 and on)")

SSDS <- bind_rows(SSDS %>% filter(!tagid=="TAG149"),TAG149_special)
  
if (length(SSDS$tagid) == length(unique(SSDS$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

x=c("TAG - Sess 2 - V1",
    "TAG - Sess 2 - V2",
    "TAG - Sess 2 - V3 - minus CTQ",
    "TAG - Sess 2 - V3 for Home - (SSDS_2 and on)")

SSDS_Wave1<-left_join(SSDS,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,    
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%    
  mutate(SSDS_1 = ifelse(grepl(paste0(x,collapse="|"),survey_name),NA,   #NV updated due to errors in some Qualtrics versions
                            ifelse(tagid=="TAG149",NA,SSDS_13)),
         SSDS_13 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_13,
                            ifelse(tagid=="TAG149",SSDS_13,SSDS_14)),
         SSDS_14 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_14,
                            ifelse(tagid=="TAG149",SSDS_14,SSDS_15)),
         SSDS_15 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_15,
                            ifelse(tagid=="TAG149",SSDS_15,SSDS_16)),
         SSDS_16 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_16,
                            ifelse(tagid=="TAG149",SSDS_16,SSDS_17)),
         SSDS_17 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_17,
                            ifelse(tagid=="TAG149",SSDS_17,SSDS_18)),
         SSDS_18 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_18,
                            ifelse(tagid=="TAG149",SSDS_18,SSDS_19)),
         SSDS_19 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_19,
                            ifelse(tagid=="TAG149",SSDS_19,SSDS_20)),
         SSDS_20 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_20,
                            ifelse(tagid=="TAG149",SSDS_20,SSDS_21)),
         SSDS_21 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_21,
                            ifelse(tagid=="TAG149",SSDS_21,SSDS_22)),
         SSDS_22 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_22,
                            ifelse(tagid=="TAG149",SSDS_22,SSDS_23)),
         SSDS_23 = ifelse(grepl(paste0(x,collapse="|"),survey_name),SSDS_23,
                            ifelse(tagid=="TAG149",SSDS_23,SSDS_24))) %>% 
  mutate(SSDS_family_disclosure_total=rowSums(cbind(SSDS_1,SSDS_2,SSDS_3,SSDS_4,SSDS_5,SSDS_6,SSDS_7,SSDS_8), na.rm=F),
         SSDS_friend_disclosure_total=rowSums(cbind(SSDS_9,SSDS_10,SSDS_11,SSDS_12,SSDS_13,SSDS_14,SSDS_15), na.rm=F),
         SSDS_physdev_disclosure_total=rowSums(cbind(SSDS_16,SSDS_17,SSDS_18,SSDS_19,SSDS_20,SSDS_21,SSDS_22,SSDS_23), na.rm=F),
         SSDS_disclosure_total=rowSums(cbind(SSDS_1,SSDS_2,SSDS_3,SSDS_4,SSDS_5,SSDS_6,SSDS_7,SSDS_8,SSDS_9,SSDS_10,SSDS_11,SSDS_12,SSDS_13,SSDS_14,SSDS_15,SSDS_16,SSDS_17,SSDS_18,SSDS_19,SSDS_20,SSDS_21,SSDS_22,SSDS_23), na.rm=F),
         SSDS_family_disclosure_mean=round(rowMeans(cbind(SSDS_2,SSDS_3,SSDS_4,SSDS_5,SSDS_6,SSDS_7,SSDS_8), na.rm=T),3),
         SSDS_friend_disclosure_mean=round(rowMeans(cbind(SSDS_9,SSDS_10,SSDS_11,SSDS_12,SSDS_13,SSDS_14,SSDS_15), na.rm=T),3),
         SSDS_physdev_disclosure_mean=round(rowMeans(cbind(SSDS_16,SSDS_17,SSDS_18,SSDS_19,SSDS_20,SSDS_21,SSDS_22,SSDS_23), na.rm=T),3),
         SSDS_disclosure_mean=round(rowMeans(cbind(SSDS_1,SSDS_2,SSDS_3,SSDS_4,SSDS_5,SSDS_6,SSDS_7,SSDS_8,SSDS_9,SSDS_10,SSDS_11,SSDS_12,SSDS_13,SSDS_14,SSDS_15,SSDS_16,SSDS_17,SSDS_18,SSDS_19,SSDS_20,SSDS_21,SSDS_22,SSDS_23), na.rm=T),3)) %>%
  select(-SSDS_24) %>%
  mutate(SSDS_family_disclosure_N=8,
         SSDS_family_disclosure_missing=rowSums(is.na(cbind(SSDS_1,SSDS_2,SSDS_3,SSDS_4,SSDS_5,SSDS_6,SSDS_7,SSDS_8))),
         SSDS_family_disclosure_missing_perc=100*(rowSums(is.na(cbind(SSDS_1,SSDS_2,SSDS_3,SSDS_4,SSDS_5,SSDS_6,SSDS_7,SSDS_8)))/8),
         SSDS_friend_disclosure_N=7,
         SSDS_friend_disclosure_missing=rowSums(is.na(cbind(SSDS_9,SSDS_10,SSDS_11,SSDS_12,SSDS_13,SSDS_14,SSDS_15))),
         SSDS_friend_disclosure_missing_perc=100*(rowSums(is.na(cbind(SSDS_9,SSDS_10,SSDS_11,SSDS_12,SSDS_13,SSDS_14,SSDS_15)))/7),
         SSDS_physdev_disclosure_N=8,
         SSDS_physdev_disclosure_missing=rowSums(is.na(cbind(SSDS_16,SSDS_17,SSDS_18,SSDS_19,SSDS_20,SSDS_21,SSDS_22,SSDS_23))),
         SSDS_physdev_disclosure_missing_perc=100*(rowSums(is.na(cbind(SSDS_16,SSDS_17,SSDS_18,SSDS_19,SSDS_20,SSDS_21,SSDS_22,SSDS_23)))/8),
         SSDS_disclosure_N=23,
         SSDS_disclosure_missing=rowSums(is.na(cbind(SSDS_1,SSDS_2,SSDS_3,SSDS_4,SSDS_5,SSDS_6,SSDS_7,SSDS_8,SSDS_9,SSDS_10,SSDS_11,SSDS_12,SSDS_13,SSDS_14,SSDS_15,SSDS_16,SSDS_17,SSDS_18,SSDS_19,SSDS_20,SSDS_21,SSDS_22,SSDS_23))),
         SSDS_disclosure_missing_perc=100*(rowSums(is.na(cbind(SSDS_1,SSDS_2,SSDS_3,SSDS_4,SSDS_5,SSDS_6,SSDS_7,SSDS_8,SSDS_9,SSDS_10,SSDS_11,SSDS_12,SSDS_13,SSDS_14,SSDS_15,SSDS_16,SSDS_17,SSDS_18,SSDS_19,SSDS_20,SSDS_21,SSDS_22,SSDS_23)))/23)) #NV:added global disclosure scale, as well as missing percentages.
  
## Save it
SSDS_Wave1_outdf <- SSDS_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(SSDS_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/SSDS_Wave1.csv"))

SSDS_Wave2_outdf <- SSDS_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(SSDS_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/SSDS_Wave2.csv"))

## Graph it
SSDS_Wave1_totals<-SSDS_Wave1 %>%
  select(tagid,SSDS_family_disclosure_total,SSDS_friend_disclosure_total,
         SSDS_physdev_disclosure_total) %>%
  mutate(Family_Disclosure=SSDS_family_disclosure_total,
         Friend_Disclosure=SSDS_friend_disclosure_total,
         Physical_Development_Disclosure=SSDS_physdev_disclosure_total) %>%
  select(-contains("SSDS")) %>%
  gather('item','value',2:length(.)) 
SSDS_Wave1_totals_graph<-ggplot(SSDS_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Friendship disclosure subscale totals for ",length(unique(SSDS_Wave1$tagid[!is.na(SSDS_Wave1$SSDS_family_disclosure_total)]))," participants"))

SSDS_Wave1_means<-SSDS_Wave1 %>%
  select(tagid,SSDS_1,SSDS_family_disclosure_mean,SSDS_friend_disclosure_mean,
         SSDS_physdev_disclosure_mean) %>%
  mutate(#Self=SSDS_1, NV: deleted this from coding above, since it's not a valid item.
         Family_Disclosure=SSDS_family_disclosure_mean,
         Friend_Disclosure=SSDS_friend_disclosure_mean,
         Physical_Development_Disclosure=SSDS_physdev_disclosure_mean) %>%
  select(-contains("SSDS")) %>%
  gather('item','value',2:length(.)) 
SSDS_Wave1_means_graph<-ggplot(SSDS_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Friendship disclosure subscale means for ",length(unique(SSDS_Wave1$tagid[!is.na(SSDS_Wave1$SSDS_family_disclosure_mean)]))," participants"))


## Make RDOC ready file
ndar_ssds_data <- left_join(SSDS_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         site="University of Oregon",
         comments_misc=ifelse(grepl("Sess 1",survey_name),"Session1; ssds_1 not administered",
                      ifelse(grepl("Session 1",survey_name),"Session1; ssds_1 not administered",
                             ifelse(grepl("Sess 2",survey_name),"Session2; ssds_1 not administered",
                                    ifelse(grepl("Session 2",survey_name),"Session2; ssds_1 not administered",
                                           ifelse(grepl("Sensitive Qs",survey_name),"Session2; ssds_1 not administered",
                                           ifelse(grepl("Home",survey_name),"Home Questionnaires; ssds_1 not administered",NA)))))),
         #ssds_1=88, #NV: This needs to be updated based on rescoring above. The only thing that needs to be changed is this first item - ssds_1=SSDS_1
         ssds_1=SSDS_1,
         ssds_2=SSDS_2,
         ssds_3=SSDS_3,
         ssds_4=SSDS_4,
         ssds_5=SSDS_5,
         ssds_6=SSDS_6,
         ssds_7=SSDS_7,
         ssds_8=SSDS_8,
         ssds_9=SSDS_9,
         ssds_10=SSDS_10,
         ssds_11=SSDS_11,
         ssds_12=SSDS_12,
         ssds_13=SSDS_13,
         ssds_14=SSDS_14,
         ssds_15=SSDS_15,
         ssds_16=SSDS_16,
         ssds_17=SSDS_17,
         ssds_18=SSDS_18,
         ssds_19=SSDS_19,
         ssds_20=SSDS_20,
         ssds_21=SSDS_21,
         ssds_22=SSDS_22,
         ssds_23=SSDS_23,
         ssds_fam=ifelse(!is.na(SSDS_family_disclosure_total),SSDS_family_disclosure_total,999),
         ssds_friend=ifelse(!is.na(SSDS_friend_disclosure_total),SSDS_friend_disclosure_total,999),
         ssds_phys=ifelse(!is.na(SSDS_physdev_disclosure_total),SSDS_physdev_disclosure_total,999))

ndar_ssds_data <- left_join(ndar_key,ndar_ssds_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("SSDS",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)

ssds_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/ssds01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
ssds_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/ssds01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
ssds_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/ssds01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

ssds_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/ssds01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
ssds_temp_df<-data.frame(ssds_temp)
ndar_ssds_data<-bind_rows(ssds_temp_df,ndar_ssds_data)

part2<-colnames(ndar_ssds_data)
part3<-as.matrix(ndar_ssds_data)
colnames(part3)<-NULL
together<-rbind(ssds_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/ssds01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,ssds_df_header,ssds_temp,ssds_temp_df,SSDS,SSDS_Wave1,SSDS_Wave1_means,SSDS_Wave1_means_graph,
   SSDS_Wave1_totals,SSDS_Wave1_totals_graph)
```

Prepare PANAS-C
```{r}
PANAS<-left_join(filter(cleaned_survey_data, grepl("PANAS",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")

if (length(PANAS$tagid) == length(unique(PANAS$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

PANAS_Wave1<-left_join(PANAS,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(PANAS_pos_total=rowSums(cbind(PANAS_C_1,PANAS_C_3,PANAS_C_5,PANAS_C_7,PANAS_C_9),na.rm=FALSE),
         PANAS_pos_mean=rowMeans(cbind(PANAS_C_1,PANAS_C_3,PANAS_C_5,PANAS_C_7,PANAS_C_9),na.rm=TRUE),
         PANAS_neg_total=rowSums(cbind(PANAS_C_2,PANAS_C_4,PANAS_C_6,PANAS_C_8,PANAS_C_10),na.rm=FALSE),
         PANAS_neg_mean=rowMeans(cbind(PANAS_C_2,PANAS_C_4,PANAS_C_6,PANAS_C_8,PANAS_C_10),na.rm=TRUE))

## Save it
PANAS_Wave1_outdf <- PANAS_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(PANAS_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/PANAS_Wave1.csv"))

PANAS_Wave2_outdf <- PANAS_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(PANAS_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/PANAS_Wave2.csv"))

## Graph it
PANAS_Wave1_totals<-PANAS_Wave1 %>%
  select(tagid,PANAS_pos_total,PANAS_neg_total) %>%
  mutate(Positive_Affect=PANAS_pos_total,
         Negative_Affect=PANAS_neg_total) %>%
  select(-contains("PANAS")) %>%
  gather('item','value',2:length(.)) 
PANAS_Wave1_totals_graph<-ggplot(PANAS_Wave1_totals, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("PANAS totals for ",length(unique(PANAS_Wave1$tagid[!is.na(PANAS_Wave1$PANAS_pos_total)]))," participants"))

PANAS_Wave1_means<-PANAS_Wave1 %>%
  select(tagid,PANAS_pos_mean,PANAS_neg_mean) %>%
  mutate(Positive_Affect=PANAS_pos_mean,
         Negative_Affect=PANAS_neg_mean) %>%
  select(-contains("PANAS")) %>%
  gather('item','value',2:length(.)) 
PANAS_Wave1_means_graph<-ggplot(PANAS_Wave1_means, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("PANAS means for ",length(unique(PANAS_Wave1$tagid[!is.na(PANAS_Wave1$PANAS_pos_mean)]))," participants"))

options(scipen=999)
PANAS_Wave1_cor_graph<-ggplot(PANAS_Wave1, aes(x=PANAS_neg_mean,y=PANAS_pos_mean)) +
  ylab("Positive Affect")+
  xlab("Negative Affect")+
  geom_point(show.legend = FALSE)+
  ggtitle(paste0("PANAS positive and negative affect correlations for ",length(unique(PANAS_Wave1$tagid[!is.na(PANAS_Wave1$PANAS_pos_mean)])),
                 " Wave 1 participants. r = ",
                 round(cor.test(x = PANAS_Wave1$PANAS_pos_mean,y=PANAS_Wave1$PANAS_neg_mean,use=na.or.complete)[[4]],3)," p = ",
                 cor.test(x=PANAS_Wave1$PANAS_pos_mean,y=PANAS_Wave1$PANAS_neg_mean,use=na.or.complete)[[3]]))

## Make RDOC ready file
ndar_panas_data <- left_join(PANAS_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         panas_21=PANAS_C_1,
         panas_15=PANAS_C_2,
         panas_17=PANAS_C_3,
         panas_23=PANAS_C_4,
         panas_8=PANAS_C_5,
         panas_20=PANAS_C_6,
         panas_30=PANAS_C_7,
         panas_13=PANAS_C_8,
         panas_19=PANAS_C_9,
         panas_2=PANAS_C_10,
         sum_pos=-9,
         sum_neg=-9)

ndar_panas_data <- left_join(ndar_key,ndar_panas_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("PANAS",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
panas_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/panas_c01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
panas_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/panas_c01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
panas_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/panas_c01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

panas_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/panas_c01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
panas_temp_df<-data.frame(panas_temp)
ndar_panas_data<-bind_rows(panas_temp_df,ndar_panas_data)

part2<-colnames(ndar_panas_data)
part3<-as.matrix(ndar_panas_data)
colnames(part3)<-NULL
together<-rbind(panas_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/panas_c01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,panas_df_header,panas_temp,panas_temp_df,PANAS,PANAS_Wave1_means,PANAS_Wave1,PANAS_Wave1_totals,PANAS_Wave1_totals_graph,
   PANAS_Wave1_cor_graph)
```

Prepare SCS-C # Do not submit to RDOC
```{r}
SCSC_Roles <- left_join(filter(cleaned_survey_data, grepl("^SCS_C_Roles",item)) %>%
                 mutate(value=as.character(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")
SCSC_Adj <- left_join(filter(cleaned_survey_data, grepl("^SCS_C",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")
#Change this if anyone endorses adjective "bad" in subsequent waves
SCSC_Adj$SCS_C_1_9 <- NA

SCSC <- left_join(SCSC_Roles, SCSC_Adj)

if (length(SCSC$tagid) == length(unique(SCSC$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

SCSC_Wave1<-left_join(SCSC,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                            ))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(SCS_C_Roles_1_TEXT=ifelse(is.na(SCS_C_Roles_1_TEXT),0,1),
         SCS_C_Roles_2_TEXT=ifelse(is.na(SCS_C_Roles_2_TEXT),0,1),
         SCS_C_Roles_3_TEXT=ifelse(is.na(SCS_C_Roles_3_TEXT),0,1),
         SCS_C_Roles_4_TEXT=ifelse(is.na(SCS_C_Roles_4_TEXT),0,1),
         SCS_C_Roles_5_TEXT=ifelse(is.na(SCS_C_Roles_5_TEXT),0,1),
         SCS_C_Roles_6_TEXT=ifelse(is.na(SCS_C_Roles_6_TEXT),0,1),
         SCS_C_Roles_7_TEXT=ifelse(is.na(SCS_C_Roles_7_TEXT),0,1),
         SCS_C_Roles_8_TEXT=ifelse(is.na(SCS_C_Roles_8_TEXT),0,1),
         SCS_C_Roles_9_TEXT=ifelse(is.na(SCS_C_Roles_9_TEXT),0,1),
         SCS_C_Roles_10_TEXT=ifelse(is.na(SCS_C_Roles_10_TEXT),0,1),
         SCS_C_NASPECTS=rowSums(cbind(SCS_C_Roles_1_TEXT, SCS_C_Roles_2_TEXT,
                                      SCS_C_Roles_3_TEXT, SCS_C_Roles_4_TEXT,
                                      SCS_C_Roles_5_TEXT, SCS_C_Roles_6_TEXT,
                                      SCS_C_Roles_7_TEXT, SCS_C_Roles_8_TEXT,
                                      SCS_C_Roles_9_TEXT, SCS_C_Roles_10_TEXT), na.rm = F)) %>% 
  mutate(SCS_C_Group_Happy=as.character(paste0(SCS_C_1_1, SCS_C_2_1, SCS_C_3_1, SCS_C_4_1, SCS_C_5_1,
                                  SCS_C_6_1, SCS_C_7_1, SCS_C_8_1, SCS_C_9_1, SCS_C_10_1)),
         SCS_C_Group_Smart=as.character(paste0(SCS_C_1_2, SCS_C_2_2, SCS_C_3_2, SCS_C_4_2, SCS_C_5_2,
                                  SCS_C_6_2, SCS_C_7_2, SCS_C_8_2, SCS_C_9_2, SCS_C_10_2)),
         SCS_C_Group_Brave=as.character(paste0(SCS_C_1_3, SCS_C_2_3, SCS_C_3_3, SCS_C_4_3, SCS_C_5_3,
                                  SCS_C_6_3, SCS_C_7_3, SCS_C_8_3, SCS_C_9_3, SCS_C_10_3)),
         SCS_C_Group_Helpful=as.character(paste0(SCS_C_1_4, SCS_C_2_4, SCS_C_3_4, SCS_C_4_4, SCS_C_5_4,
                                  SCS_C_6_4, SCS_C_7_4, SCS_C_8_4, SCS_C_9_4, SCS_C_10_4)),
         SCS_C_Group_Nice=as.character(paste0(SCS_C_1_5, SCS_C_2_5, SCS_C_3_5, SCS_C_4_5, SCS_C_5_5,
                                  SCS_C_6_5, SCS_C_7_5, SCS_C_8_5, SCS_C_9_5, SCS_C_10_5)),
         SCS_C_Group_Angry=as.character(paste0(SCS_C_1_6, SCS_C_2_6, SCS_C_3_6, SCS_C_4_6, SCS_C_5_6,
                                  SCS_C_6_6, SCS_C_7_6, SCS_C_8_6, SCS_C_9_6, SCS_C_10_6)),
         SCS_C_Group_Lonely=as.character(paste0(SCS_C_1_7, SCS_C_2_7, SCS_C_3_7, SCS_C_4_7, SCS_C_5_7,
                                  SCS_C_6_7, SCS_C_7_7, SCS_C_8_7, SCS_C_9_7, SCS_C_10_7)),
         SCS_C_Group_Lazy=as.character(paste0(SCS_C_1_8, SCS_C_2_8, SCS_C_3_8, SCS_C_4_8, SCS_C_5_8,
                                  SCS_C_6_8, SCS_C_7_8, SCS_C_8_8, SCS_C_9_8, SCS_C_10_8)),
         SCS_C_Group_Bad=as.character(paste0(SCS_C_1_9, SCS_C_2_9, SCS_C_3_9, SCS_C_4_9, SCS_C_5_9,
                                  SCS_C_6_9, SCS_C_7_9, SCS_C_8_9, SCS_C_9_9, SCS_C_10_9)),
         SCS_C_Group_Scared=as.character(paste0(SCS_C_1_10, SCS_C_2_10, SCS_C_3_10, SCS_C_4_10, SCS_C_5_10,
                                  SCS_C_6_10, SCS_C_7_10, SCS_C_8_10, SCS_C_9_10, SCS_C_10_10)),
         SCS_C_Group_Responsible=as.character(paste0(SCS_C_1_11, SCS_C_2_11, SCS_C_3_11, SCS_C_4_11, SCS_C_5_11,
                                  SCS_C_6_11, SCS_C_7_11, SCS_C_8_11, SCS_C_9_11, SCS_C_10_11)),
         SCS_C_Group_Confident=as.character(paste0(SCS_C_1_12, SCS_C_2_12, SCS_C_3_12, SCS_C_4_12, SCS_C_5_12,
                                  SCS_C_6_12, SCS_C_7_12, SCS_C_8_12, SCS_C_9_12, SCS_C_10_12)),
         SCS_C_Group_Kind=as.character(paste0(SCS_C_1_13, SCS_C_2_13, SCS_C_3_13, SCS_C_4_13, SCS_C_5_13,
                                  SCS_C_6_13, SCS_C_7_13, SCS_C_8_13, SCS_C_9_13, SCS_C_10_13)),
         SCS_C_Group_Calm=as.character(paste0(SCS_C_1_14, SCS_C_2_14, SCS_C_3_14, SCS_C_4_14, SCS_C_5_14,
                                  SCS_C_6_14, SCS_C_7_14, SCS_C_8_14, SCS_C_9_14, SCS_C_10_14)),
         SCS_C_Group_Funny=as.character(paste0(SCS_C_1_15, SCS_C_2_15, SCS_C_3_15, SCS_C_4_15, SCS_C_5_15,
                                  SCS_C_6_15, SCS_C_7_15, SCS_C_8_15, SCS_C_9_15, SCS_C_10_15)),
         SCS_C_Group_Ugly=as.character(paste0(SCS_C_1_16, SCS_C_2_16, SCS_C_3_16, SCS_C_4_16, SCS_C_5_16,
                                  SCS_C_6_16, SCS_C_7_16, SCS_C_8_16, SCS_C_9_16, SCS_C_10_16)),
         SCS_C_Group_Sad=as.character(paste0(SCS_C_1_17, SCS_C_2_17, SCS_C_3_17, SCS_C_4_17, SCS_C_5_17,
                                  SCS_C_6_17, SCS_C_7_17, SCS_C_8_17, SCS_C_9_17, SCS_C_10_17)),
         SCS_C_Group_Shy=as.character(paste0(SCS_C_1_18, SCS_C_2_18, SCS_C_3_18, SCS_C_4_18, SCS_C_5_18,
                                  SCS_C_6_18, SCS_C_7_18, SCS_C_8_18, SCS_C_9_18, SCS_C_10_18)),
         SCS_C_Group_Confused=as.character(paste0(SCS_C_1_19, SCS_C_2_19, SCS_C_3_19, SCS_C_4_19, SCS_C_5_19,
                                  SCS_C_6_19, SCS_C_7_19, SCS_C_8_19, SCS_C_9_19, SCS_C_10_19)),
         SCS_C_Group_Careless=as.character(paste0(SCS_C_1_20, SCS_C_2_20, SCS_C_3_20, SCS_C_4_20, SCS_C_5_20,
                                  SCS_C_6_20, SCS_C_7_20, SCS_C_8_20, SCS_C_9_20, SCS_C_10_20)))

SCSC_Groups <- SCSC_Wave1 %>% select(SCS_C_Group_Happy, SCS_C_Group_Smart, SCS_C_Group_Brave, SCS_C_Group_Helpful, 
                                     SCS_C_Group_Nice, SCS_C_Group_Angry, SCS_C_Group_Lonely, SCS_C_Group_Lazy, 
                                     SCS_C_Group_Bad, SCS_C_Group_Scared, SCS_C_Group_Responsible, SCS_C_Group_Confident, 
                                     SCS_C_Group_Kind, SCS_C_Group_Calm, SCS_C_Group_Funny, SCS_C_Group_Ugly, 
                                     SCS_C_Group_Sad, SCS_C_Group_Shy, SCS_C_Group_Confused, SCS_C_Group_Careless)
SCSC_Groups$patterncount <- apply(SCSC_Groups, 1, function(x)length(unique(x)))
  
```
           mutate(SCS_C_HTotal=log2(20)-((xi(log2(xi))/20)))
           # %>%

  mutate(SCC_N=10,
         SCC_missing=rowSums(is.na(cbind(SCC_1,SCC_2,SCC_3,SCC_4,SCC_5,SCC_6,SCC_7,SCC_8,SCC_9,SCC_10,SCC_11,SCC_12))),
         SCC_total=rowSums(cbind(SCC_1,SCC_2,SCC_3,SCC_4,SCC_5,SCC_6,SCC_7,SCC_8,SCC_9,SCC_10,SCC_11,SCC_12), na.rm=F),
         SCC_mean=rowMeans(cbind(SCC_1,SCC_2,SCC_3,SCC_4,SCC_5,SCC_6,SCC_7,SCC_8,SCC_9,SCC_10,SCC_11,SCC_12), na.rm=T))

## Save it
write.csv(SCC_Wave1, file = paste0(workdir,"Questionnaires/Wave_1/SCC_Wave1.csv"))

## Graph it
SCC_Wave1_total<-SCC_Wave1 %>%
  select(tagid,SCC_total) %>%
  gather('item','value',2:length(.)) 
SCC_Wave1_total_graph<-ggplot(SCC_Wave1_total, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Self-Concept Clarity total score for ",length(unique(SCC_Wave1$tagid[!is.na(SCC_Wave1$SCC_total)]))," participants"))

SCC_Wave1_mean<-SCC_Wave1 %>%
  select(tagid,SCC_mean)%>%
  gather('item','value',2:length(.)) 
SCC_Wave1_mean_graph<-ggplot(SCC_Wave1_mean, aes(x=value, colour=item)) +
  geom_density(alpha=.3)+
  ggtitle(paste0("Self-Concept Clarity mean score for ",length(unique(SCC_Wave1$tagid[!is.na(SCC_Wave1$SCC_mean)]))," participants"))
    

Prepare PSQI_MEQ # Do not submit to RDOC
```{r}
                              
```

Prepare YRBS # Do not submit to RDOC
```{r}
YRBS<-left_join(filter(cleaned_survey_data, grepl("YRBS",item)) %>%
                 mutate(value=as.numeric(value)) %>% 
                 filter(!is.na(value)) %>%
                 filter(!value=="") %>%
                 distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                 spread(item,value),
               redcap_cleaned %>%
                 filter(!is.na(dob),!is.na(sa_date)) %>%
                 select(tagid, sa_date, sb_date, dob),by="tagid")
  
YRBS_Wave1<-left_join(YRBS,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) 

## Save it
YRBS_Wave1_outdf <- YRBS_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(YRBS_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/YRBS_Wave1.csv"))


```

Prepare Parent CBCL
```{r}
x <- c("Sport","Hobb","Club","Chore","Friends","Get_Along","Grades","Other_sub","Specialed","What","Rep","Reasons","School_prob","Disability",
       "Best","VIII","P_","How_Well")

CBCL<-left_join(filter(cleaned_survey_data, grepl("Parent",survey_name)) %>%
                  filter(grepl(paste(x, collapse = "|"),item)) %>%
                  filter(!is.na(value), !value=="") %>%
                  distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                    filter(!tagid=="TAG110") %>% 
                  spread(item,value),
                redcap_cleaned %>%
                  filter(!is.na(dob),!is.na(sa_date)) %>%
                  select(tagid, sa_date, sb_date, dob),by="tagid")

#need to fix tag 110.  w1 accidentally administered w2 parent qs

if (length(CBCL$tagid) == length(unique(CBCL$tagid))){
  print("No duplicate TAGIDs in data")
  } else {
      print("DUPLICATE TAGIDs in data")
  }

CBCL_Wave1<-left_join(CBCL,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Parent Questionnaires V1",sa_date,
                            ifelse(survey_name=="TAG - Parent Questionnaires - V2 - Current",sa_date,
                                   as.character(qualtrics_date)
                                          ))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) 

## Save it
CBCL_Wave1_outdf <- CBCL_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(CBCL_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/CBCL_Wave1.csv"))

CBCL_Wave2_outdf <- CBCL_Wave1 %>% filter(grepl("W2",survey_name)) 
write.csv(CBCL_Wave2_outdf, file = paste0(workdir,"Questionnaires/Wave2/CBCL_Wave2.csv"))

CBCL_Wave3_outdf <- CBCL_Wave1 %>% filter(grepl("W3",survey_name)) 
write.csv(CBCL_Wave3_outdf, file = paste0(workdir,"Questionnaires/Wave3/CBCL_Wave3.csv"))


## Make RDOC ready file
ndar_cbcl_data <- left_join(CBCL_Wave1,distinct(redcap_cleaned, tagid, dob),by="tagid") %>%
  filter(!is.na(survey_date),!survey_date=="") %>%
  mutate(interview_date=paste0(sprintf("%02d",month(survey_date)),"/",sprintf("%02d",day(survey_date)),"/",year(survey_date)),
         interview_age=round((interval(start =dob, end = survey_date) / duration(num = 1, units = "months")),0),
         gender="F",
         relationship=ifelse(P_Gender==1 && P_Relation==1,2,
                             ifelse(P_Gender==2 && P_Relation==1,1,
                                    ifelse(P_Gender==1 && P_Relation==2,18,
                                           ifelse(P_Gender==2 && P_Relation==2,17,
                                                  ifelse(P_Gender==1 && P_Relation==3,24,
                                                         ifelse(P_Gender==2 && P_Relation==3,23,
                                                                ifelse(P_Gender==1 && P_Relation==4,20,
                                                                       ifelse(P_Gender==2 && P_Relation==4,19,
                                                                              ifelse(P_Gender==1 && P_Relation==5,22,
                                                                                     ifelse(P_Gender==2 && P_Relation==5,21,
                                                                                            ifelse(P_Gender==1 && P_Relation==6,84,
                                                                                                   ifelse(P_Gender==2 && P_Relation==6,82,NA)))))))))))),
         study="Transitions in Adolescent Girls (TAG) Study",
         sports_des1=Sport_List_1_TEXT,
         sports_des2=Sport_List_2_TEXT,
         sports_des3=Sport_List_3_TEXT,
         sports_time1=ifelse(!is.na(Sport_Time_1),as.numeric(Sport_Time_1),999),
         sports_well1=ifelse(!is.na(Sport_Well_1),as.numeric(Sport_Well_1),999),
         sports_time2=ifelse(!is.na(Sport_Time_2),as.numeric(Sport_Time_2),999),
         sports_well2=ifelse(!is.na(Sport_Well_2),as.numeric(Sport_Well_2),999),
         sports_time3=ifelse(!is.na(Sport_Time_3),as.numeric(Sport_Time_3),999),
         sports_well3=ifelse(!is.na(Sport_Well_3),as.numeric(Sport_Well_3),999),
         activities_des1=Hobby_List_1_TEXT,
         activities_time1=as.numeric(Hobby_Time_1),
         activities_well1=as.numeric(Hobby_Well_1),
         activities_des2=Hobby_List_2_TEXT,
         activities_time2=as.numeric(Hobby_Time_2),
         activities_well2=as.numeric(Hobby_Well_2),
         activities_des3=Hobby_List_3_TEXT,
         activities_time3=as.numeric(Hobby_Time_3),
         activities_well3=as.numeric(Hobby_Well_3),
         clubs_des1=Clubs_List_1_TEXT,
         clubs_active1=as.numeric(ClubActive_1),
         clubs_des2=Clubs_List_2_TEXT,
         clubs_active2=as.numeric(ClubActive_2),
         clubs_des3=Clubs_List_3_TEXT,
         clubs_active3=as.numeric(ClubActive_3),
         chores_des1=Chores_List_1_TEXT,
         chores_well1=as.numeric(Chore_Well_1),
         chores_des2=Chores_List_2_TEXT,
         chores_well2=as.numeric(Chore_Well_2),
         chores_des3=Chores_List_3_TEXT,
         chores_well3=as.numeric(Chore_Well_3),
         friends=Friends_Number,
         friends_time=Friends_Time,
         interp_siblings=as.numeric(How_Well_Get_Along_Sibs),
         interp_kids=as.numeric(How_Well_Get_Along_Kids),
         interp_parents=as.numeric(How_Well_Behave_Parents),
         interp_alone=as.numeric(How_Well_Play_Work_Alone),
         cbcl1=VIII_1,
         cbcl2=VIII_2,
         cbcl3=VIII_3,
         cbcl4=VIII_4,
         cbcl5=VIII_5,
         cbcl6=VIII_6,
         cbcl7=VIII_7,
         cbcl8=VIII_8,
         cbcl9=VIII_9,
         cbcl10=ifelse(!is.na(VIII_10),VIII_10,999),
         cbcl11=ifelse(!is.na(VIII_11),VIII_11,999),
         cbcl12=VIII_12,
         cbcl13=VIII_13,
         cbcl14=VIII_14,
         cbcl15=VIII_15,
         cbcl16=VIII_16,
         cbcl17=VIII_17,
         cbcl18=VIII_18,
         cbcl19=VIII_19,
         cbcl20=VIII_20,
         cbcl21=VIII_21,
         cbcl22=VIII_22,
         cbcl23=VIII_23,
         cbcl24=ifelse(!is.na(VIII_24),VIII_24,999),
         cbcl25=VIII_25,
         cbcl26=VIII_26,
         cbcl27=VIII_27,
         cbcl28=VIII_28,
         cbcl29=VIII_29,
         cbcl30=ifelse(!is.na(VIII_30),VIII_30,999),
         cbcl31=ifelse(!is.na(VIII_31),VIII_31,999),
         cbcl32=VIII_32,
         cbcl33=VIII_33,
         cbcl34=ifelse(!is.na(VIII_34),VIII_34,999),
         cbcl35=VIII_35,
         cbcl36=VIII_36,
         cbcl37=VIII_37,
         cbcl38=ifelse(!is.na(VIII_38),VIII_38,999),
         cbcl39=VIII_39,
         cbcl40=ifelse(!is.na(VIII_40),VIII_40,999),
         cbcl41=VIII_41,
         cbcl42=VIII_42,
         cbcl43=VIII_43,
         cbcl44=VIII_44,
         cbcl45=VIII_45,
         cbcl46=VIII_46,
         cbcl47=ifelse(!is.na(VIII_47),VIII_47,999),
         cbcl48=ifelse(!is.na(VIII_48),VIII_48,999),
         cbcl49=ifelse(!is.na(VIII_49),VIII_49,999),
         cbcl50=VIII_50,
         cbcl51=VIII_51,
         cbcl52=VIII_52,
         cbcl53=VIII_53,
         cbcl54=VIII_54,
         cbcl55=VIII_55,
         cbcl56a=VIII_56a,
         cbcl56b=VIII_56b,
         cbcl56c=VIII_56c,
         cbcl56d=VIII_56d,
         cbcl56e=ifelse(!is.na(VIII_56e),VIII_56e,999),
         cbcl56f=VIII_56f,
         cbcl56g=VIII_56g,
         cbcl56h=ifelse(!is.na(VIII_56h),as.numeric(VIII_56h),999),
         cbcl57=VIII_57,
         cbcl58=VIII_58,
         cbcl59=VIII_59,
         cbcl60=VIII_60,
         cbcl61=VIII_61,
         cbcl62=VIII_62,
         cbcl63=VIII_63,
         cbcl64=VIII_64,
         cbcl65=VIII_65,
         cbcl66=VIII_66,
         cbcl67=VIII_67,
         cbcl68=VIII_68,
         cbcl69=VIII_69,
         cbcl70=ifelse(!is.na(VIII_70),as.numeric(VIII_70),999),
         cbcl71=VIII_71,
         cbcl72=VIII_72,
         cbcl73=VIII_73,
         cbcl74=ifelse(!is.na(VIII_74),VIII_74,999),
         cbcl75=VIII_75,
         cbcl76=VIII_76,
         cbcl77=VIII_77,
         cbcl78=VIII_78,
         cbcl79=VIII_79,
         cbcl80=ifelse(!is.na(VIII_80),VIII_80,999),
         cbcl81=VIII_81,
         cbcl82=VIII_82,
         cbcl83=VIII_83,
         cbcl84=VIII_84,
         cbcl85=ifelse(!is.na(VIII_85),VIII_85,999),
         cbcl86=VIII_86,
         cbcl87=VIII_87,
         cbcl88=VIII_88,
         cbcl89=VIII_89,
         cbcl90=VIII_90,
         cbcl91=VIII_91,
         cbcl92=VIII_92,
         cbcl93=VIII_93,
         cbcl94=ifelse(!is.na(VIII_94),VIII_94,999),
         cbcl95=VIII_95,
         cbcl96=VIII_96,
         cbcl97=ifelse(!is.na(VIII_97),VIII_97,999),
         cbcl98=VIII_98,
         cbcl99=VIII_99,
         cbcl100=VIII_100,
         cbcl101=VIII_101,
         cbcl102=VIII_102,
         cbcl103=VIII_103,
         cbcl104=VIII_104,
         cbcl105=VIII_105,
         cbcl106=VIII_106,
         cbcl107=VIII_107,
         cbcl108=VIII_108,
         cbcl109=VIII_109,
         cbcl110=ifelse(!is.na(VIII_110),VIII_110,999),
         cbcl111=ifelse(!is.na(VIII_111),VIII_111,999),
         cbcl112=VIII_112,
         cbcl_emotional_raw=999,
         cbcl_emotional=999,
         cbcl_anxious_raw=999,
         cbcl_anxious=999,
         cbcl_somatic_c_raw=999,
         cbcl_somatic_c=999,
         cbcl_withdrawn_raw=999,
         cbcl_withdrawn=999,
         cbcl_sleep_raw=999,
         cbcl_sleep=999,
         cbcl_attention_raw=999,
         cbcl_attention=999,
         cbcl_aggressive_raw=999,
         cbcl_aggressive=999,
         cbcl_internal_raw=999,
         cbcl_internal=999,
         cbcl_external_raw=999,
         cbcl_external=999,
         cbcl_total_raw=999,
         cbcl_total=999,
         cbcl_affective_raw=999,
         cbcl_affective=999,
         cbcl_anxiety_raw=999,
         cbcl_anxiety=999,
         cbcl_pervasive_raw=999,
         cbcl_pervasive=999,
         cbcl_adhd_raw=999,
         cbcl_adhd=999,
         cbcl_oppositional_raw=999,
         cbcl_oppositional=999,
         cbcl_social_p_raw=999,
         cbcl_social_p=999,
         cbcl_thought_raw=999,
         cbcl_thought=999,
         cbcl_rulebreak_raw=999,
         cbcl_rulebreak=999,
         cbcl_activities_raw=999,
         cbcl_activities=999,
         cbcl_social_c_raw=999,
         cbcl_social_c=999,
         cbcl_school_raw=999,
         cbcl_school=999,
         cbcl_total_c_raw=999,
         cbcl_total_c=999,
         cbcl_somatic_p_raw=999,
         cbcl_somatic_p=999,
         cbcl_conduct_raw=999,
         cbcl_conduct=999,
         cbcl_sct_raw=999,
         cbcl_sct=999,
         cbcl_ocd_raw=999,
         cbcl_ocd=999,
         cbcl_ptsd_raw=999,
         cbcl_ptsd=999,
         cbcl_depresspr=999,
         cbcl_depresspr_raw=999)

ndar_cbcl_data <- left_join(ndar_key,ndar_cbcl_data, by="tagid") %>%
  mutate(src_subject_id=anontagid,
         subjectkey=guid) %>%
  filter(!is.na(subjectkey),
         !interview_age=="") %>%
  select(-contains("CBCL",ignore.case = FALSE),-dob,-survey_date,-survey_name,-tagid,-anontagid,-ID,-guid,-survey_type)
cbcl_df_header<-rep(NA,length(read.csv(paste0(workdir,"RDoCdb/templates/cbcl01_template.csv"), header = FALSE, stringsAsFactors = FALSE)))
cbcl_df_header[1]<-read.csv(paste0(workdir,"RDoCdb/templates/cbcl01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,1]
cbcl_df_header[2]<-read.csv(paste0(workdir,"RDoCdb/templates/cbcl01_template.csv"), header = FALSE, stringsAsFactors = FALSE)[1,2]

cbcl_temp<-as.list(read.csv(paste0(workdir,"RDoCdb/templates/cbcl01_template.csv"), header = TRUE, stringsAsFactors = FALSE, skip=1))
cbcl_temp_df<-data.frame(cbcl_temp)
ndar_cbcl_data<-bind_rows(cbcl_temp_df,ndar_cbcl_data)[c(1:429)]

part2<-colnames(ndar_cbcl_data)
part3<-as.matrix(ndar_cbcl_data)
colnames(part3)<-NULL
together<-rbind(cbcl_df_header,part2,part3)
write.table(together,file =paste0(workdir,"RDoCdb/output/jan2019/cbcl01.csv"),sep=",",na = "",row.names=FALSE,col.names=FALSE)
rm(together,part2,part3,cbcl_df_header,cbcl_temp,cbcl_temp_df,CBCL,CBCL_Wave1)
```

Prepare Parent-report PDS
```{r}
#section completed by NV
PDS_parent<-left_join(filter(cleaned_survey_data, grepl("Parent",survey_name)) %>%
                  filter(grepl("PDS",item)) %>%
                  filter(!is.na(value), !value=="") %>%
                  distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>%
                  spread(item,value),
                redcap_cleaned %>%
                  filter(!is.na(dob),!is.na(sa_date)) %>%
                  select(tagid, sa_date, sb_date, dob),by="tagid")

PDS_parent_Wave1<-left_join(PDS_parent,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>%
  select(-value)%>%
  mutate(survey_date=ifelse(survey_name=="TAG - Parent Questionnaires V1",sa_date,
                            ifelse(survey_name=="TAG - Parent Questionnaires - V2 - Current",sa_date,
                                   as.character(qualtrics_date)
                                          ))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) 

PDS_parent_Wave1<-left_join(PDS_parent,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>% 
  select(-value) %>%
  mutate(survey_date=ifelse(survey_name=="TAG - Parent Questionnaires V1",sa_date,
                            ifelse(survey_name=="TAG - Parent Questionnaires - V2 - Current",sa_date,
                                   as.character(qualtrics_date)
                                          ))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(peta=PDS_F1,
         petb=PDS_F2,
         petc=PDS_F3,
         petd=PDS_F4,
         pete=PDS_F5,
         fpete=PDS_F6,
         petaf=ifelse(PDS_F1==1,1,
                      ifelse(PDS_F1==2,2,
                             ifelse(PDS_F1==3,3,
                                    ifelse(PDS_F1==4,5,
                                           NA)))),
         petbf=ifelse(PDS_F2==1,1,
                      ifelse(PDS_F2==2,2,
                             ifelse(PDS_F2==3,4,
                                    ifelse(PDS_F2==4,5,
                                           NA)))),
         petcf=ifelse(PDS_F3==1,1,
                      ifelse(PDS_F3==2,2,
                             ifelse(PDS_F3==3,4,
                                    ifelse(PDS_F3==4,5,
                                           NA)))),
         petdf=ifelse(PDS_F4==1,1,
                      ifelse(PDS_F4==2,3,
                             ifelse(PDS_F4==3,4,
                                    ifelse(PDS_F4==4,5,
                                           NA)))),         
         petef=ifelse(PDS_F6==0,1,
                      ifelse(PDS_F6==1,5,
                             NA))) %>%
  mutate(adrenf=rowMeans(cbind(petbf,petcf),na.rm=F)) %>%
  mutate(adrenf2=ifelse(adrenf==1,1,
                        ifelse(petb==1 & adrenf==1.5,1,
                               ifelse(petb==2 & adrenf==1.5,2,
                                      ifelse(adrenf==2,2,
                                             ifelse(adrenf==2.5,3,
                                                    ifelse(adrenf==3,3,
                                                           ifelse(adrenf==3.5,4,
                                                                  ifelse(adrenf==4,4,
                                                                         ifelse(adrenf==4.5,5,
                                                                                ifelse(adrenf==5,5,
                                                                                       NA))))))))))) %>%
  mutate(gonadf=rowMeans(cbind(petaf,petdf),na.rm=F)) %>%
  mutate(gonadf2=ifelse(gonadf==1 & petef==1,1,
                        ifelse(gonadf==1.5 & petef==1,1,
                               ifelse(gonadf==2 & petef==1,2,
                                      ifelse(gonadf==2.5 & petef==1,2,
                                             ifelse(gonadf==3 & petef==1,3,
                                                    ifelse(gonadf==3.5 & petef==1,3,
                                                           ifelse(gonadf==4 & petef==1,3,
                                                                  ifelse(gonadf==4.5 & petef==1,4,
                                                                         ifelse(gonadf==5 & petef==1,4,
                                                                                ifelse(gonadf==1 & petef==5,2,
                                                                                       ifelse(gonadf==1.5 & petef==5,3,
                                                                                              ifelse(gonadf==2 & petef==5,4,
                                                                                                     ifelse(gonadf==2.5 & petef==5,4,
                                                                                                            ifelse(gonadf==3 & petef==5,4,
                                                                                                                   ifelse(gonadf==3.5 & petef==5,5,
                                                                                                                          ifelse(gonadf==4 & petef==5,5,
                                                                                                                                 ifelse(gonadf==4.5 & petef==5,5,
                                                                                                                                        ifelse(gonadf==5 & petef==5,5,
                                                                                                                                               NA))))))))))))))))))) %>%
  mutate(pdss=rowMeans(cbind(adrenf2,gonadf2),na.rm=F),
         pdss_N=5,
         pdss_missing=rowSums(is.na(cbind(PDS_F1,PDS_F2,PDS_F3,PDS_F4,PDS_F6))),
         pdss_missing_perc=100*(rowSums(is.na(cbind(PDS_F1,PDS_F2,PDS_F3,PDS_F4,PDS_F6)))/5),
         adrenf2_N=2,
         adrenf2_missing=rowSums(is.na(cbind(PDS_F2,PDS_F3))),
         adrenf2_missing_perc=100*(rowSums(is.na(cbind(PDS_F2,PDS_F3)))/2),
         gonadf2_N=3,
         gonadf2_missing=rowSums(is.na(cbind(PDS_F1,PDS_F4,PDS_F6))),
         gonadf2_missing_perc=100*(rowSums(is.na(cbind(PDS_F1,PDS_F4,PDS_F6)))/3),
         ) #NV added perc missing      

## Save it
PDS_parent_Wave1_outdf <- PDS_parent_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(PDS_parent_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/PDS_parent_Wave1.csv"))
```

Prepare Parent-report CES_D 
```{r}
CESD_parent<-left_join(filter(cleaned_survey_data, grepl("CES_D_",item)) %>% 
                   mutate(value=as.numeric(value)) %>% 
                   filter(!is.na(value)) %>% 
                   distinct(tagid,item,value,survey_name,.keep_all = FALSE) %>% 
                   spread(item,value),redcap_cleaned %>%
                   filter(!is.na(dob),!is.na(sa_date)) %>%
                   select(tagid, sa_date, sb_date, dob),by="tagid")

CESD_parent_Wave1<-left_join(CESD_parent,survey_date, by = c("tagid","survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = TRUE) %>%
  mutate(qualtrics_date=value) %>% 
  select(-value) %>%
  mutate(survey_date=ifelse(survey_name=="TAG - Sess 2 - V1",sb_date,
                            ifelse(survey_name=="TAG - Sess 2 - V2",sb_date,
                                   ifelse(survey_name=="TAG - Sess 2 - V3 - Current",sb_date,
                                          ifelse(survey_name=="Sensitive Q's for 042",sb_date,as.character(qualtrics_date)
                                          ))))) %>%
  select(-qualtrics_date,-sb_date,-sa_date,-dob) %>%
  mutate(CES_D_4=ifelse(CES_D_4==0,3,
                         ifelse(CES_D_4==1,2,
                                ifelse(CES_D_4==2,1,
                                       ifelse(CES_D_4==3,0,
                                              NA)))),
         CES_D_8=ifelse(CES_D_8==0,3,
                         ifelse(CES_D_8==1,2,
                                ifelse(CES_D_8==2,1,
                                       ifelse(CES_D_8==3,0,
                                              NA)))),
         CES_D_12=ifelse(CES_D_12==0,3,
                          ifelse(CES_D_12==1,2,
                                 ifelse(CES_D_12==2,1,
                                        ifelse(CES_D_12==3,0,
                                               NA)))),
         CES_D_16=ifelse(CES_D_16==0,3,
                          ifelse(CES_D_16==1,2,
                                 ifelse(CES_D_16==2,1,
                                        ifelse(CES_D_16==3,0,
                                               NA))))) %>%
  mutate(
    CES_D_C=20,
    CES_D_missing=rowSums(is.na(cbind(CES_D_1,CES_D_2,CES_D_3,CES_D_4,CES_D_5,CES_D_6,CES_D_7,CES_D_8,CES_D_9,CES_D_10,CES_D_11,CES_D_12,CES_D_13,CES_D_14,CES_D_15,CES_D_16,CES_D_17,CES_D_18,CES_D_19,CES_D_20))),
    CES_D_missing_perc=100*(rowSums(is.na(cbind(CES_D_1,CES_D_2,CES_D_3,CES_D_4,CES_D_5,CES_D_6,CES_D_7,CES_D_8,CES_D_9,CES_D_10,CES_D_11,CES_D_12,CES_D_13,CES_D_14,CES_D_15,CES_D_16,CES_D_17,CES_D_18,CES_D_19,CES_D_20)))/20),
    CES_D_mean=rowMeans(cbind(CES_D_1,CES_D_2,CES_D_3,CES_D_4,CES_D_5,CES_D_6,CES_D_7,CES_D_8,CES_D_9,CES_D_10,CES_D_11,CES_D_12,CES_D_13,CES_D_14,CES_D_15,CES_D_16,CES_D_17,CES_D_18,CES_D_19,CES_D_20), na.rm=T),
    CES_D_total=rowSums(cbind(CES_D_1,CES_D_2,CES_D_3,CES_D_4,CES_D_5,CES_D_6,CES_D_7,CES_D_8,CES_D_9,CES_D_10,CES_D_11,CES_D_12,CES_D_13,CES_D_14,CES_D_15,CES_D_16,CES_D_17,CES_D_18,CES_D_19,CES_D_20), na.rm=F)) %>%
  mutate(CES_D_total_75perc=ifelse(CES_D_missing_perc <= 25,CES_D_mean*20,NA))

## Save it
CESD_parent_Wave1_outdf <- CESD_parent_Wave1 %>% filter(!grepl("W2|W3",survey_name)) 
write.csv(CESD_parent_Wave1_outdf, file = paste0(workdir,"Questionnaires/Wave1/CESD_parent_Wave1.csv"))

## Graph it
CESD_parent_Wave1_totals_graph<-ggplot(CESD_parent_Wave1, aes(x=CES_D_total, colour="deeppink")) +
  geom_density(alpha=.3,show.legend = FALSE)+
  ggtitle(paste0("CESD-Parent total scores for ",length(CESD_parent_Wave1$CES_D_total[!is.na(CESD_parent_Wave1$CES_D_total)])," Wave 1 participants"))

CESD_parent_Wave1_means_graph<-ggplot(CESD_parent_Wave1, aes(x=CES_D_mean, colour="dodgerblue")) +
  geom_density(alpha=.3, show.legend = FALSE)+
  ggtitle(paste0("CESD-Parent mean scores for ",length(CESD_parent_Wave1$CES_D_mean[!is.na(CESD_parent_Wave1$CES_D_mean)])," Wave 1 participants"))

```

Prepare Parent-report DEM/SES
```{r}
#Error-dataframe not found
x <- c("^Sib","Ethn","Edu","Inc","Free_Lunch","Gender")
qualtricsData_raw_dem <-filter(qualtricsData_raw_long, grepl("Parent",survey_name)) %>% 
  filter(grepl(paste(x, collapse = "|"),item)) %>%
  mutate(value=as.numeric(value)) %>%
  filter(!is.na(value)) %>%
  filter(!is.na(value)) %>%
  distinct(tagid,item,value,.keep_all = TRUE) %>% 
  spread(item,value) %>%
  filter(!tagid=="TAG070")

qualtricsData_raw_dem<-left_join(qualtricsData_raw_dem,survey_date, by = c("tagid", "survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = FALSE) %>%
  mutate(survey_date=value) %>% select(-item, -value) %>%
  mutate(Income=ifelse(Income==1,"<25000",
                       ifelse(Income==2,"25-40,000",
                              ifelse(Income==3,"40-75,000",
                                     ifelse(Income==4,"75-100,000",
                                            ifelse(Income==5,">100,000",
                                                   NA))))),
         Income=ordered(Income, levels=c("<25000","25-40,000","40-75,000","75-100,000",">100,000")),
         MomEdu=as.factor(ifelse(P_Gender==2,P_Edu,Spouse_Edu)),
         DadEdu=as.factor(ifelse(P_Gender==2,Spouse_Edu,P_Edu)))



DadEthnic=ifelse(DadEthnic_1==1,1,
                 ifelse(DadEthnic_2==1,2,
                        ifelse(DadEthnic_3==1,3,
                               ifelse(DadEthnic_4==1,4,
                                      ifelse(DadEthnic_5==1,5,
                                             ifelse(DadEthnic_6==1,6,
                                                    ifelse(DadEthnic_7==7,
                                                           NA))))))))

,
MomEthnic=ifelse(DadEthnic_1==1,1,
                 ifelse(DadEthnic_2==1,2,
                        ifelse(DadEthnic_3==1,3,
                               ifelse(DadEthnic_4==1,4,
                                      ifelse(DadEthnic_5==1,5,
                                             ifelse(DadEthnic_6==1,6,
                                                    ifelse(DadEthnic_7==7,
                                                           NA))))))))

```

DEPRECATED: VISUALIZATION
```{r}
library(ggplot2)
theme_set(theme_gray(base_size = 18))

#PDS
qualtricsData_raw_pds$pdss_int<-as.integer(qualtricsData_raw_pds$pdss)
ggplot(qualtricsData_raw_pds, aes(x=pdss_int)) + geom_bar() + theme(axis.title.x=element_blank(), axis.title.y=element_blank()) + ggtitle("PDS")

ggplot(qualtricsData_raw_pds, aes(x=adrenf2)) + geom_bar() + theme(axis.title.x=element_blank(), axis.title.y=element_blank()) + ggtitle("Adrenarche")

ggplot(qualtricsData_raw_pds, aes(x=gonadf2)) + geom_bar() + theme(axis.title.x=element_blank(), axis.title.y=element_blank()) + ggtitle("Gonadarche")

#Income
ggplot(qualtricsData_raw_dem[!is.na(qualtricsData_raw_dem$Income),], aes(x=Income)) + geom_bar() + theme(axis.text.x = element_text(angle=90), axis.title.x=element_blank(), axis.title.y=element_blank()) + ggtitle("Income")

#MotherEdu
Labels <- c("Public School","High School Dip","Trade School","Associate's Deg","Undergrad","Postgrad","Other")
ggplot(qualtricsData_raw_dem[!is.na(qualtricsData_raw_dem$MomEdu),], aes(x=MomEdu)) + geom_bar() + scale_x_discrete(labels=Labels) + theme(axis.text.x = element_text(angle=90), axis.title.x=element_blank(), axis.title.y=element_blank()) + ggtitle("Mother's Education")

#FatherEdu
Labels <- c("Public School","High School Dip","Trade School","Associate's Deg","Undergrad","Postgrad","Other")
ggplot(qualtricsData_raw_dem[!is.na(qualtricsData_raw_dem$DadEdu),], aes(x=DadEdu)) + geom_bar() + scale_x_discrete(labels=Labels) + theme(axis.text.x = element_text(angle=90), axis.title.x=element_blank(), axis.title.y=element_blank()) + ggtitle("Father's Education")

```

DEPRECATED: DEMO
```{r}
x <- c("Ethnicity_1","Ethnicity_2","Ethnicity_3","Ethnicity_4","Ethnicity_5","Ethnicity_6","Ethnicity_7","Ethnicity_8","Ethnicity_9","Ethnicity_10","Ethnicity_11","Ethnicity_7_TEXT")

qualtricsData_raw_parent_demo <-filter(qualtricsData_raw_long, grepl("Parent",survey_name)) %>% 
  filter(grepl(paste(x, collapse = "|"),item)) %>%
  mutate(value=as.numeric(value)) %>% 
  distinct(tagid,item,.keep_all = TRUE) %>% 
  spread(item,value)

qualtricsData_raw_parent_demo<-left_join(qualtricsData_raw_parent_demo,survey_date, by = c("tagid", "survey_name")) %>% 
  distinct(tagid,survey_name,.keep_all = FALSE) %>%
  mutate(survey_date=value) %>% select(-item, -value) %>%
  mutate(ethnicity=ifelse(Ethnicity_2==1,"Hispanic",
                          "NonHispanic")) %>%
  mutate(race=ifelse((Ethnicity_1 == 1) & (is.na(Ethnicity_2)) & (is.na(Ethnicity_3)) & (is.na(Ethnicity_4)) & (is.na(Ethnicity_5)) & (is.na(Ethnicity_6)) & (is.na(Ethnicity_10)), 1,
                     ifelse((Ethnicity_2 == 1) & (is.na(Ethnicity_1)) & (is.na(Ethnicity_3)) & (is.na(Ethnicity_4)) & (is.na(Ethnicity_5)) & (is.na(Ethnicity_6)) & (is.na(Ethnicity_10)), 2,
                            ifelse((Ethnicity_3 == 1) & (is.na(Ethnicity_1)) & (is.na(Ethnicity_2)) & (is.na(Ethnicity_4)) & (is.na(Ethnicity_5)) & (is.na(Ethnicity_6)) & (is.na(Ethnicity_10)), 3,
                                   ifelse((Ethnicity_4 == 1) & (is.na(Ethnicity_1)) & (is.na(Ethnicity_2)) & (is.na(Ethnicity_3)) & (is.na(Ethnicity_5)) & (is.na(Ethnicity_6)) & (is.na(Ethnicity_10)), 4,
                                          ifelse((Ethnicity_5 == 1) & (is.na(Ethnicity_1)) & (is.na(Ethnicity_2)) & (is.na(Ethnicity_3)) & (is.na(Ethnicity_4)) & (is.na(Ethnicity_6)) & (is.na(Ethnicity_10)), 5,
                                                 ifelse((Ethnicity_6 == 1) & (is.na(Ethnicity_1)) & (is.na(Ethnicity_2)) & (is.na(Ethnicity_3)) & (is.na(Ethnicity_4)) & (is.na(Ethnicity_10)), 6,
                                                        ifelse((Ethnicity_10 == 1) & (is.na(Ethnicity_1)) & (is.na(Ethnicity_2)) & (is.na(Ethnicity_3)) & (is.na(Ethnicity_4)) & (is.na(Ethnicity_5)) & (is.na(Ethnicity_10)), 10,
                                                               "multiple"))))))))

qualtricsData_raw_hisp <- qualtricsData_raw_parent_demo[order(qualtricsData_raw_parent_demo$survey_date),] %>% filter(ethnicity=="Hispanic" & survey_date > "2016-05-01")
qualtricsData_raw_nonhisp <- qualtricsData_raw_parent_demo[order(qualtricsData_raw_parent_demo$survey_date),] %>% filter(is.na(ethnicity)  & survey_date > "2016-05-01") 

redcapData_merged <- merge(redcapData_merged, qualtricsData_raw_parent_demo, by = "tagid", all.x=T)
checkDemo <- redcapData_merged[,c("tagid","sa_date","ethnicity","race")]
checkDemo <- checkDemo[order(checkDemo$sa_date),]


qualtricsData_raw_parent_demo <-filter(qualtricsData_raw_long, grepl("Parent",survey_name)) %>% 
  filter(grepl(paste(x, collapse = "|"),item)) %>%
  mutate(value=as.numeric(value)) %>% 
  distinct(tagid,item,.keep_all = TRUE) %>% 
  spread(item,value)
```
